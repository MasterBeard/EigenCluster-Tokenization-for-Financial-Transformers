{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgW733KnLGMLUb+GobQIdJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MasterBeard/EigenCluster-Tokenization-for-Financial-Transformers/blob/main/Implementation_EigenCluster_Tokenization_for_Financial_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EigenCluster Tokenization Implementation for Financial Time Series\n",
        "\n",
        "This code repository provides the implementation of **EigenCluster Tokenization** methodology as presented in the paper:  \n",
        "\n",
        "**\"EigenCluster Tokenization for Financial Transformers: Bullish Signal Prediction\"**  \n",
        "\n",
        "## Key Features\n",
        "\n",
        "1. **Core Implementation**:\n",
        "   - Complete pipeline for financial time series tokenization\n",
        "   - EigenCluster algorithm with multi-scale feature reduction\n",
        "   - Dynamic clustering with PCA-transformed features (Eigenvectors scalars)\n",
        "\n",
        "2. **Reproduction Study**:\n",
        "   - Full replication of the 2015-2024 CSI300 constituent stocks prediction\n",
        "   - Includes data preprocessing, feature engineering, and model training components\n",
        "\n",
        "3. **Technical Notes**:\n",
        "   - Code comments were primarily generated with DeepSeek's assistance\n",
        "   - Please refer to the original paper for authoritative terminology and methodological details\n",
        "   - Discrepancies between code comments and the paper should defer to the original publication\n",
        "\n",
        "4. **Dependencies**:\n",
        "   ```python\n",
        "   numpy, sklearn, torch, imblearn"
      ],
      "metadata": {
        "id": "pQseFr0qaHt6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpviTPKkU-qI",
        "outputId": "be6e2fda-8ab2-4f42-8b5c-5df329c19f32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features shape: (4827, 44)\n",
            "Train norm_features shape: (4827, 44)\n",
            "Train labels shape: (4827,)\n",
            "Validation features shape: (467, 44)\n",
            "Validation norm_features shape: (467, 44)\n",
            "Validation labels shape: (467,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "# Define index codes\n",
        "tickers = {\n",
        "    'SSEC': '000001.SS', # Shanghai Composite\n",
        "    'SZSC': '399001.SZ', # Shenzhen Component\n",
        "}\n",
        "\n",
        "idm = -2\n",
        "date_ranges = {\n",
        "    'train': (\"2004-01-01\", \"2013-12-31\"),\n",
        "    'val': (\"2014-01-02\", \"2014-12-31\")\n",
        "}\n",
        "\n",
        "# Initialize data storage\n",
        "data_splits = {split: {'features': [], 'norm_features': [], 'labels': []} for split in date_ranges}\n",
        "\n",
        "# Window length\n",
        "window_size = 11\n",
        "\n",
        "# Process train and val data\n",
        "for split in ['train', 'val']:\n",
        "    start_date, end_date = date_ranges[split]\n",
        "    index_data = {}\n",
        "    for name, ticker in tickers.items():\n",
        "        if ticker.endswith('.SZ') or ticker.endswith('.SS'):\n",
        "            index_data[name] = yf.Ticker(ticker).history(start=start_date, end=end_date, auto_adjust=True)\n",
        "        else:\n",
        "            index_data[name] = yf.download(ticker, start=start_date, end=end_date, auto_adjust=True)\n",
        "\n",
        "    # Create feature vectors and labels\n",
        "    for index_name, data in index_data.items():\n",
        "        if data.empty:\n",
        "            continue\n",
        "\n",
        "        # Fix multi-level column names if needed\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            data.columns = data.columns.get_level_values(0)\n",
        "\n",
        "        open_values = data['Open'].dropna().values\n",
        "        close_values = data['Close'].dropna().values\n",
        "        low_values = data['Low'].dropna().values\n",
        "        high_values = data['High'].dropna().values\n",
        "\n",
        "        for start in range(len(data) - window_size + 1):\n",
        "            open_row = open_values[start:start + window_size]\n",
        "            low_row = low_values[start:start + window_size]\n",
        "            high_row = high_values[start:start + window_size]\n",
        "            close_row = close_values[start:start + window_size]\n",
        "\n",
        "            # Build feature vector (unnormalized)\n",
        "            combined = np.array([\n",
        "                val for i in range(window_size)\n",
        "                for val in (open_row[i], low_row[i], high_row[i], close_row[i])\n",
        "            ])\n",
        "\n",
        "            # Normalized feature vector\n",
        "            norm_combined = np.array([\n",
        "                (open_row[i] / close_row[idm],\n",
        "                low_row[i] / close_row[idm],\n",
        "                high_row[i] / close_row[idm],\n",
        "                close_row[i] / close_row[idm])\n",
        "                for i in range(window_size)\n",
        "            ]).flatten()\n",
        "\n",
        "            label = 1 if close_row[-1] > close_row[idm] else 0\n",
        "\n",
        "            data_splits[split]['features'].append(combined)\n",
        "            data_splits[split]['norm_features'].append(norm_combined)\n",
        "            data_splits[split]['labels'].append(label)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "train_features = np.array(data_splits['train']['features'])\n",
        "train_norm_features = np.array(data_splits['train']['norm_features'])\n",
        "train_labels = np.array(data_splits['train']['labels'])\n",
        "\n",
        "val_features = np.array(data_splits['val']['features'])\n",
        "val_norm_features = np.array(data_splits['val']['norm_features'])\n",
        "val_labels = np.array(data_splits['val']['labels'])\n",
        "\n",
        "# Print shapes\n",
        "print(f\"Train features shape: {train_features.shape}\")\n",
        "print(f\"Train norm_features shape: {train_norm_features.shape}\")\n",
        "print(f\"Train labels shape: {train_labels.shape}\")\n",
        "\n",
        "print(f\"Validation features shape: {val_features.shape}\")\n",
        "print(f\"Validation norm_features shape: {val_norm_features.shape}\")\n",
        "print(f\"Validation labels shape: {val_labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive (if not already mounted)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Read the data file\n",
        "file_path = \"/content/drive/MyDrive/stock_data_qfq_2015_2024.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(\"Raw data:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz2a81ZzVpBf",
        "outputId": "4e763c62-23b2-40e0-815e-7d1029497c15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Raw data:\n",
            "     ts_code  trade_date     open     high      low    close  pre_close  \\\n",
            "0  600519.SH    20241231  1525.40  1545.00  1522.01  1524.00    1525.00   \n",
            "1  600519.SH    20241230  1533.97  1543.96  1525.00  1525.00    1528.97   \n",
            "2  600519.SH    20241227  1528.90  1536.00  1519.50  1528.97    1527.79   \n",
            "3  600519.SH    20241226  1534.00  1538.78  1523.00  1527.79    1530.00   \n",
            "4  600519.SH    20241225  1538.80  1538.80  1526.10  1530.00    1538.82   \n",
            "\n",
            "   change  pct_chg       vol       amount  \n",
            "0   -1.00    -0.07  39354.45  6033540.366  \n",
            "1   -3.97    -0.26  25129.82  3849542.646  \n",
            "2    1.18     0.08  20759.32  3170191.445  \n",
            "3   -2.21    -0.14  18286.51  2798840.003  \n",
            "4   -8.82    -0.57  17123.39  2621061.878  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main processing pipeline\n",
        "window_size = 11\n",
        "test_features1 = []\n",
        "test_norm_features1 = []\n",
        "test_labels1 = []\n",
        "successful_stocks = 0  # Counter for successfully processed stocks\n",
        "\n",
        "for csv_file in np.unique(df['ts_code']):  # Process all stocks\n",
        "    try:\n",
        "        # Read and process data with special formatting\n",
        "        ohlc = df[df['ts_code']==csv_file][::-1][['open', 'high', 'low', 'close']].reset_index(drop=True)\n",
        "\n",
        "        if len(ohlc['open'].values) != 0:\n",
        "            successful_stocks += 1\n",
        "\n",
        "        # Check if data is empty\n",
        "        if len(ohlc) == 0:\n",
        "            print(f\"{csv_file} has no data in 2015-2024 period\")\n",
        "            continue\n",
        "\n",
        "        # Extract OHLC data\n",
        "        open_vals = ohlc['open'].values\n",
        "        high_vals = ohlc['high'].values\n",
        "        low_vals = ohlc['low'].values\n",
        "        close_vals = ohlc['close'].values\n",
        "\n",
        "        # Build windowed data\n",
        "        for start in range(len(ohlc) - window_size):\n",
        "            window_open = open_vals[start:start+window_size]\n",
        "            window_high = high_vals[start:start+window_size]\n",
        "            window_low = low_vals[start:start+window_size]\n",
        "            window_close = close_vals[start:start+window_size]\n",
        "\n",
        "            # Build feature vector (Open, Low, High, Close order)\n",
        "            feature_vec = np.array([\n",
        "                val for i in range(window_size)\n",
        "                for val in (window_open[i], window_low[i], window_high[i], window_close[i])\n",
        "            ])\n",
        "\n",
        "            # Calculate label (1 if price increased, 0 otherwise)\n",
        "            label = 1 if window_close[-1] > window_close[-2] else 0\n",
        "\n",
        "            test_features1.append(feature_vec)\n",
        "            test_norm_features1.append(feature_vec/window_close[-2])  # Normalized features\n",
        "            test_labels1.append(label)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {csv_file}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "if test_features1:  # Check if any data was generated\n",
        "    test_features1 = np.array(test_features1)\n",
        "    test_norm_features1 = np.array(test_norm_features1)  # Shape changes from (N,44) to (N,44,1)\n",
        "    test_labels1 = np.array(test_labels1)\n",
        "else:\n",
        "    test_features1 = np.array([])\n",
        "    test_labels1 = np.array([])\n",
        "    test_norm_features1 = np.array([])\n",
        "\n",
        "# Output results\n",
        "print(\"\\nTest set generation results:\")\n",
        "if len(test_features1) > 0:\n",
        "    print(f\"Feature matrix shape: {test_features1.shape}\")\n",
        "    print(f\"Normalized feature matrix shape: {test_norm_features1.shape}\")\n",
        "    print(f\"Number of successfully processed stocks: {successful_stocks}\")\n",
        "    print(f\"Label distribution - Up: {np.mean(test_labels1):.1%}, Down: {1-np.mean(test_labels1):.1%}\")\n",
        "else:\n",
        "    print(\"No features generated - please check input file or date range\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zcr7jsS7VxRi",
        "outputId": "4be5df47-0fe3-4694-87d0-2947fb7c4954"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set generation results:\n",
            "Feature matrix shape: (633768, 44)\n",
            "Normalized feature matrix shape: (633768, 44)\n",
            "Number of successfully processed stocks: 300\n",
            "Label distribution - Up: 47.5%, Down: 52.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# ============================================\n",
        "# Utility Functions\n",
        "# ============================================\n",
        "def extract_normalized_daily_ohlc(matrices, epsilon=1e-6):\n",
        "    \"\"\"\n",
        "    Extracts 5-day windows (each 5×4 = 20 dimensions) from each 44-dim vector,\n",
        "    producing 7 windows per vector. Each window is normalized by its 4th day's close price.\n",
        "\n",
        "    Args:\n",
        "        matrices: Input array of OHLC vectors (each 44 dimensions)\n",
        "        epsilon: Small value to avoid division by zero\n",
        "\n",
        "    Returns:\n",
        "        Array of normalized windows with shape [N_samples × 7, 20]\n",
        "    \"\"\"\n",
        "    all_windows = []\n",
        "\n",
        "    for vec in matrices:\n",
        "        reshaped = vec.reshape(-1, 4)  # Reshape to (11 days, 4 features)\n",
        "        for i in range(1, reshaped.shape[0] - 10 + 1):  # 7 sliding windows\n",
        "            window = reshaped[i:i + 10]  # Extract 5-day window (5, 4)\n",
        "            flat = window.flatten()      # Flatten to (20,)\n",
        "\n",
        "            # Normalize by the 4th day's close price (flat[15])\n",
        "            denominator = flat[-5]\n",
        "            if abs(denominator) < epsilon:\n",
        "                denominator = 1.0  # Prevent division by zero\n",
        "\n",
        "            normalized = flat / denominator\n",
        "            all_windows.append(normalized)\n",
        "\n",
        "    return np.array(all_windows)  # shape: [N_samples × 7, 20]\n",
        "\n",
        "# Extract normalized windows for each dataset\n",
        "train_days = extract_normalized_daily_ohlc(train_features)\n",
        "val_days = extract_normalized_daily_ohlc(val_features)"
      ],
      "metadata": {
        "id": "7FOe0p68WIF_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA, NMF, TruncatedSVD\n",
        "\n",
        "# 1. Principal Component Analysis (PCA) - Variance Maximization\n",
        "# Initialize PCA with all components (same dimension as input)\n",
        "pca = PCA(n_components=train_days.shape[1])\n",
        "\n",
        "# Fit PCA on training data and transform both train/val sets\n",
        "# Note: Typically we would fit only on training data and transform validation,\n",
        "# but current implementation fits separately (may want to change this)\n",
        "train_1d = pca.fit_transform(train_days)  # Transform training data\n",
        "val_1d = pca.fit_transform(val_days)     # Transform validation data\n",
        "\n",
        "# Create clustering features by combining:\n",
        "# 1) Mean of sine-transformed components (captures periodic patterns)\n",
        "# 2) Vector magnitude (Euclidean norm)\n",
        "# This creates a 1D feature space for clustering\n",
        "train_theta = (np.mean(np.sin(train_1d), axis=1) * np.linalg.norm(train_1d, axis=1)).reshape(-1, 1)\n",
        "val_theta = (np.mean(np.sin(val_1d), axis=1) * np.linalg.norm(val_1d, axis=1)).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "iOwM7VAQWTwS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Define feature reduction steps [40, 36, 32, ..., 4]\n",
        "feature_steps = list(range(40, 3, -4))  # 10 steps total\n",
        "\n",
        "# Store PCA and clustering models for each step\n",
        "pca_models = []\n",
        "cluster_models = []\n",
        "\n",
        "# === 1. Fit PCA and Clustering Models on Training Data ===\n",
        "for n_features in feature_steps:\n",
        "    # Select subset of features\n",
        "    X_train = train_days[:, :n_features]\n",
        "\n",
        "    # Create and store PCA model (using all components)\n",
        "    pca = PCA(n_components=X_train.shape[1])\n",
        "    pca_1d = pca.fit_transform(X_train)\n",
        "    pca_models.append(pca)\n",
        "\n",
        "    # Create theta feature combining:\n",
        "    # - Mean of sine-transformed components (periodic patterns)\n",
        "    # - Vector magnitude (Euclidean norm)\n",
        "    pca_theta = (np.mean(np.sin(pca_1d), axis=1) * np.linalg.norm(pca_1d, axis=1)).reshape(-1, 1)\n",
        "\n",
        "    # Determine number of clusters (9 for first matrix, 10 for others)\n",
        "    n_clusters = 9 if n_features == 40 else 10\n",
        "\n",
        "    # Train and store KMeans model\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "    kmeans.fit(pca_theta)\n",
        "    cluster_models.append(kmeans)\n",
        "\n",
        "# === 2. Transform All Datasets ===\n",
        "def generate_clusters(data, pca_models, cluster_models, feature_steps):\n",
        "    \"\"\"\n",
        "    Convert data into cluster label matrix (n_samples, 10)\n",
        "\n",
        "    Args:\n",
        "        data: Input data matrix\n",
        "        pca_models: List of trained PCA models\n",
        "        cluster_models: List of trained KMeans models\n",
        "        feature_steps: List of feature dimensions used\n",
        "\n",
        "    Returns:\n",
        "        Matrix of cluster labels with shape (n_samples, n_steps)\n",
        "    \"\"\"\n",
        "    clusters = np.zeros((data.shape[0], len(cluster_models)), dtype=int)\n",
        "\n",
        "    # Precompute cluster label offsets to ensure unique labels across steps\n",
        "    offsets = [0] * len(feature_steps)\n",
        "    for i in range(1, len(feature_steps)):\n",
        "        # Offset determined by number of clusters in previous step\n",
        "        prev_n_clusters = 9 if feature_steps[i-1] == 40 else 10\n",
        "        offsets[i] = offsets[i-1] + prev_n_clusters\n",
        "\n",
        "    # Generate cluster labels for each feature reduction step\n",
        "    for i, (pca, model) in enumerate(zip(pca_models, cluster_models)):\n",
        "        # Use corresponding number of features\n",
        "        X = data[:, :feature_steps[i]]\n",
        "\n",
        "        # Transform using pre-trained PCA model\n",
        "        pca_1d = pca.transform(X)\n",
        "        pca_theta = (np.mean(np.sin(pca_1d), axis=1) * np.linalg.norm(pca_1d, axis=1)).reshape(-1, 1)\n",
        "\n",
        "        # Apply offset to ensure unique cluster labels across steps\n",
        "        if i == 0:\n",
        "            clusters[:, i] = model.predict(pca_theta)\n",
        "        else:\n",
        "            clusters[:, i] = model.predict(pca_theta) + offsets[i]\n",
        "\n",
        "    return clusters\n",
        "\n",
        "# Generate cluster representations for all datasets\n",
        "train_clusters = generate_clusters(train_days, pca_models, cluster_models, feature_steps)\n",
        "val_clusters = generate_clusters(val_days, pca_models, cluster_models, feature_steps)\n",
        "\n",
        "# Verify output shapes\n",
        "print(\"Train clusters shape:\", train_clusters.shape)\n",
        "print(\"Validation clusters shape:\", val_clusters.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf6mlC5lWlPh",
        "outputId": "a0e835d5-16e9-4202-882c-6c9228bc03ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train clusters shape: (4827, 10)\n",
            "Validation clusters shape: (467, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_clusters[:,::-1]\n",
        "val_x =  val_clusters[:,::-1]\n",
        "\n",
        "y_train = train_x[:,-1]\n",
        "y_val = val_x[:,-1]"
      ],
      "metadata": {
        "id": "MuuA659dXKe8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# 1. Analyze original class distribution (keep exactly as is)\n",
        "train_counts = Counter(y_train)\n",
        "print(\"Original training set class distribution:\", train_counts)\n",
        "\n",
        "# 2. Set target sample count - using median (keep exactly as is)\n",
        "target_counts = int(np.median(list(train_counts.values())))\n",
        "print(\"Target samples per class:\", target_counts)\n",
        "\n",
        "# 3. Define sampling strategies (modified: split oversampling approach)\n",
        "# Use SMOTE for normal minority classes\n",
        "smote_strategy = {k: target_counts for k in train_counts\n",
        "                 if 2 <= train_counts[k] < target_counts}  # Need at least 2 samples for SMOTE\n",
        "# Use random duplication for extreme minority classes\n",
        "random_strategy = {k: target_counts for k in train_counts\n",
        "                  if 0 < train_counts[k] < 2}  # Handle classes with only 1 sample\n",
        "# Under sampling strategy for majority classes\n",
        "under_strategy = {k: target_counts for k in train_counts\n",
        "                 if train_counts[k] > target_counts}  # Keep as is\n",
        "\n",
        "# 4. Create sampling pipeline (modified: multi-stage processing)\n",
        "sampling_pipeline = Pipeline([\n",
        "    # Stage 1: Handle extreme minority classes (classes with only 1 sample)\n",
        "    ('random_over', RandomOverSampler(\n",
        "        sampling_strategy=random_strategy,\n",
        "        random_state=42\n",
        "    )),\n",
        "    # Stage 2: Normal SMOTE oversampling\n",
        "    ('smote', SMOTE(\n",
        "        sampling_strategy=smote_strategy,\n",
        "        k_neighbors=2,  # Ensured each class has ≥2 samples\n",
        "        random_state=42\n",
        "    )),\n",
        "    # Stage 3: Under sampling for majority classes\n",
        "    ('under', RandomUnderSampler(\n",
        "        sampling_strategy=under_strategy,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 5. Execute resampling (keep exactly as is)\n",
        "try:\n",
        "    train_x_resampled, y_train_resampled = sampling_pipeline.fit_resample(train_x, y_train)\n",
        "\n",
        "    # 6. Check results (keep exactly as is)\n",
        "    resampled_counts = Counter(y_train_resampled)\n",
        "    print(\"Resampled training set class distribution:\", resampled_counts)\n",
        "\n",
        "except ValueError as e:\n",
        "    print(f\"Resampling failed: {e}\")\n",
        "    print(\"Recommendation: Check if any classes still have insufficient samples after preprocessing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9OPNDCPXYai",
        "outputId": "757fb580-bf49-41fb-eed1-026b06111aa7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original training set class distribution: Counter({np.int64(6): 2257, np.int64(0): 956, np.int64(1): 706, np.int64(8): 385, np.int64(7): 192, np.int64(4): 166, np.int64(5): 83, np.int64(3): 58, np.int64(2): 24})\n",
            "Target samples per class: 192\n",
            "Resampled training set class distribution: Counter({np.int64(0): 192, np.int64(1): 192, np.int64(2): 192, np.int64(3): 192, np.int64(4): 192, np.int64(5): 192, np.int64(6): 192, np.int64(7): 192, np.int64(8): 192})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Cluster assignment matrices from previous processing steps\n",
        "# Shape: [n_samples, 10] where each row contains 10 consecutive cluster assignments\n",
        "X_train = train_x_resampled  # Training set cluster assignments\n",
        "X_val = val_x                # Validation set cluster assignments\n",
        "\n",
        "# Flatten matrices into 1D sequences of cluster IDs\n",
        "# This converts the 2D structure into continuous sequences suitable for embedding\n",
        "train_flattened = X_train.ravel()  # Result shape: [n_samples * 10]\n",
        "val_flattened = X_val.ravel()      # Result shape: [n_samples * 10]\n",
        "\n",
        "# Convert to PyTorch tensors for embedding layer input\n",
        "# Using LongTensor since these represent categorical cluster IDs (discrete values)\n",
        "train_data = torch.LongTensor(train_flattened)\n",
        "val_data = torch.LongTensor(val_flattened)\n",
        "\n",
        "# Verification and debugging output\n",
        "print(f\"Training data tensor shape: {train_data.shape}\")  # Expected: [total_windows]\n",
        "print(f\"Validation data tensor shape: {val_data.shape}\")  # Expected: [total_windows]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ3sEVqsXbRY",
        "outputId": "63166555-d878-4d02-cb0e-235c8155b2bf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data tensor shape: torch.Size([17280])\n",
            "Validation data tensor shape: torch.Size([4670])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 4  # How many batches per training step\n",
        "context_length = 9  # Length of the token chunk each batch\n",
        "d_model = 64  # The size of our model token embeddings\n",
        "num_blocks = 8  # Number of transformer blocks\n",
        "num_heads = 4  # Number of heads in Multi-head attention\n",
        "learning_rate = 1e-3  # 0.001\n",
        "dropout = 0.1  # Dropout rate\n",
        "max_iters = 2000  # Total of training iterations <- Change this to smaller number for testing\n",
        "eval_interval = 50  # How often to evaluate\n",
        "eval_iters = 20\n",
        "max_token_value = train_clusters.max() + 1  # Number of iterations to average for evaluation\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Use GPU if it's available.\n",
        "TORCH_SEED = 1337\n",
        "torch.manual_seed(TORCH_SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3_jzxBMX9Z_",
        "outputId": "6a3678a6-39d4-424f-b2df-7f2bd50718be"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7be1252e2310>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import math\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "# Define Feed Forward Network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.dropout = dropout\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(in_features=self.d_model, out_features=self.d_model * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=self.d_model * 4, out_features=self.d_model),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.ffn(x)\n",
        "\n",
        "# Define Scaled Dot Product Attention\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, head_size: int):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.head_size = head_size\n",
        "        self.context_length = context_length\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.key_layer = nn.Linear(in_features=self.d_model, out_features=self.head_size, bias=False)\n",
        "        self.query_layer = nn.Linear(in_features=self.d_model, out_features=self.head_size, bias=False)\n",
        "        self.value_layer = nn.Linear(in_features=self.d_model, out_features=self.head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(\n",
        "            torch.ones((self.context_length, self.context_length))))  # Lower triangular mask\n",
        "        self.dropout_layer = nn.Dropout(self.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape  # Batch size, Time steps(current context_length), Channels(dimensions)\n",
        "        assert T <= self.context_length\n",
        "        assert C == self.d_model\n",
        "        q = self.query_layer(x)\n",
        "        k = self.key_layer(x)\n",
        "        v = self.value_layer(x)\n",
        "\n",
        "        # Scaled dot product attention: Q @ K^T / sqrt(d_k)\n",
        "        weights = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        # Apply masked attention\n",
        "        weights = weights.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        weights = F.softmax(input=weights, dim=-1)\n",
        "        weights = self.dropout_layer(weights)\n",
        "\n",
        "        # Apply dot product attention: weights @ V\n",
        "        out = weights @ v\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, head_size: int):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_size = head_size\n",
        "        self.d_model = d_model\n",
        "        self.context_length = context_length\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.heads = nn.ModuleList([Attention(head_size=self.head_size) for _ in range(self.num_heads)])\n",
        "        self.projection_layer = nn.Linear(in_features=self.d_model, out_features=self.d_model)\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.projection_layer(out)\n",
        "        out = self.dropout_layer(out)\n",
        "        return out\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads: int):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.context_length = context_length\n",
        "        self.head_size = d_model // num_heads  # head size should be divisible by d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.multi_head_attention_layer = MultiHeadAttention(head_size=self.head_size)\n",
        "        self.feed_forward_layer = FeedForward()\n",
        "        self.layer_norm_1 = nn.LayerNorm(normalized_shape=self.d_model)\n",
        "        self.layer_norm_2 = nn.LayerNorm(normalized_shape=self.d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Note: The order of the operations is different from the original Transformer paper\n",
        "        # The order here is: LayerNorm -> Multi-head attention -> LayerNorm -> Feed forward\n",
        "        x = x + self.multi_head_attention_layer(self.layer_norm_1(x))  # Residual connection\n",
        "        x = x + self.feed_forward_layer(self.layer_norm_2(x))  # Residual connection\n",
        "        return x\n",
        "\n",
        "class TransformerLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.context_length = context_length\n",
        "        self.num_heads = num_heads\n",
        "        self.num_blocks = num_blocks\n",
        "        self.dropout = dropout\n",
        "        self.max_token_value = max_token_value\n",
        "        # Set up token embedding look-up table\n",
        "        self.token_embedding_lookup_table = nn.Embedding(num_embeddings=self.max_token_value, embedding_dim=self.d_model)\n",
        "\n",
        "        # Run all the transformer blocks\n",
        "        # Different from original paper, here we add a final layer norm after all the blocks\n",
        "        self.transformer_blocks = nn.Sequential(*(\n",
        "                [TransformerBlock(num_heads=self.num_heads) for _ in range(self.num_blocks)] +\n",
        "                [nn.LayerNorm(self.d_model)]\n",
        "        ))\n",
        "        self.language_model_out_linear_layer = nn.Linear(in_features=self.d_model, out_features=self.max_token_value)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        \"\"\"\n",
        "        # Set up position embedding look-up table\n",
        "        # following the same approach as the original Transformer paper (Sine and Cosine functions)\n",
        "        \"\"\"\n",
        "        position_encoding_lookup_table = torch.zeros(self.context_length, self.d_model)\n",
        "        position = torch.arange(0, self.context_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * (-math.log(10000.0) / self.d_model))\n",
        "        position_encoding_lookup_table[:, 0::2] = torch.sin(position * div_term)\n",
        "        position_encoding_lookup_table[:, 1::2] = torch.cos(position * div_term)\n",
        "        # change position_encoding_lookup_table from (context_length, d_model) to (T, d_model)\n",
        "        position_embedding = position_encoding_lookup_table[:T, :].to(device)\n",
        "        x = self.token_embedding_lookup_table(idx) + position_embedding\n",
        "        x = self.transformer_blocks(x)\n",
        "        # The \"logits\" are the output values of our model before applying softmax\n",
        "        logits = self.language_model_out_linear_layer(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            B, T, C = logits.shape\n",
        "            logits_reshaped = logits.view(B * T, C)\n",
        "            targets_reshaped = targets.view(B * T)\n",
        "            loss = F.cross_entropy(input=logits_reshaped, target=targets_reshaped)\n",
        "        else:\n",
        "            loss = None\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "\n",
        "        for _ in range(max_new_tokens):\n",
        "            # Crop idx to the max size of positional embeddings table\n",
        "            idx_crop = idx[:, -self.context_length:]\n",
        "\n",
        "            # Get predictions\n",
        "            logits, _ = self(idx_crop)  # logits: (B, T, C)\n",
        "\n",
        "            # Get the last time step logits\n",
        "            logits_last_timestep = logits[:, -1, :]  # Shape: (B, C)\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = F.softmax(input=logits_last_timestep, dim=-1)\n",
        "\n",
        "            # Select the most probable index for each sample in the batch\n",
        "            idx_next = torch.argmax(probs, dim=-1, keepdim=True)  # Shape: (B, 1)\n",
        "\n",
        "            # Append the sampled indices to idx\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # Shape: (B, T+1)\n",
        "\n",
        "        return idx"
      ],
      "metadata": {
        "id": "CpcqR-09X_zE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = TransformerLanguageModel()\n",
        "model = model.to(device)\n",
        "\n",
        "# Get input embedding batch\n",
        "def get_batch(split: str):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    idxs = torch.randint(low=0, high=np.rint((len(data)/(context_length+1))- 1).astype(np.int64), size=(batch_size,))*(context_length+1)\n",
        "    x = torch.stack([data[idx:idx + context_length ] for idx in idxs]).to(device)\n",
        "    y = torch.stack([data[idx +1:idx + context_length+1] for idx in idxs]).to(device)\n",
        "    return x, y\n",
        "\n",
        "# Calculate loss\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'valid']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            x_batch, y_batch = get_batch(split)\n",
        "            logits, loss = model(x_batch, y_batch)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "KsB_UKbXYBxd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "# Use AdamW optimizer\n",
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate)\n",
        "tracked_losses = list()\n",
        "\n",
        "# Early stopping parameters\n",
        "best_val_loss = float('inf')\n",
        "best_model_state = None\n",
        "patience = 300  # Number of evaluations to wait before stopping\n",
        "patience_counter = 0\n",
        "early_stop = False\n",
        "\n",
        "for step in range(max_iters):\n",
        "    if step % eval_iters == 0 or step == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        tracked_losses.append(losses)\n",
        "        print('Step:', step, 'Training Loss:', round(losses['train'].item(), 3),\n",
        "              'Validation Loss:', round(losses['valid'].item(), 3))\n",
        "\n",
        "        # Early stopping check\n",
        "        current_val_loss = losses['valid'].item()\n",
        "        if current_val_loss < best_val_loss:\n",
        "            best_val_loss = current_val_loss\n",
        "            best_model_state = copy.deepcopy(model.state_dict()) # Save best model state\n",
        "            patience_counter = 0  # Reset patience counter\n",
        "            print(f\"New best validation loss: {best_val_loss:.4f}, saving model...\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            #print(f\"No improvement in validation loss for {patience_counter}/{patience} evaluations\")\n",
        "            if patience_counter >= patience:\n",
        "                early_stop = True\n",
        "                print(f\"Early stopping triggered at step {step}\")\n",
        "                break\n",
        "\n",
        "    if early_stop:\n",
        "        break\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Load the best model weights at the end\n",
        "if best_model_state is not None:\n",
        "    model.load_state_dict(best_model_state)\n",
        "    print(\"Loaded best model weights based on validation loss\")\n",
        "\n",
        "print(\"Training completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGyM-rLRYEAW",
        "outputId": "8ed77bdc-e67c-4ca8-c391-6b46fc146c97"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0 Training Loss: 4.642 Validation Loss: 4.611\n",
            "New best validation loss: 4.6112, saving model...\n",
            "Step: 20 Training Loss: 3.027 Validation Loss: 2.339\n",
            "New best validation loss: 2.3393, saving model...\n",
            "Step: 40 Training Loss: 2.133 Validation Loss: 1.567\n",
            "New best validation loss: 1.5667, saving model...\n",
            "Step: 60 Training Loss: 1.762 Validation Loss: 1.147\n",
            "New best validation loss: 1.1472, saving model...\n",
            "Step: 80 Training Loss: 1.472 Validation Loss: 0.849\n",
            "New best validation loss: 0.8485, saving model...\n",
            "Step: 100 Training Loss: 1.291 Validation Loss: 0.699\n",
            "New best validation loss: 0.6987, saving model...\n",
            "Step: 120 Training Loss: 1.159 Validation Loss: 0.591\n",
            "New best validation loss: 0.5912, saving model...\n",
            "Step: 140 Training Loss: 1.114 Validation Loss: 0.502\n",
            "New best validation loss: 0.5020, saving model...\n",
            "Step: 160 Training Loss: 1.07 Validation Loss: 0.464\n",
            "New best validation loss: 0.4637, saving model...\n",
            "Step: 180 Training Loss: 0.844 Validation Loss: 0.594\n",
            "Step: 200 Training Loss: 0.812 Validation Loss: 0.471\n",
            "Step: 220 Training Loss: 0.854 Validation Loss: 0.326\n",
            "New best validation loss: 0.3258, saving model...\n",
            "Step: 240 Training Loss: 0.956 Validation Loss: 0.391\n",
            "Step: 260 Training Loss: 0.865 Validation Loss: 0.377\n",
            "Step: 280 Training Loss: 0.833 Validation Loss: 0.355\n",
            "Step: 300 Training Loss: 0.635 Validation Loss: 0.402\n",
            "Step: 320 Training Loss: 0.788 Validation Loss: 0.428\n",
            "Step: 340 Training Loss: 0.797 Validation Loss: 0.382\n",
            "Step: 360 Training Loss: 0.762 Validation Loss: 0.427\n",
            "Step: 380 Training Loss: 0.679 Validation Loss: 0.345\n",
            "Step: 400 Training Loss: 0.668 Validation Loss: 0.362\n",
            "Step: 420 Training Loss: 0.622 Validation Loss: 0.417\n",
            "Step: 440 Training Loss: 0.691 Validation Loss: 0.321\n",
            "New best validation loss: 0.3209, saving model...\n",
            "Step: 460 Training Loss: 0.611 Validation Loss: 0.412\n",
            "Step: 480 Training Loss: 0.711 Validation Loss: 0.368\n",
            "Step: 500 Training Loss: 0.783 Validation Loss: 0.419\n",
            "Step: 520 Training Loss: 0.706 Validation Loss: 0.406\n",
            "Step: 540 Training Loss: 0.647 Validation Loss: 0.38\n",
            "Step: 560 Training Loss: 0.73 Validation Loss: 0.266\n",
            "New best validation loss: 0.2662, saving model...\n",
            "Step: 580 Training Loss: 0.667 Validation Loss: 0.385\n",
            "Step: 600 Training Loss: 0.728 Validation Loss: 0.392\n",
            "Step: 620 Training Loss: 0.682 Validation Loss: 0.34\n",
            "Step: 640 Training Loss: 0.634 Validation Loss: 0.375\n",
            "Step: 660 Training Loss: 0.684 Validation Loss: 0.398\n",
            "Step: 680 Training Loss: 0.63 Validation Loss: 0.314\n",
            "Step: 700 Training Loss: 0.604 Validation Loss: 0.296\n",
            "Step: 720 Training Loss: 0.743 Validation Loss: 0.325\n",
            "Step: 740 Training Loss: 0.62 Validation Loss: 0.374\n",
            "Step: 760 Training Loss: 0.63 Validation Loss: 0.298\n",
            "Step: 780 Training Loss: 0.699 Validation Loss: 0.34\n",
            "Step: 800 Training Loss: 0.656 Validation Loss: 0.322\n",
            "Step: 820 Training Loss: 0.673 Validation Loss: 0.344\n",
            "Step: 840 Training Loss: 0.746 Validation Loss: 0.365\n",
            "Step: 860 Training Loss: 0.636 Validation Loss: 0.48\n",
            "Step: 880 Training Loss: 0.587 Validation Loss: 0.367\n",
            "Step: 900 Training Loss: 0.683 Validation Loss: 0.408\n",
            "Step: 920 Training Loss: 0.661 Validation Loss: 0.331\n",
            "Step: 940 Training Loss: 0.661 Validation Loss: 0.44\n",
            "Step: 960 Training Loss: 0.632 Validation Loss: 0.339\n",
            "Step: 980 Training Loss: 0.615 Validation Loss: 0.359\n",
            "Step: 1000 Training Loss: 0.655 Validation Loss: 0.296\n",
            "Step: 1020 Training Loss: 0.653 Validation Loss: 0.384\n",
            "Step: 1040 Training Loss: 0.65 Validation Loss: 0.315\n",
            "Step: 1060 Training Loss: 0.588 Validation Loss: 0.327\n",
            "Step: 1080 Training Loss: 0.574 Validation Loss: 0.362\n",
            "Step: 1100 Training Loss: 0.562 Validation Loss: 0.318\n",
            "Step: 1120 Training Loss: 0.586 Validation Loss: 0.365\n",
            "Step: 1140 Training Loss: 0.54 Validation Loss: 0.32\n",
            "Step: 1160 Training Loss: 0.572 Validation Loss: 0.34\n",
            "Step: 1180 Training Loss: 0.586 Validation Loss: 0.267\n",
            "Step: 1200 Training Loss: 0.645 Validation Loss: 0.328\n",
            "Step: 1220 Training Loss: 0.618 Validation Loss: 0.298\n",
            "Step: 1240 Training Loss: 0.649 Validation Loss: 0.283\n",
            "Step: 1260 Training Loss: 0.516 Validation Loss: 0.264\n",
            "New best validation loss: 0.2642, saving model...\n",
            "Step: 1280 Training Loss: 0.597 Validation Loss: 0.305\n",
            "Step: 1300 Training Loss: 0.567 Validation Loss: 0.347\n",
            "Step: 1320 Training Loss: 0.489 Validation Loss: 0.286\n",
            "Step: 1340 Training Loss: 0.533 Validation Loss: 0.334\n",
            "Step: 1360 Training Loss: 0.622 Validation Loss: 0.343\n",
            "Step: 1380 Training Loss: 0.544 Validation Loss: 0.349\n",
            "Step: 1400 Training Loss: 0.564 Validation Loss: 0.383\n",
            "Step: 1420 Training Loss: 0.582 Validation Loss: 0.28\n",
            "Step: 1440 Training Loss: 0.578 Validation Loss: 0.261\n",
            "New best validation loss: 0.2606, saving model...\n",
            "Step: 1460 Training Loss: 0.605 Validation Loss: 0.413\n",
            "Step: 1480 Training Loss: 0.519 Validation Loss: 0.308\n",
            "Step: 1500 Training Loss: 0.669 Validation Loss: 0.296\n",
            "Step: 1520 Training Loss: 0.561 Validation Loss: 0.296\n",
            "Step: 1540 Training Loss: 0.651 Validation Loss: 0.356\n",
            "Step: 1560 Training Loss: 0.589 Validation Loss: 0.31\n",
            "Step: 1580 Training Loss: 0.644 Validation Loss: 0.359\n",
            "Step: 1600 Training Loss: 0.71 Validation Loss: 0.307\n",
            "Step: 1620 Training Loss: 0.543 Validation Loss: 0.332\n",
            "Step: 1640 Training Loss: 0.609 Validation Loss: 0.283\n",
            "Step: 1660 Training Loss: 0.54 Validation Loss: 0.34\n",
            "Step: 1680 Training Loss: 0.594 Validation Loss: 0.286\n",
            "Step: 1700 Training Loss: 0.608 Validation Loss: 0.306\n",
            "Step: 1720 Training Loss: 0.535 Validation Loss: 0.366\n",
            "Step: 1740 Training Loss: 0.578 Validation Loss: 0.328\n",
            "Step: 1760 Training Loss: 0.63 Validation Loss: 0.28\n",
            "Step: 1780 Training Loss: 0.597 Validation Loss: 0.319\n",
            "Step: 1800 Training Loss: 0.514 Validation Loss: 0.318\n",
            "Step: 1820 Training Loss: 0.652 Validation Loss: 0.252\n",
            "New best validation loss: 0.2524, saving model...\n",
            "Step: 1840 Training Loss: 0.605 Validation Loss: 0.287\n",
            "Step: 1860 Training Loss: 0.562 Validation Loss: 0.33\n",
            "Step: 1880 Training Loss: 0.586 Validation Loss: 0.282\n",
            "Step: 1900 Training Loss: 0.552 Validation Loss: 0.33\n",
            "Step: 1920 Training Loss: 0.549 Validation Loss: 0.342\n",
            "Step: 1940 Training Loss: 0.642 Validation Loss: 0.371\n",
            "Step: 1960 Training Loss: 0.57 Validation Loss: 0.293\n",
            "Step: 1980 Training Loss: 0.652 Validation Loss: 0.268\n",
            "Step: 1999 Training Loss: 0.633 Validation Loss: 0.291\n",
            "Loaded best model weights based on validation loss\n",
            "Training completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "alternative_n = cluster_models[0].cluster_centers_.shape[0]\n",
        "# 1. Get cluster centers and sort by closing price\n",
        "cluster_centers = cluster_models[0].cluster_centers_\n",
        "closing_prices = cluster_centers[:, -1]\n",
        "sorted_indices = np.argsort(closing_prices)\n",
        "\n",
        "# 2. Count class 0 and 1 in each cluster\n",
        "class0_counts = np.zeros(alternative_n)\n",
        "class1_counts = np.zeros(alternative_n)\n",
        "\n",
        "for cluster in range(alternative_n ):\n",
        "    mask = (train_clusters[:,0]  == cluster)\n",
        "    #mask = (train_clusters[:,-1] - y_train.min() == cluster)\n",
        "    #mask = (train_clusters.reshape(-1, 10)[:,-1] == cluster)\n",
        "    class0_counts[cluster] = np.sum(train_labels[mask] == 0)\n",
        "    class1_counts[cluster] = np.sum(train_labels[mask] == 1)\n",
        "\n",
        "# 3. Calculate Class 1 ratio (Class 1 / Total)\n",
        "total_counts = class0_counts + class1_counts\n",
        "class1_ratios = np.divide(class1_counts, total_counts, out=np.zeros_like(class1_counts), where=(total_counts != 0))\n",
        "\n",
        "# 4. Find top 4 clusters with highest Class 1 ratio\n",
        "top4_ratio_indices = np.argsort(class1_ratios)[::-1][:6]\n",
        "bottom4_ratio_indices = np.argsort(class1_ratios)[::-1][-3:]\n",
        "print(\"Top 4 Clusters with Highest Class 1 Ratio:\")\n",
        "for i, cluster_idx in enumerate(top4_ratio_indices, 1):\n",
        "    ratio = class1_ratios[cluster_idx]\n",
        "    print(f\"{i}. Cluster {cluster_idx} (Ratio: {ratio:.2f}) - \"\n",
        "          f\"Class 0: {int(class0_counts[cluster_idx])}, \"\n",
        "          f\"Class 1: {int(class1_counts[cluster_idx])}, \"\n",
        "          f\"Closing Price: {closing_prices[cluster_idx]:.2f}\")\n",
        "\n",
        "# 5. Prepare data for plotting (sorted by closing price)\n",
        "sorted_class0 = class0_counts[sorted_indices]\n",
        "sorted_class1 = class1_counts[sorted_indices]\n",
        "sorted_ratios = class1_ratios[sorted_indices]\n",
        "\n",
        "# 6. Create stacked bar plot (highlight top 4 clusters)\n",
        "plt.figure(figsize=(14, 7))\n",
        "bar_width = 0.8\n",
        "colors_class0 = ['tomato'] * alternative_n\n",
        "colors_class1 = ['royalblue'] * alternative_n\n",
        "\n",
        "# Highlight top 4 clusters in the plot (if they appear in sorted order)\n",
        "for i, cluster_idx in enumerate(sorted_indices):\n",
        "    if cluster_idx in top4_ratio_indices:\n",
        "        colors_class0[i] = 'darkred'\n",
        "        colors_class1[i] = 'darkblue'\n",
        "\n",
        "# Plot stacked bars\n",
        "p0 = plt.bar(range(alternative_n), sorted_class0, color=colors_class0,\n",
        "             edgecolor='white', width=bar_width, label='Class 0')\n",
        "p1 = plt.bar(range(alternative_n), sorted_class1, bottom=sorted_class0,\n",
        "             color=colors_class1, edgecolor='white', width=bar_width, label='Class 1')\n",
        "\n",
        "# 7. Customize the plot\n",
        "plt.xlabel('Cluster (ordered by closing price from low to high)')\n",
        "plt.ylabel('Number of samples')\n",
        "plt.title('Class Distribution Across Clusters (Top 4 High-Ratio Clusters Highlighted)')\n",
        "\n",
        "# Add cluster index and closing price to x-axis labels\n",
        "labels = [f'{i}({closing_prices[i]:.2f})' for i in sorted_indices]\n",
        "plt.xticks(range(alternative_n), labels, rotation=45)\n",
        "\n",
        "# Add total count labels on bars\n",
        "for rect0, rect1 in zip(p0, p1):\n",
        "    height0 = rect0.get_height()\n",
        "    height1 = rect1.get_height()\n",
        "    total = height0 + height1\n",
        "    if total > 0:\n",
        "        plt.text(rect0.get_x() + rect0.get_width()/2., total + 0.5,\n",
        "                f'{int(total)}', ha='center', va='bottom')\n",
        "\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "jVDXSzjWYH0_",
        "outputId": "cb8af944-ada2-42a0-c2c5-8d41be6a4c38"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 4 Clusters with Highest Class 1 Ratio:\n",
            "1. Cluster 2 (Ratio: 0.79) - Class 0: 5, Class 1: 19, Closing Price: 0.02\n",
            "2. Cluster 4 (Ratio: 0.58) - Class 0: 70, Class 1: 96, Closing Price: 0.00\n",
            "3. Cluster 1 (Ratio: 0.56) - Class 0: 310, Class 1: 396, Closing Price: -0.00\n",
            "4. Cluster 7 (Ratio: 0.56) - Class 0: 85, Class 1: 107, Closing Price: -0.00\n",
            "5. Cluster 5 (Ratio: 0.53) - Class 0: 39, Class 1: 44, Closing Price: 0.01\n",
            "6. Cluster 6 (Ratio: 0.51) - Class 0: 1107, Class 1: 1150, Closing Price: -0.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAKyCAYAAACuWPzHAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAA1gdJREFUeJzs3XmcjfX7x/H3mTOLmTGLZRaTbQZlly1kS5bBpISKUJYoRta0KVtRkYqStKGyFCLxtVNKkm2SJcIwMcZuhsFs5/794Td3jplhDjPmMK/n4zGPnOv+3Pd9Xee+zznTNff53BbDMAwBAAAAAAAAAJyCS14nAAAAAAAAAAD4D01bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAMAdo3Tp0urWrVtep3HTRo4cKYvFckv29cADD+iBBx4wH//000+yWCyaN2/eLdl/t27dVLp06VuyL2SfxWLRyJEj8zqNPNG3b181b948r9PIczfz2uzWrZsKFiyYswnlovT3vZ9++ilP9n/1+zAydzPP0wMPPKDKlStfd9zBgwdlsVg0ffp0M3Yzn8np6548efKG1s8JmZ3fHTt21OOPP55nOQEAsoemLQDA6e3fv1/PPvuswsLCVKBAAfn6+qp+/fqaOHGiLl68mNfpXdP06dNlsVjMnwIFCigkJETh4eGaNGmSzp07lyP7iY2N1ciRIxUVFZUj28tJzpybJO3evds8NmfPns3rdHJVVFSUunTpohIlSsjDw0OFCxdWs2bNNG3aNKWlpd2SHJz5fIiOjtbnn3+uV199VdLlRs+Vr9+sfm51g/vs2bMKDAzM9h9Y0htR7777bqbLnaGxdKX0fNN/XFxcVLhwYbVq1UobNmy44e1+/PHHds243Hbs2DG98MILKl++vLy8vOTt7a2aNWvqzTffvKXvNWPHjtXChQtv2f6y43p/ILzdGv854VYep5deeknz58/Xn3/+eUv2BwC4Ma55nQAAANeyZMkSPfbYY/Lw8NBTTz2lypUrKzk5Wb/++quGDh2qnTt36tNPP83rNK9r9OjRCg0NVUpKiuLi4vTTTz9p4MCBeu+997Ro0SJVrVrVHPvaa6/p5Zdfdmj7sbGxGjVqlEqXLq1777032+utWLHCof3ciGvl9tlnn8lms+V6DtfyzTffKDg4WGfOnNG8efP0zDPP5Gk+ueXzzz/Xc889p6CgIHXt2lXlypXTuXPntHr1avXs2VNHjx41m5W56UbP1Vth4sSJCg0NVZMmTSRJw4YNszsfNm3apEmTJunVV19VhQoVzPiVr99bYfjw4bpw4UKu7sMZXpudOnVS69atlZaWpr179+rjjz9WkyZNtGnTJlWpUsXh7X388ccqWrRohm9kNGrUSBcvXpS7u3sOZX75XGndurXOnz+vLl26qGbNmpKkzZs36+2339a6detuyfuvdLkZ2KFDB7Vt2/aW7C+33Krn62o38pl8I27lcapevbpq1aqlCRMm6Kuvvsr1/QEAbgxNWwCA04qOjlbHjh1VqlQprVmzRsWKFTOXRUZGat++fVqyZEkeZph9rVq1Uq1atczHr7zyitasWaOHHnpIDz/8sHbv3i1PT09Jkqurq1xdc/cj+sKFC/Ly8srRJsWNcHNzy9P9G4ahWbNm6cknn1R0dLRmzpyZY01bm82m5ORkFShQIEe2dzN+//13Pffcc6pXr57+97//ycfHx1w2cOBAbd68WTt27MjDDG9eYmKivL29b3j9lJQUzZw5U88995wZu3qahAIFCmjSpElq3rx5nn2dfceOHZoyZYqGDx+u4cOH59p+8vq1KUk1atRQly5dzMcNGzZUq1atNGXKFH388cc5th8XF5ccfZ2ePXtWjz76qKxWq7Zt26by5cvbLR8zZow+++yzHNtfXrh06ZLc3d3l4nLrvriZV59Xt+IzOS88/vjjGjFihD7++ON8d1UzANwumB4BAOC0xo0bp/Pnz+uLL76wa9imK1u2rAYMGJDl+qdPn9YLL7ygKlWqqGDBgvL19VWrVq0y/Trghx9+qEqVKsnLy0uFChVSrVq1NGvWLHP5uXPnNHDgQJUuXVoeHh4KDAxU8+bNtXXr1huu78EHH9Trr7+uQ4cO6ZtvvjHjmc2ft3LlSjVo0ED+/v4qWLCg7rnnHvOqyJ9++km1a9eWJHXv3t38SnH614DT5/LbsmWLGjVqJC8vL7uvf2fWfEpLS9Orr76q4OBgeXt76+GHH9a///5rNyarOYSv3Ob1csts3szExEQNGTLE/Ar/Pffco3fffVeGYdiNs1gs6tevnxYuXKjKlSvLw8NDlSpV0rJlyzJ/wjOxfv16HTx4UB07dlTHjh21bt06HT58OMM4m82miRMnqkqVKipQoIACAgLUsmVLbd68OUM+M2fOVKVKleTh4WHmsm3bNrVq1Uq+vr4qWLCgmjZtqt9//91uHykpKRo1apTKlSunAgUKqEiRImrQoIFWrlxpjomLi1P37t1VvHhxeXh4qFixYnrkkUd08ODBa9Y5atQoWSwWzZw5065hm65WrVrXnA86q/lNc/pclaSNGzeqZcuW8vPzk5eXlxo3bqz169dnut9du3bpySefVKFChdSgQYObeo5+/fVXnTx5Us2aNbvmuMx8/PHH5jEPCQlRZGRkhq+/X/k6vP/+++Xp6anQ0FB98sknDu1rwIABevTRR9WwYUOH83REZsf81KlT6tq1q3x9feXv76+nn35af/75Z4ZjmO7IkSNq27atChYsqICAAL3wwgs3NQ1Hes379++3i0+bNk0PPvigAgMD5eHhoYoVK2rKlCl2Y0qXLq2dO3fq559/Ns+7K9+nMpvTdu7cuapZs6Y8PT1VtGhRdenSRUeOHLlunlOnTtWRI0f03nvvZWjYSlJQUJBee+21LNdPn1bn6nM2szz/+ecftW/fXsHBwSpQoICKFy+ujh07Kj4+XtLl96XExETNmDHDrPvK1/qRI0fUo0cPBQUFme+hX375Zab7nTNnjl577TXddddd8vLyUkJCQrbet3JKZp9Xhw4d0sMPPyxvb28FBgZq0KBBWr58eZZzFO/atUtNmjSRl5eX7rrrLo0bN+66+83sfe7ixYvq37+/ihYtKh8fHz388MM6cuRIltOlnD17Vt26dZO/v7/8/PzUvXt3u6vlc+I4SdLhw4fVtm1bu+cjKSkp07qaN2+uxMTEXDlWAICccef9yRAAcMf48ccfFRYWpvvvv/+G1j9w4IAWLlyoxx57TKGhoTp27JimTp2qxo0ba9euXQoJCZF0+WvA/fv3V4cOHTRgwABdunRJ27dv18aNG/Xkk09Kkp577jnNmzdP/fr1U8WKFXXq1Cn9+uuv2r17t2rUqHHDNXbt2lWvvvqqVqxYoV69emU6ZufOnXrooYdUtWpVjR49Wh4eHtq3b5/ZyKpQoYJGjx6t4cOHq3fv3mZj48rn7dSpU2rVqpU6duyoLl26KCgo6Jp5jRkzRhaLRS+99JKOHz+uDz74QM2aNVNUVJR5RXB2ZCe3KxmGoYcfflhr165Vz549de+992r58uUaOnSojhw5ovfff99u/K+//qrvv/9effv2lY+PjyZNmqT27dsrJiZGRYoUuW5+M2fOVJkyZVS7dm1VrlxZXl5emj17toYOHWo3rmfPnpo+fbpatWqlZ555Rqmpqfrll1/0+++/211BvWbNGn333Xfq16+fihYtajaKGjZsKF9fX7344otyc3PT1KlT9cADD+jnn39WnTp1JF1uDLz11lt65plndN999ykhIUGbN2/W1q1bzSs+27dvr507d+r5559X6dKldfz4ca1cuVIxMTFZ3jTqwoULWr16tRo1aqSSJUte9zm5GTd7rq5Zs0atWrVSzZo1NWLECLm4uJgNuV9++UX33Xef3f4ee+wxlStXTmPHjjWb+jfyHEnSb7/9JovFourVqztU88iRIzVq1Cg1a9ZMffr00Z49ezRlyhRt2rRJ69evt7ti9cyZM2rdurUef/xxderUSd9995369Okjd3d39ejR47r7mjt3rn777Tft3r37uk3ozFy4cCHTeWuzM9WCzWZTmzZt9Mcff6hPnz4qX768fvjhBz399NOZjk9LS1N4eLjq1Kmjd999V6tWrdKECRNUpkwZ9enTx+HcJZk1FypUyC4+ZcoUVapUSQ8//LBcXV31448/qm/fvrLZbIqMjJQkffDBB3r++edVsGBBDRs2TJKu+T44ffp0de/eXbVr19Zbb72lY8eOaeLEiVq/fr22bdsmf3//LNddtGiRPD091aFDhxuqM7uSk5MVHh6upKQkPf/88woODtaRI0e0ePFinT17Vn5+fvr666/N95TevXtLksqUKSPp8py7devWNf/gFBAQoKVLl6pnz55KSEjQwIED7fb3xhtvyN3dXS+88IKSkpLk7u6erfetazl37lym52RWjcYrJSYm6sEHH9TRo0c1YMAABQcHa9asWVq7dm2m48+cOaOWLVuqXbt2evzxxzVv3jy99NJLqlKlilq1anXd/V2pW7du+u6779S1a1fVrVtXP//8syIiIrIc//jjjys0NFRvvfWWtm7dqs8//1yBgYF65513JClHjtPFixfVtGlTxcTEqH///goJCdHXX3+tNWvWZJpTxYoV5enpqfXr1+vRRx91qH4AwC1iAADghOLj4w1JxiOPPJLtdUqVKmU8/fTT5uNLly4ZaWlpdmOio6MNDw8PY/To0WbskUceMSpVqnTNbfv5+RmRkZHZziXdtGnTDEnGpk2brrnt6tWrm49HjBhhXPkR/f777xuSjBMnTmS5jU2bNhmSjGnTpmVY1rhxY0OS8cknn2S6rHHjxubjtWvXGpKMu+66y0hISDDj3333nSHJmDhxohm7+vnOapvXyu3pp582SpUqZT5euHChIcl488037cZ16NDBsFgsxr59+8yYJMPd3d0u9ueffxqSjA8//DDDvq6WnJxsFClSxBg2bJgZe/LJJ41q1arZjVuzZo0hyejfv3+GbdhsNrt8XFxcjJ07d9qNadu2reHu7m7s37/fjMXGxho+Pj5Go0aNzFi1atWMiIiILPM9c+aMIckYP378dWu7UvpzMmDAgGyvI8kYMWKE+fjq45QuJ89Vm81mlCtXzggPD7d7Xi9cuGCEhoYazZs3z7DfTp062W3jRp8jwzCMLl26GEWKFLnmmLlz5xqSjLVr1xqGYRjHjx833N3djRYtWti913z00UeGJOPLL780Y+mvwwkTJpixpKQk49577zUCAwON5OTka+77woULRsmSJY1XXnnFMIz/Xqtz5869bm3R0dGGpOv+XHncrj7m8+fPNyQZH3zwgRlLS0szHnzwwQzH8+mnnzYk2b3PGoZhVK9e3ahZs2a28x01apRx4sQJIy4uzvjll1+M2rVrZ1rzhQsXMmwjPDzcCAsLs4tVqlTJ7r0pXfpzmX5ck5OTjcDAQKNy5crGxYsXzXGLFy82JBnDhw+/Zv6FChXK8D5yLVe/Z6Z/bkRHR18zz23btmXrHPD29s70vbpnz55GsWLFjJMnT9rFO3bsaPj5+ZnPa/p+w8LCMjzX13vfykr6Nq/14+3tbbfO1c/ThAkTDEnGwoULzdjFixeN8uXL2z1P6etKMr766iszlpSUZAQHBxvt27c3Y+nn3pXn89Xvc1u2bDEkGQMHDrTLr1u3bhneO9PX7dGjh93YRx99NMP7zc0epw8++MCQZHz33XfmmMTERKNs2bIZno90d999t9GqVasMcQCAc2B6BACAU0pISJCkTL/KnV0eHh7mfHtpaWk6deqU+XXtK6c18Pf31+HDh7Vp06Yst+Xv76+NGzcqNjb2hvPJSsGCBXXu3Llr7luSfvjhhxu+MZCHh4e6d++e7fFPPfWU3XPfoUMHFStWTP/73/9uaP/Z9b///U9Wq1X9+/e3iw8ZMkSGYWjp0qV28WbNmplXI0mXbwjl6+urAwcOXHdfS5cu1alTp9SpUycz1qlTJ/3555/auXOnGZs/f74sFotGjBiRYRtXf2W2cePGqlixovk4LS1NK1asUNu2bRUWFmbGixUrpieffFK//vqrea77+/tr586d+ueffzLN19PTU+7u7vrpp5905syZ69aXLideS9l1M+dqVFSU/vnnHz355JM6deqUTp48qZMnTyoxMVFNmzbVunXrMmzzyvlnpRt/jqTLV6NffQXn9axatUrJyckaOHCg3dyevXr1kq+vb4Y5t11dXfXss8+aj93d3fXss8/q+PHj2rJlyzX39fbbbyslJeWmbhbXu3dvrVy5MsNP165dr7vusmXL5ObmZveNABcXF/NK1sxcfXwaNmyYrddmuhEjRiggIEDBwcFq2LChdu/erQkTJmS4gvXKq//j4+N18uRJNW7cWAcOHDCnCXDE5s2bdfz4cfXt29durtuIiAiVL1/+unOpJyQk3JLXm5+fnyRp+fLlDt+YzjAMzZ8/X23atJFhGObr7eTJkwoPD1d8fHyG6X+efvrpDN+0uN771vUMHz4803OyRYsW11132bJluuuuu/Twww+bsQIFCmT5rZWCBQvazZHs7u6u++67z6FzMn2/ktS3b1+7+PPPP5/lOpm9Fk6dOmW+P2fFkeP0v//9T8WKFbN7fXh5eZlX7mamUKFCmV7pDABwDjRtAQBOydfXV5Ku2cy8HpvNpvfff1/lypWTh4eHihYtqoCAAG3fvt3uf+RfeuklFSxYUPfdd5/KlSunyMjIDHNojhs3Tjt27FCJEiV03333aeTIkQ7/j15Wzp8/f83/wX/iiSdUv359PfPMMwoKClLHjh313XffOdQUu+uuuxy6iUu5cuXsHlssFpUtW/aGvpLtiEOHDikkJCTD81GhQgVz+ZUy+7p/oUKFstWw++abbxQaGmp+hX/fvn0qU6aMvLy8NHPmTHPc/v37FRISosKFC193m6GhoXaPT5w4oQsXLuiee+7JMLZChQqy2WzmXMGjR4/W2bNndffdd6tKlSoaOnSotm/fbo738PDQO++8o6VLlyooKEiNGjXSuHHjFBcXd82ccuK1lF03c66mN32efvppBQQE2P18/vnnSkpKytCAu/r5vtHnKJ1x1bzJ15N+Pl59fN3d3RUWFpbhfA0JCclws7S7775bkq752jp48KDGjx+vMWPG3NQNg8qVK6dmzZpl+LnyDwpZOXTokIoVKyYvLy+7eNmyZTMdnz7385Wufm2eOHFCcXFx5s/58+ftxqc3mX/88UcNGjRIFy9ezHRO3PXr16tZs2by9vaWv7+/AgICzOb2jTRtszquklS+fPkMx/Vqvr6+t+T1FhoaqsGDB+vzzz9X0aJFFR4ersmTJ2er5hMnTujs2bP69NNPM7ze0v/Ad/z48Qz7u9r13reup0qVKpmek5nNY3+1Q4cOqUyZMhn+eJbVOVm8ePEMY7P7eXH1fl1cXDI8H1ntV8r4WZX+B6Lr7duR43To0CGVLVs2Q42ZncfpDMPIMB4A4Dxo2gIAnJKvr69CQkJu6o72Y8eO1eDBg9WoUSN98803Wr58uVauXKlKlSrZNZEqVKigPXv2aM6cOWrQoIHmz5+vBg0a2F1Z+fjjj+vAgQP68MMPFRISovHjx6tSpUoZrvx01OHDhxUfH3/N/9nz9PTUunXrtGrVKnXt2lXbt2/XE088oebNm2f7pj6OzEObXVn9j97N3GjIUVarNdP49ZpvCQkJ+vHHHxUdHa1y5cqZPxUrVtSFCxc0a9Yshxt40s09z40aNdL+/fv15ZdfqnLlyvr8889Vo0YNff755+aYgQMHau/evXrrrbdUoEABvf7666pQoYK2bduW5XbLli0rV1dX/fXXXzecW3aP9c2cq+mvyfHjx2d65d3KlSszNCwze75v5DmSpCJFijjcvLlVhg8frrvuuksPPPCADh48qIMHD5qN6BMnTujgwYM3fBV+bsnqtXml2rVrq1ixYubPu+++a7c8vcn80EMP6b333tOgQYP08ssv290AcP/+/WratKlOnjyp9957T0uWLNHKlSs1aNAgScqT56V8+fLau3evkpOTb2h9R95bJ0yYoO3bt+vVV181b45VqVKlTG+oeKX056VLly5Zvt7q169vt05mr7fsvG85ixv9vMjLfd/IcXLEmTNnVLRo0RteHwCQu2jaAgCc1kMPPaT9+/drw4YNN7T+vHnz1KRJE33xxRfq2LGjWrRooWbNmmW4q7skeXt764knntC0adMUExOjiIgIjRkzRpcuXTLHFCtWTH379tXChQsVHR2tIkWKaMyYMTdanqTLNx+RpPDw8GuOc3FxUdOmTfXee+9p165dGjNmjNasWWPecCWnr5S5+quuhmFo3759djdyKlSoUKbP5dVXoTmSW6lSpRQbG5vhKrW///7bXJ4Tvv/+e126dElTpkzR3Llz7X7efPNNHTp0yLzaukyZMoqNjdXp06cd3k9AQIC8vLy0Z8+eDMv+/vtvubi4qESJEmascOHC6t69u2bPnq1///1XVatWzXAn8jJlymjIkCFasWKFduzYoeTkZE2YMCHLHLy8vPTggw9q3bp15lW9jsrusZZu/FxNn+bC19c30yvvmjVrZndTr2tx9DmSLjfazpw549CVmenn49XHNzk5WdHR0RnO19jYWCUmJtrF9u7dK0nXvElaTEyM9u3bp7CwMIWGhio0NNSc1qNv374KDQ297tesb1apUqV09OjRDF/D37dv3w1vc+bMmXbNp6eeeuqa44cNGyYfHx+99tprZuzHH39UUlKSFi1apGeffVatW7dWs2bNMm0wZve9KKvjmh673vtQmzZtdPHiRc2fPz9b+7ta+lWYV7/msrrCt0qVKnrttde0bt06/fLLLzpy5Ig++eQTc3lmdQcEBMjHx0dpaWlZvt4CAwOzlW923rdyQ6lSpbR///4Mjc+bOSezu1+bzabo6Ogc3e/NHqesno/MzmNJSk1N1b///mt+kwUA4Hxo2gIAnNaLL74ob29vPfPMMzp27FiG5fv379fEiROzXN9qtWb4n5e5c+fqyJEjdrFTp07ZPXZ3d1fFihVlGIZSUlKUlpaWoZETGBiokJCQbN3hOitr1qzRG2+8odDQUHXu3DnLcZk1C++9915J/91hO/0r15k11m7EV199Zdc4nTdvno4ePWp3h+0yZcro999/t7uabPHixRkag47k1rp1a6Wlpemjjz6yi7///vuyWCwO3+E7K998843CwsL03HPPqUOHDnY/L7zwggoWLGhOkdC+fXsZhqFRo0Zl2M71rpKyWq1q0aKFfvjhB7uvvx87dkyzZs1SgwYNzOkLrj4PCxYsqLJly5rH+MKFC3Z/RJAuHwMfH5/rnocjRoyQYRjq2rVrhq+gS9KWLVs0Y8aMLNcvU6aM4uPj7b72fPToUS1YsMBu3M2cqzVr1lSZMmX07rvvZprjiRMnsswv3c08R/Xq1ZNhGNedW/ZKzZo1k7u7uyZNmmR3LnzxxReKj4/PcDf51NRUTZ061XycnJysqVOnKiAgQDVr1sxyP2+++aYWLFhg9/PGG29Iuvw+uWDBggzTLuS08PBwpaSk6LPPPjNjNptNkydPvuFt1q9f36FpGvz9/fXss89q+fLlioqKkvTfFYxXPv/x8fGaNm1ahvW9vb2z9T5Uq1YtBQYG6pNPPrE7b5YuXardu3dnOK5Xe+6551SsWDENGTLEbMpf6fjx43rzzTezXD/9Dxjr1q0zY2lpafr000/txiUkJCg1NdUuVqVKFbm4uNjlnVndVqtV7du31/z58zP9Rkt2Xm/S9d+3clN4eLiOHDmiRYsWmbFLly7ZnaO5tV9J+vjjj+3iH3744U1t92aPU+vWrRUbG6t58+aZsQsXLmQ4b9Lt2rVLly5d0v33339TeQMAco9rXicAAEBWypQpo1mzZumJJ55QhQoV9NRTT6ly5cpKTk7Wb7/9prlz56pbt25Zrv/QQw9p9OjR6t69u+6//3799ddfmjlzZobGQIsWLRQcHKz69esrKChIu3fv1kcffaSIiAj5+Pjo7NmzKl68uDp06KBq1aqpYMGCWrVqlTZt2nTdq/fSLV26VH///bdSU1N17NgxrVmzRitXrlSpUqW0aNEiu5vdXG306NFat26dIiIiVKpUKR0/flwff/yxihcvrgYNGpjPlb+/vz755BP5+PjI29tbderUyXQOwuwoXLiwGjRooO7du+vYsWP64IMPVLZsWbsbvDzzzDOaN2+eWrZsqccff1z79+/XN998Y3djMEdza9OmjZo0aaJhw4bp4MGDqlatmlasWKEffvhBAwcOzLDtGxEbG6u1a9dmuNlZOg8PD4WHh2vu3LmaNGmSmjRpoq5du2rSpEn6559/1LJlS9lsNv3yyy9q0qSJ+vXrd839vfnmm1q5cqUaNGigvn37ytXVVVOnTlVSUpLGjRtnjqtYsaIeeOAB1axZU4ULF9bmzZs1b948c/t79+5V06ZN9fjjj6tixYpydXXVggULdOzYMXXs2PGaOdx///2aPHmy+vbtq/Lly6tr164qV66czp07p59++kmLFi26ZhOpY8eOeumll/Too4+qf//+unDhgqZMmaK7777b7mZFN3uufv7552rVqpUqVaqk7t2766677tKRI0e0du1a+fr66scff7xmnTfzHDVo0EBFihTRqlWr9OCDD15zbLqAgAC98sorGjVqlFq2bKmHH35Ye/bs0ccff6zatWvb3fRIujyn7TvvvKODBw/q7rvv1rfffquoqCh9+umn17yKOP25u1L6Td9q166ttm3bZivfm9G2bVvdd999GjJkiPbt26fy5ctr0aJFZqP+Vs2LOWDAAH3wwQd6++23NWfOHLVo0ULu7u5q06aNnn32WZ0/f16fffaZAgMDdfToUbt1a9asqSlTpujNN99U2bJlFRgYmOmxdnNz0zvvvKPu3burcePG6tSpk44dO6aJEyeqdOnS5tQLWSlUqJAWLFig1q1b695771WXLl3MpvzWrVs1e/Zs1atXL8v1K1WqpLp16+qVV17R6dOnVbhwYc2ZMydDg3bNmjXq16+fHnvsMd19991KTU3V119/bTb6rqx71apVeu+99xQSEqLQ0FDVqVNHb7/9ttauXas6deqoV69eqlixok6fPq2tW7dq1apV2fp2wfXet3LTs88+q48++kidOnXSgAEDVKxYMc2cOdP8PM2tc7JmzZpq3769PvjgA506dUp169bVzz//bDbob3S/N3ucevXqpY8++khPPfWUtmzZomLFiunrr7/OMA91upUrV8rLy0vNmze/sScCAJD7DAAAnNzevXuNXr16GaVLlzbc3d0NHx8fo379+saHH35oXLp0yRxXqlQp4+mnnzYfX7p0yRgyZIhRrFgxw9PT06hfv76xYcMGo3Hjxkbjxo3NcVOnTjUaNWpkFClSxPDw8DDKlCljDB061IiPjzcMwzCSkpKMoUOHGtWqVTN8fHwMb29vo1q1asbHH3983dynTZtmSDJ/3N3djeDgYKN58+bGxIkTjYSEhAzrjBgxwrjyI3r16tXGI488YoSEhBju7u5GSEiI0alTJ2Pv3r126/3www9GxYoVDVdXV0OSMW3aNMMwDKNx48ZGpUqVMs3v6udi7dq1hiRj9uzZxiuvvGIEBgYanp6eRkREhHHo0KEM60+YMMG46667DA8PD6N+/frG5s2bM2zzWrk9/fTTRqlSpezGnjt3zhg0aJAREhJiuLm5GeXKlTPGjx9v2Gw2u3GSjMjIyAw5XX0eZJazJGP16tVZjpk+fbohyfjhhx8MwzCM1NRUY/z48Ub58uUNd3d3IyAgwGjVqpWxZcuW6+ZjGIaxdetWIzw83ChYsKDh5eVlNGnSxPjtt9/sxrz55pvGfffdZ/j7+xuenp5G+fLljTFjxhjJycmGYRjGyZMnjcjISKN8+fKGt7e34efnZ9SpU8f47rvvsqzjalu2bDGefPJJ87ktVKiQ0bRpU2PGjBlGWlqaXS0jRoywW3fFihVG5cqVDXd3d+Oee+4xvvnmmxw/Vw3DMLZt22a0a9fOfD2WKlXKePzxx+2OV/p+T5w4Ybfdm32O+vfvb5QtWzbL5XPnzjUkGWvXrrWLf/TRR0b58uUNNzc3IygoyOjTp49x5swZuzHpr8PNmzcb9erVMwoUKGCUKlXK+Oijj7KV29XSX6tz58697tjo6GhDkjF+/PhMl2f2fGb22jxx4oTx5JNPGj4+Poafn5/RrVs3Y/369YYkY86cOXbrent7Z7mfm823W7duhtVqNfbt22cYhmEsWrTIqFq1qlGgQAGjdOnSxjvvvGN8+eWXhiQjOjraXC8uLs6IiIgwfHx8DEnm+1T6c3n1cf3222+N6tWrGx4eHkbhwoWNzp07G4cPH75u/uliY2ONQYMGGXfffbdRoEABw8vLy6hZs6YxZswY8/PFMDK+DxuGYezfv99o1qyZ4eHhYQQFBRmvvvqqsXLlSrs8Dxw4YPTo0cMoU6aMUaBAAaNw4cJGkyZNjFWrVtlt6++//zYaNWpkeHp6GpLs3h+PHTtmREZGGiVKlDDc3NyM4OBgo2nTpsann35qjrnWuXa9962sXO/8zewcyux5OnDggBEREWF4enoaAQEBxpAhQ4z58+cbkozff//dbt3MPgevPs/Tz70r35MyO28TExONyMhIo3DhwkbBggWNtm3bGnv27DEkGW+//XaGda9+r0r/3eDK8/Nmj5NhGMahQ4eMhx9+2PDy8jKKFi1qDBgwwFi2bFmm53edOnWMLl26ZHhOAADOw2IYt2DmdQAAAMDJHThwQOXLl9fSpUvVtGnTHN32Aw88oJMnT97UzRWd0cKFC/Xoo4/q119/vakbIgE55YMPPtCgQYN0+PBh3XXXXbdsv1FRUapevbq++eaba0555AyioqJUo0YNbd261ZzCBgDgfJjTFgAAAJAUFhamnj176u23387rVJzSxYsX7R6npaXpww8/lK+vr2rUqJFHWSE/u/qcvHTpkqZOnapy5crlasP26v1Kl5vFLi4uatSoUa7tN6e8/fbb6tChAw1bAHByzGkLAAAA/L8pU6bkdQpO6/nnn9fFixdVr149JSUl6fvvv9dvv/2msWPHytPTM6/TQz7Url07lSxZUvfee6/i4+P1zTff6O+//zZvJJlbxo0bpy1btqhJkyZydXXV0qVLtXTpUvXu3VslSpTI1X3nhDlz5uR1CgCAbKBpCwAAAOC6HnzwQU2YMEGLFy/WpUuXVLZsWX344Ye35KZTQGbCw8P1+eefa+bMmUpLS1PFihU1Z84cPfHEE7m63/vvv18rV67UG2+8ofPnz6tkyZIaOXKkhg0blqv7BQDkL8xpCwAAAAAAAABOhDltAQAAAAAAAMCJ0LQFAAAAAAAAACfCnLbZYLPZFBsbKx8fH1kslrxOBwAAAAAAAMBtyDAMnTt3TiEhIXJxyfp6Wpq22RAbG3tb3AUUAAAAAAAAgPP7999/Vbx48SyX07TNBh8fH0mXn0xfX988zgYAAAAAAADA7SghIUElSpQw+41ZoWmbDelTIvj6+tK0BQAAAAAAAHBTrjcFKzciAwAAAAAAAAAnQtMWAAAAAAAAAJwITVsAAAAAAAAAcCLMaQsAAAAAAADcIdLS0pSSkpLXaeRbbm5uslqtN70dmrYAAAAAAADAbc4wDMXFxens2bN5nUq+5+/vr+Dg4OvebOxaaNoCAAAAAAAAt7n0hm1gYKC8vLxuqmGIG2MYhi5cuKDjx49LkooVK3bD26JpCwAAAAAAANzG0tLSzIZtkSJF8jqdfM3T01OSdPz4cQUGBt7wVAnciAwAAAAAAAC4jaXPYevl5ZXHmUD67zjczNzCNG0BAAAAAACAOwBTIjiHnDgONG0BAAAAAAAAwInQtAUAAAAAAADg1CwWixYuXJjXadwyNG0BAEC+89Zbb6l27dry8fFRYGCg2rZtqz179pjLT58+reeff1733HOPPD09VbJkSfXv31/x8fF227FYLBl+5syZYy7v1q1bpmMqVap0y2oFAABAPmdLc/r9xcXF6fnnn1dYWJg8PDxUokQJtWnTRqtXr86FBB1nGIaGDx+uYsWKydPTU82aNdM///yTq/t0zdWtAwAAOKGff/5ZkZGRql27tlJTU/Xqq6+qRYsW2rVrl7y9vRUbG6vY2Fi9++67qlixog4dOqTnnntOsbGxmjdvnt22pk2bppYtW5qP/f39zX9PnDhRb7/9tvk4NTVV1apV02OPPZbrNQIAAACSJBer9Nk70tF/c39fxUpIvV5yaJWDBw+qfv368vf31/jx41WlShWlpKRo+fLlioyM1N9//51LyWbfuHHjNGnSJM2YMUOhoaF6/fXXFR4erl27dqlAgQK5sk+atgAAIN9ZtmyZ3ePp06crMDBQW7ZsUaNGjVS5cmXNnz/fXF6mTBmNGTNGXbp0UWpqqlxd//sVyt/fX8HBwZnux8/PT35+fubjhQsX6syZM+revXsOVwQAAABcw9F/pZh9eZ1Fpvr27SuLxaI//vhD3t7eZrxSpUrq0aNHluu99NJLWrBggQ4fPqzg4GB17txZw4cPl5ubmyTpzz//1MCBA7V582ZZLBaVK1dOU6dOVa1atXTo0CH169dPv/76q5KTk1W6dGmNHz9erVu3zrAfwzD0wQcf6LXXXtMjjzwiSfrqq68UFBSkhQsXqmPHjjn8jFzG9AgAACDfS5/2oHDhwtcc4+vra9ewlaTIyEgVLVpU9913n7788ksZhpHlNr744gs1a9ZMpUqVypnEAQAAgNvY6dOntWzZMkVGRto1bNNd+S22q/n4+Gj69OnatWuXJk6cqM8++0zvv/++ubxz584qXry4Nm3apC1btujll182G7qRkZFKSkrSunXr9Ndff+mdd95RwYIFM91PdHS04uLi1KxZMzPm5+enOnXqaMOGDTdY+fVxpS0AAMjXbDabBg4cqPr166ty5cqZjjl58qTeeOMN9e7d2y4+evRoPfjgg/Ly8tKKFSvUt29fnT9/Xv3798+wjdjYWC1dulSzZs3KlToAAACA282+fftkGIbKly/v8Lqvvfaa+e/SpUvrhRde0Jw5c/Tiiy9KkmJiYjR06FBz2+XKlTPHx8TEqH379qpSpYokKSwsLMv9xMXFSZKCgoLs4kFBQeay3EDTFgAA5GuRkZHasWOHfv3110yXJyQkKCIiQhUrVtTIkSPtlr3++uvmv6tXr67ExESNHz8+06btjBkz5O/vr7Zt2+Zk+gAAAMBt61rfUrueb7/9VpMmTdL+/ft1/vx5paamytfX11w+ePBgPfPMM/r666/VrFkzPfbYYypTpowkqX///urTp49WrFihZs2aqX379qpatepN15OTmB4BAADkW/369dPixYu1du1aFS9ePMPyc+fOqWXLlvLx8dGCBQvMr1NlpU6dOjp8+LCSkpLs4oZh6Msvv1TXrl3l7u6eozUAAAAAt6ty5crJYrE4fLOxDRs2qHPnzmrdurUWL16sbdu2adiwYUpOTjbHjBw5Ujt37lRERITWrFmjihUrasGCBZKkZ555RgcOHFDXrl31119/qVatWvrwww8z3Vf6/SuOHTtmFz927FiW97bICTRtAQBAvmMYhvr166cFCxZozZo1Cg0NzTAmISFBLVq0kLu7uxYtWpStu8JGRUWpUKFC8vDwsIv//PPP2rdvn3r27JljNQAAAAC3u8KFCys8PFyTJ09WYmJihuVnz57NdL3ffvtNpUqV0rBhw1SrVi2VK1dOhw4dyjDu7rvv1qBBg7RixQq1a9dO06ZNM5eVKFFCzz33nL7//nsNGTJEn332Wab7Cg0NVXBwsFavXm3GEhIStHHjRtWrV8/BirOP6REAAEC+ExkZqVmzZumHH36Qj4+POReVn5+fPD09zYbthQsX9M033yghIUEJCQmSpICAAFmtVv344486duyY6tatqwIFCmjlypUaO3asXnjhhQz7++KLL1SnTp0s58wFAAAA8qvJkyerfv36uu+++zR69GhVrVpVqampWrlypaZMmaLdu3dnWKdcuXKKiYnRnDlzVLt2bS1ZssS8ilaSLl68qKFDh6pDhw4KDQ3V4cOHtWnTJrVv316SNHDgQLVq1Up33323zpw5o7Vr16pChQqZ5mexWDRw4EC9+eabKleunEJDQ/X6668rJCQkV6c+o2kLAADynSlTpkiSHnjgAbv4tGnT1K1bN23dulUbN26UJJUtW9ZuTHR0tEqXLi03NzdNnjxZgwYNkmEYKlu2rN577z316tXLbnx8fLzmz5+viRMn5l5BAAAAwLUUK+G0+wkLC9PWrVs1ZswYDRkyREePHlVAQIBq1qxp/t5+tYcffliDBg1Sv379lJSUpIiICL3++uvmPSisVqtOnTqlp556SseOHVPRokXVrl07jRo1SpKUlpamyMhIHT58WL6+vmrZsqXef//9LHN88cUXlZiYqN69e+vs2bNq0KCBli1blq1v490oi3EzM/7mEwkJCfLz81N8fLzdhMYAAAAAAABAXrt06ZKio6MVGhqasZFoS5NcrLcumVu9Pyd0reOR3T4jc9oCAAAAAAAAd6pb3UDN5w3bnELTFgAAAAAAAACcCE1bAACQa9LSbHmdAhzA8QIAAACcAzciAwAAucZqdVHnzku0e/epvE4F11GhQhHNnBmR12kAAAAAEE1bAACQy3bvPqVt247ndRoAAAAAcNtgegQAAAAAAAAAcCI0bQEAAAAAAADAidC0BQAAAAAAAAAnQtMWAAAAAAAAAJwITVsAAAAAAAAATs1isWjhwoV5ncYtQ9MWAAAAAAAAuEOl2Qyn319cXJyef/55hYWFycPDQyVKlFCbNm20evXqXMjQcd9//71atGihIkWKyGKxKCoqKtf36ZrrewAAAAAAAACQJ6wuFo2ZdlIxcSm5vq+SwW4a1r2oQ+scPHhQ9evXl7+/v8aPH68qVaooJSVFy5cvV2RkpP7+++9cyjb7EhMT1aBBAz3++OPq1avXLdknTVsAAAAAAADgDhYTl6J//s39pu2N6Nu3rywWi/744w95e3ub8UqVKqlHjx5ZrvfSSy9pwYIFOnz4sIKDg9W5c2cNHz5cbm5ukqQ///xTAwcO1ObNm2WxWFSuXDlNnTpVtWrV0qFDh9SvXz/9+uuvSk5OVunSpTV+/Hi1bt0603117dpV0uUG861C0xYAAAAAAADALXf69GktW7ZMY8aMsWvYpvP3989yXR8fH02fPl0hISH666+/1KtXL/n4+OjFF1+UJHXu3FnVq1fXlClTZLVaFRUVZTZ0IyMjlZycrHXr1snb21u7du1SwYIFc6XGG0XTFgAAAAAAAMAtt2/fPhmGofLlyzu87muvvWb+u3Tp0nrhhRc0Z84cs2kbExOjoUOHmtsuV66cOT4mJkbt27dXlSpVJElhYWE3U0au4EZkAAAAAAAAAG45w7jxm6R9++23ql+/voKDg1WwYEG99tpriomJMZcPHjxYzzzzjJo1a6a3335b+/fvN5f1799fb775purXr68RI0Zo+/btN1VHbqBpCwAAAAAAAOCWK1eunCwWi8M3G9uwYYM6d+6s1q1ba/Hixdq2bZuGDRum5ORkc8zIkSO1c+dORUREaM2aNapYsaIWLFggSXrmmWd04MABde3aVX/99Zdq1aqlDz/8MEdru1k0bQEAAAAAAADccoULF1Z4eLgmT56sxMTEDMvPnj2b6Xq//fabSpUqpWHDhqlWrVoqV66cDh06lGHc3XffrUGDBmnFihVq166dpk2bZi4rUaKEnnvuOX3//fcaMmSIPvvssxyrKyfQtAUAAAAAAACQJyZPnqy0tDTdd999mj9/vv755x/t3r1bkyZNUr169TJdp1y5coqJidGcOXO0f/9+TZo0ybyKVpIuXryofv366aefftKhQ4e0fv16bdq0SRUqVJAkDRw4UMuXL1d0dLS2bt2qtWvXmssyc/r0aUVFRWnXrl2SpD179igqKkpxcXE5+EzY40ZkAAAAAAAAwB2sZLCb0+4nLCxMW7du1ZgxYzRkyBAdPXpUAQEBqlmzpqZMmZLpOg8//LAGDRqkfv36KSkpSREREXr99dc1cuRISZLVatWpU6f01FNP6dixYypatKjatWunUaNGSZLS0tIUGRmpw4cPy9fXVy1bttT777+fZY6LFi1S9+7dzccdO3aUJI0YMcLcZ06zGDcz428+kZCQID8/P8XHx8vX1zev0wEA4LZSo8ZX2rbteF6ngeuoXj1QW7c+lddpAAAA4AZcunRJ0dHRCg0NVYECBeyWpdkMWV0styyXW70/Z3St45HdPiPTIwAAAAAAAAB3qFvdQM3vDducQtMWAAAAAAAAAJwITVsAAAAAAAAAcCI0bQEAAAAAAADAidC0BQAAAAAAAAAnQtMWAAAAAAAAuAPYbLa8TgHKmePgmgN5AAAAAAAAAMgj7u7ucnFxUWxsrAICAuTu7i6LxZLXaeU7hmEoOTlZJ06ckIuLi9zd3W94WzRtAQAAAAAAgNuYi4uLQkNDdfToUcXGxuZ1Ovmel5eXSpYsKReXG5/kgKYtAAAAAAAAcJtzd3dXyZIllZqaqrS0tLxOJ9+yWq1ydXW96SudadoCAAAAAAAAdwCLxSI3Nze5ubnldSq4SdyIDAAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcSJ42bd966y3Vrl1bPj4+CgwMVNu2bbVnzx67MZcuXVJkZKSKFCmiggULqn379jp27JjdmJiYGEVERMjLy0uBgYEaOnSoUlNT7cb89NNPqlGjhjw8PFS2bFlNnz49t8sDAAAAAAAAAIfladP2559/VmRkpH7//XetXLlSKSkpatGihRITE80xgwYN0o8//qi5c+fq559/VmxsrNq1a2cuT0tLU0REhJKTk/Xbb79pxowZmj59uoYPH26OiY6OVkREhJo0aaKoqCgNHDhQzzzzjJYvX35L6wUAAAAAAACA67EYhmHkdRLpTpw4ocDAQP38889q1KiR4uPjFRAQoFmzZqlDhw6SpL///lsVKlTQhg0bVLduXS1dulQPPfSQYmNjFRQUJEn65JNP9NJLL+nEiRNyd3fXSy+9pCVLlmjHjh3mvjp27KizZ89q2bJl180rISFBfn5+io+Pl6+vb+4UDwDAHapGja+0bdvxvE4D11G9eqC2bn0qr9MAAAAA7mjZ7TO63sKcris+Pl6SVLhwYUnSli1blJKSombNmpljypcvr5IlS5pN2w0bNqhKlSpmw1aSwsPD1adPH+3cuVPVq1fXhg0b7LaRPmbgwIGZ5pGUlKSkpCTzcUJCgiQpNTXVnHbBxcVFLi4ustlsstls5tj0eFpamq7sh2cVt1qtslgsGaZzsFqtki5fSZyduKurqwzDsItbLBZZrdYMOWYVpyZqoiZqoiZqyo2aLBbJ3d1ixgxDSkkx5OIiubpmjFutktX6X9xmM5SaKrm6Si4u/8XT0gylpUlubhZZ/gsrNdWQzZZ1/MpcpMv7NIyM8eRkQxbL5e1cHc8q99u5JotFdsf7Tjj37sTXEzVREzVREzVREzVREzXd3jVdPSYrTtO0tdlsGjhwoOrXr6/KlStLkuLi4uTu7i5/f3+7sUFBQYqLizPHXNmwTV+evuxaYxISEnTx4kV5enraLXvrrbc0atSoDDlu27ZN3t7ekqSAgACVKVNG0dHROnHihDmmePHiKl68uPbu3Ws2oSUpLCxMgYGB2rFjhy5evGjGy5cvL39/f23bts3uAFatWlXu7u7avHmzXQ61atVScnKytm/fbsasVqtq166t+Ph4/f3332bc09NT1apV08mTJ3XgwAEz7ufnpwoVKig2NlaHDx8249RETdRETdRETblRU1CQi1q1CjbjJ0+maurUE6pa1UsREX5m/MCBJM2efVr16/uoYcOCZjwq6oKWLIlXeLif7r3Xy4z/8st5rVt3Th06FFJYmIcZX7IkXlFRF9SjR1EVLfrfrzqzZ5/WgQNJGjAgyK6ZOXXqCSUkpGno0P9ylKTx4+Pk62vVs88GmLHkZEPjx8epdGkPdepU+I6qKSjIxe643gnn3p34eqImaqImaqImaqImaqKm27umK6eFvRanmR6hT58+Wrp0qX799VcVL15ckjRr1ix1797d7qpXSbrvvvvUpEkTvfPOO+rdu7cOHTpkNz/thQsX5O3trf/9739q1aqV7r77bnXv3l2vvPKKOeZ///ufIiIidOHChQxN28yutC1RooROnTplXrbMXxeoiZqoiZqoiZqyV1PNml9px47/fgG6E65KzSr327mmGjUCtXHjk2bsTjj37sTXEzVREzVREzVREzVREzXd3jUlJCSoSJEit8f0CP369dPixYu1bt06s2ErScHBwUpOTtbZs2ftrrY9duyYgoODzTF//PGH3faOHTtmLkv/b3rsyjG+vr4ZGraS5OHhIQ8PjwxxV1dXubraP2XpB+tq6Qclu/Grt3sjcYvFkmk8qxwdjVMTNWUVpyZqkqgpqxwdjd+JNRnG5abg1Wy2zONpaZebl1e7/PtPxnhKSuZ/f84qntk+s4o7mvvtXJNhZH78budz7058PVETNUnUlFWOjsapiZokasoqR0fj1ERNEjVllePV8azGZMgpW6NyiWEY6tevnxYsWKA1a9YoNDTUbnnNmjXl5uam1atXm7E9e/YoJiZG9erVkyTVq1dPf/31l44f/+8GJytXrpSvr68qVqxojrlyG+lj0rcBAAAAAAAAAM4iT6+0jYyM1KxZs/TDDz/Ix8fHnIPWz89Pnp6e8vPzU8+ePTV48GAVLlxYvr6+ev7551WvXj3VrVtXktSiRQtVrFhRXbt21bhx4xQXF6fXXntNkZGR5tWyzz33nD766CO9+OKL6tGjh9asWaPvvvtOS5YsybPaAQAAAAAAACAzeXql7ZQpUxQfH68HHnhAxYoVM3++/fZbc8z777+vhx56SO3bt1ejRo0UHBys77//3lxutVq1ePFiWa1W1atXT126dNFTTz2l0aNHm2NCQ0O1ZMkSrVy5UtWqVdOECRP0+eefKzw8/JbWCwAAAAAAAADX4zQ3InNmCQkJ8vPzu+4EwQAAIKMaNb7Stm3Hrz8Qeap69UBt3fpUXqcBAAAA3NGy22fM0yttAQAAAAAAAAD2aNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBE8rRpu27dOrVp00YhISGyWCxauHCh3fJu3brJYrHY/bRs2dJuzOnTp9W5c2f5+vrK399fPXv21Pnz5+3GbN++XQ0bNlSBAgVUokQJjRs3LrdLAwAAAAAAAIAbkqdN28TERFWrVk2TJ0/OckzLli119OhR82f27Nl2yzt37qydO3dq5cqVWrx4sdatW6fevXubyxMSEtSiRQuVKlVKW7Zs0fjx4zVy5Eh9+umnuVYXAAAAAAAAANwo17zceatWrdSqVatrjvHw8FBwcHCmy3bv3q1ly5Zp06ZNqlWrliTpww8/VOvWrfXuu+8qJCREM2fOVHJysr788ku5u7urUqVKioqK0nvvvWfX3AUAAAAAAAAAZ5CnTdvs+OmnnxQYGKhChQrpwQcf1JtvvqkiRYpIkjZs2CB/f3+zYStJzZo1k4uLizZu3KhHH31UGzZsUKNGjeTu7m6OCQ8P1zvvvKMzZ86oUKFCGfaZlJSkpKQk83FCQoIkKTU1VampqZIkFxcXubi4yGazyWazmWPT42lpaTIM47pxq9Uqi8VibvfKuCSlpaVlK+7q6irDMOziFotFVqs1Q45ZxamJmqiJmqiJmnKjJotFcne3mDHDkFJSDLm4SK6uGeNWq2S1/he32QylpkqurpKLy3/xtDRDaWmSm5tFlv/CSk01ZLNlHb8yF+nyPg0jYzw52ZDFcnk7V8ezyv12rslikd3xvhPOvTvx9URN1ERN1ERN1ERN1ERNt3dNV4/JilM3bVu2bKl27dopNDRU+/fv16uvvqpWrVppw4YNslqtiouLU2BgoN06rq6uKly4sOLi4iRJcXFxCg0NtRsTFBRkLsusafvWW29p1KhRGeLbtm2Tt7e3JCkgIEBlypRRdHS0Tpw4YY4pXry4ihcvrr179yo+Pt6Mh4WFKTAwUDt27NDFixfNePny5eXv769t27bZHcCqVavK3d1dmzdvtsuhVq1aSk5O1vbt282Y1WpV7dq1FR8fr7///tuMe3p6qlq1ajp58qQOHDhgxv38/FShQgXFxsbq8OHDZpyaqImaqImaqCk3agoKclGrVv99a+bkyVRNnXpCVat6KSLCz4wfOJCk2bNPq359HzVsWNCMR0Vd0JIl8QoP99O993qZ8V9+Oa91686pQ4dCCgvzMONLlsQrKuqCevQoqqJF//tVZ/bs0zpwIEkDBgTZNTOnTj2hhIQ0DR1q/82e8ePj5Otr1bPPBpix5GRD48fHqXRpD3XqVPiOqikoyMXuuN4J596d+HqiJmqiJmqiJmqiJmqiptu7psTERGWHxbiyLZyHLBaLFixYoLZt22Y55sCBAypTpoxWrVqlpk2bauzYsZoxY4b27NljNy4wMFCjRo1Snz591KJFC4WGhmrq1Knm8l27dqlSpUratWuXKlSokGE/mV1pW6JECZ06dUq+vr6S+OsCNVETNVETNVFTdmuqWfMr7djx3y9Ad8JVqVnlfjvXVKNGoDZufNKM3Qnn3p34eqImaqImaqImaqImaqKm27umhIQEFSlSRPHx8WafMTNOfaXt1cLCwlS0aFHt27dPTZs2VXBwsI4fP243JjU1VadPnzbnwQ0ODtaxY8fsxqQ/zmquXA8PD3l4eGSIu7q6ytXV/ilLP1hXSz8o2Y1fvd0biVsslkzjWeXoaJyaqCmrODVRk0RNWeXoaPxOrMkwLjcFr2azZR5PS7vcvLza5d9/MsZTUjL/+3NW8cz2mVXc0dxv55oMI/Pjdzufe3fi64maqEmipqxydDROTdQkUVNWOToapyZqkqgpqxyvjmc1JkNO2RrlJA4fPqxTp06pWLFikqR69erp7Nmz2rJlizlmzZo1stlsqlOnjjlm3bp1SklJMcesXLlS99xzT6ZTIwAAAAAAAABAXsrTpu358+cVFRWlqKgoSVJ0dLSioqIUExOj8+fPa+jQofr999918OBBrV69Wo888ojKli2r8PBwSVKFChXUsmVL9erVS3/88YfWr1+vfv36qWPHjgoJCZEkPfnkk3J3d1fPnj21c+dOffvtt5o4caIGDx6cV2UDAAAAAAAAQJbytGm7efNmVa9eXdWrV5ckDR48WNWrV9fw4cNltVq1fft2Pfzww7r77rvVs2dP1axZU7/88ovd1AUzZ85U+fLl1bRpU7Vu3VoNGjTQp59+ai738/PTihUrFB0drZo1a2rIkCEaPny4evfufcvrBQAAAAAAAIDrcZobkTmzhIQE+fn5XXeCYAAAkFGNGl9p27bj1x+IPFW9eqC2bn0qr9MAAAAA7mjZ7TPeVnPaAgAAAAAAAMCdjqYtAAAAAAAAADgRmrYAAAAAAAAA4EQcbtrOmDFDS5YsMR+/+OKL8vf31/33369Dhw7laHIAAAAAAAAAkN843LQdO3asPD09JUkbNmzQ5MmTNW7cOBUtWlSDBg3K8QQBAAAAAAAAID9xdXSFf//9V2XLlpUkLVy4UO3bt1fv3r1Vv359PfDAAzmdHwAAAAAAAADkKw5faVuwYEGdOnVKkrRixQo1b95cklSgQAFdvHgxZ7MDAAAAAAAAgHzG4SttmzdvrmeeeUbVq1fX3r171bp1a0nSzp07Vbp06ZzODwAAAAAAAADyFYevtJ08ebLq1aunEydOaP78+SpSpIgkacuWLerUqVOOJwgAAAAAAAAA+YnDV9r6+/vro48+yhAfNWpUjiQEAAAAAAAAAPmZw1faStIvv/yiLl266P7779eRI0ckSV9//bV+/fXXHE0OAAAAAAAAAPIbh5u28+fPV3h4uDw9PbV161YlJSVJkuLj4zV27NgcTxAAAAAAAAAA8hOHm7ZvvvmmPvnkE3322Wdyc3Mz4/Xr19fWrVtzNDkAAAAAAAAAyG8cbtru2bNHjRo1yhD38/PT2bNncyInAAAAAAAAAMi3HG7aBgcHa9++fRniv/76q8LCwnIkKQAAAAAAAADIrxxu2vbq1UsDBgzQxo0bZbFYFBsbq5kzZ+qFF15Qnz59ciNHAAAAAAAAAMg3XB1d4eWXX5bNZlPTpk114cIFNWrUSB4eHnrhhRf0/PPP50aOAAAAAAAAAJBvONy0tVgsGjZsmIYOHap9+/bp/PnzqlixogoWLJgb+QEAAAAAAABAvuJw0zadu7u7KlasmJO5AAAAAAAAAEC+l62mbbt27bK9we+///6GkwEAAAAAAACA/C5bTVs/P7/czgMAAAAAAAAAoGw2badNm5bbeQAAAAAAAAAAdBNz2h4/flx79uyRJN1zzz0KDAzMsaQAAAAAAAAAIL9ycXSFhIQEde3aVXfddZcaN26sxo0b66677lKXLl0UHx+fGzkCAAAAAAAAQL7hcNO2V69e2rhxoxYvXqyzZ8/q7NmzWrx4sTZv3qxnn302N3IEAAAAAAAAgHzD4ekRFi9erOXLl6tBgwZmLDw8XJ999platmyZo8kBAAAAAAAAQH7j8JW2RYoUkZ+fX4a4n5+fChUqlCNJAQAAAAAAAEB+5XDT9rXXXtPgwYMVFxdnxuLi4jR06FC9/vrrOZocAAAAAAAAAOQ3Dk+PMGXKFO3bt08lS5ZUyZIlJUkxMTHy8PDQiRMnNHXqVHPs1q1bcy5TAAAAAAAAAMgHHG7atm3bNhfSAAAAAAAAAABIN9C0HTFiRG7kAQAAAAAAAADQDTRtr3T+/HnZbDa7mK+v700lBAAAAAAAAAD5mcM3IouOjlZERIS8vb3l5+enQoUKqVChQvL391ehQoVyI0cAAAAAAAAAyDccvtK2S5cuMgxDX375pYKCgmSxWHIjLwAAAAAAAADIlxxu2v7555/asmWL7rnnntzIBwAAAAAAAADyNYenR6hdu7b+/fff3MgFAAAAAAAAAPI9h6+0/fzzz/Xcc8/pyJEjqly5stzc3OyWV61aNceSAwAAAAAAAID8xuGm7YkTJ7R//351797djFksFhmGIYvForS0tBxNEAAAAAAAAADyE4ebtj169FD16tU1e/ZsbkQGAAAAAAAAADnM4abtoUOHtGjRIpUtWzY38gEAAAAAAACAfM3hG5E9+OCD+vPPP3MjFwAAAAAAAADI9xy+0rZNmzYaNGiQ/vrrL1WpUiXDjcgefvjhHEsOAAAAAAAAAPIbh5u2zz33nCRp9OjRGZZxIzIAAAAAAAAAuDkON21tNltu5AEAAAAAAAAA0A3MaQsAAAAAAAAAyD0OX2krSYmJifr5558VExOj5ORku2X9+/fPkcQAAAAAAAAAID9yuGm7bds2tW7dWhcuXFBiYqIKFy6skydPysvLS4GBgTRtAQAAAAAAAOAmODw9wqBBg9SmTRudOXNGnp6e+v3333Xo0CHVrFlT7777bm7kCAAAAAAAAAD5hsNN26ioKA0ZMkQuLi6yWq1KSkpSiRIlNG7cOL366qu5kSMAAAAAAAAA5BsON23d3Nzk4nJ5tcDAQMXExEiS/Pz89O+//+ZsdgAAAAAAAACQzzg8p2316tW1adMmlStXTo0bN9bw4cN18uRJff3116pcuXJu5AgAAAAAAAAA+YbDV9qOHTtWxYoVkySNGTNGhQoVUp8+fXTixAl9+umnOZ4gAAAAAAAAAOQnDl9pW6tWLfPfgYGBWrZsWY4mBAAAAAAAAAD5mcNX2l68eFEXLlwwHx86dEgffPCBVqxYkaOJAQAAAAAAAEB+5HDT9pFHHtFXX30lSTp79qzuu+8+TZgwQY888oimTJmS4wkCAAAAAAAAQH7icNN269atatiwoSRp3rx5Cg4O1qFDh/TVV19p0qRJOZ4gAAAAAAAAAOQnDjdtL1y4IB8fH0nSihUr1K5dO7m4uKhu3bo6dOhQjicIAAAAAAAAAPmJw03bsmXLauHChfr333+1fPlytWjRQpJ0/Phx+fr65niCAAAAAAAAAJCfONy0HT58uF544QWVLl1aderUUb169SRdvuq2evXqOZ4gAAAAAAAAAOQnro6u0KFDBzVo0EBHjx5VtWrVzHjTpk316KOP5mhyAAAAAAAAAJDfONy0laTg4GAFBwfbxe67774cSQgAAAAAAAAA8jOHp0cAAAAAAAAAAOQemrYAAAAAAAAA4ERo2gIAAAAAAACAE8lW07ZGjRo6c+aMJGn06NG6cOFCriYFAAAAAAAAAPlVtpq2u3fvVmJioiRp1KhROn/+fK4mBQAAAAAAAAD5lWt2Bt17773q3r27GjRoIMMw9O6776pgwYKZjh0+fHiOJggAAAAAAAAA+Um2mrbTp0/XiBEjtHjxYlksFi1dulSurhlXtVgsNG0BAAAAAAAA4CZkq2l7zz33aM6cOZIkFxcXrV69WoGBgbmaGAAAAAAAAADkR9lq2l7JZrPlRh4AAAAAAAAAAN1A01aS9u/frw8++EC7d++WJFWsWFEDBgxQmTJlcjQ5AAAAAAAAAMhvXBxdYfny5apYsaL++OMPVa1aVVWrVtXGjRtVqVIlrVy5MjdyBAAAAAAAAIB8w+ErbV9++WUNGjRIb7/9dob4Sy+9pObNm+dYcgAAAAAAAACQ3zh8pe3u3bvVs2fPDPEePXpo165dOZIUAAAAAAAAAORXDjdtAwICFBUVlSEeFRWlwMDAnMgJAAAAAAAAAPIth6dH6NWrl3r37q0DBw7o/vvvlyStX79e77zzjgYPHpzjCQIAAAAAAABAfuJw0/b111+Xj4+PJkyYoFdeeUWSFBISopEjR6p///45niAAAAAAAAAA5CcON20tFosGDRqkQYMG6dy5c5IkHx+fHE8MAAAAAAAAAPIjh5u2V6JZCwAAAAAAAAA5y+EbkQEAAAAAAAAAcg9NWwAAAAAAAABwIjRtAQAAAAAAAMCJONS0TUlJUdOmTfXPP//kVj4AAAAAAAAAkK851LR1c3PT9u3bcysXAAAAAAAAAMj3HJ4eoUuXLvriiy9yIxcAAAAAAAAAyPdcHV0hNTVVX375pVatWqWaNWvK29vbbvl7772XY8kBAAAAAAAAQH7jcNN2x44dqlGjhiRp7969dsssFkvOZAUAAAAAAAAA+ZTDTdu1a9fmRh4AAOAOVaFCkbxOAdnAcQIAAACch8NN23T79u3T/v371ahRI3l6esowDK60BQAAdtLSbJo5MyKv00A2paXZZLU6fMsDAAAAADnM4abtqVOn9Pjjj2vt2rWyWCz6559/FBYWpp49e6pQoUKaMGFCbuQJAABuQ1ari34ZNkzx0dF5nQquwy80VA3HjMnrNAAAAADoBpq2gwYNkpubm2JiYlShQgUz/sQTT2jw4ME0bQEAgJ3opUt1fNu2vE4D1xFYvTpNWwAAAMBJONy0XbFihZYvX67ixYvbxcuVK6dDhw7lWGIAAAAAAAAAkB85PGlZYmKivLy8MsRPnz4tDw+PHEkKAAAAAAAAAPIrh5u2DRs21FdffWU+tlgsstlsGjdunJo0aZKjyQEAAAAAAABAfuPw9Ajjxo1T06ZNtXnzZiUnJ+vFF1/Uzp07dfr0aa1fvz43cgQAAAAAAACAfMPhK20rV66svXv3qkGDBnrkkUeUmJiodu3aadu2bSpTpkxu5AgAAAAAAAAA+YbDV9pKkp+fn4YNG5bTuQAAAAAAAABAvndDTdszZ87oiy++0O7duyVJFStWVPfu3VW4cOEcTQ4AAAAAAAAA8huHp0dYt26dSpcurUmTJunMmTM6c+aMJk2apNDQUK1bty43cgQAAAAAAACAfMPhK20jIyP1xBNPaMqUKbJarZKktLQ09e3bV5GRkfrrr79yPEkAAAAAAAAAyC8cvtJ23759GjJkiNmwlSSr1arBgwdr3759OZocAAAAAAAAAOQ3Djdta9SoYc5le6Xdu3erWrVqOZIUAAAAAAAAAORX2ZoeYfv27ea/+/fvrwEDBmjfvn2qW7euJOn333/X5MmT9fbbb+dOlgAAAAAAAACQT1gMwzCuN8jFxUUWi0XXG2qxWJSWlpZjyTmLhIQE+fn5KT4+Xr6+vnmdDgAAt5WvatTQ8W3b8joNXEdg9ep6auvWvE4DAAAAuKNlt8+YrStto6OjcywxAAAAAAAAAEDWstW0LVWqVG7nAQAAAAAAAABQNpu2V4uNjdWvv/6q48ePy2az2S3r379/jiQGAAAAAAAAAPmRw03b6dOn69lnn5W7u7uKFCkii8ViLrNYLDRtAQAAAAAAAOAmONy0ff311zV8+HC98sorcnFxyY2cAAAAAAAAACDfcrjreuHCBXXs2DFHGrbr1q1TmzZtFBISIovFooULF9otNwxDw4cPV7FixeTp6almzZrpn3/+sRtz+vRpde7cWb6+vvL391fPnj11/vx5uzHbt29Xw4YNVaBAAZUoUULjxo276dwBAAAAAAAAIDc43Hnt2bOn5s6dmyM7T0xMVLVq1TR58uRMl48bN06TJk3SJ598oo0bN8rb21vh4eG6dOmSOaZz587auXOnVq5cqcWLF2vdunXq3bu3uTwhIUEtWrRQqVKltGXLFo0fP14jR47Up59+miM1AAAAAAAAAEBOshiGYTiyQlpamh566CFdvHhRVapUkZubm93y995778YSsVi0YMECtW3bVtLlq2xDQkI0ZMgQvfDCC5Kk+Ph4BQUFafr06erYsaN2796tihUratOmTapVq5YkadmyZWrdurUOHz6skJAQTZkyRcOGDVNcXJzc3d0lSS+//LIWLlyov//+O1u5JSQkyM/PT/Hx8fL19b2h+gAAyK++qlFDx7dty+s0cB2B1avrqa1b8zoNp3Tu3Dm9/vrrWrBggY4fP67q1atr4sSJql27tiSpW7dumjFjht064eHhWrZsmV1syZIlGj16tLZv364CBQqocePGGb5pBgAAgDtbdvuMDs9p+9Zbb2n58uW65557JCnDjchySnR0tOLi4tSsWTMz5ufnpzp16mjDhg3q2LGjNmzYIH9/f7NhK0nNmjWTi4uLNm7cqEcffVQbNmxQo0aNzIatdPmX6HfeeUdnzpxRoUKFMuw7KSlJSUlJ5uOEhARJUmpqqlJTUyVJLi4ucnFxkc1mk81mM8emx9PS0nRlPzyruNVqlcViMbd7ZVy63CTPTtzV1VWGYdjFLRaLrFZrhhyzilMTNVETNVETNeVGTbJYZLnic1iGISMlRXJxkcXVNWPcapXl/7cnSYbNJqWmSq6uslwxPZORlialpcni5iZd8TuIkZoq2WxZx6/MRbq8T8PIGE9Ovpz7VX+gNpKTs879dq7pquN9J5x7OfV66tmzp3bu3Knp06erWLFimj17tpo1a6a//vpLISEhstlsCg8P15dffmnW5O7ubtZgtVr1/fffq1evXnrjjTfUpEkTpaamavfu3RlyvFU13YnHiZqoiZqoiZqoiZqo6Xao6eoxWXG4aTthwgR9+eWX6tatm6OrOiQuLk6SFBQUZBcPCgoyl8XFxSkwMNBuuaurqwoXLmw3JjQ0NMM20pdl1rR96623NGrUqAzxbdu2ydvbW5IUEBCgMmXKKDo6WidOnDDHFC9eXMWLF9fevXsVHx9vxsPCwhQYGKgdO3bo4sWLZrx8+fLy9/fXtm3b7A5g1apV5e7urs2bN9vlUKtWLSUnJ2v79u1mzGq1qnbt2oqPj7e7etjT01PVqlXTyZMndeDAATPu5+enChUqKDY2VocPHzbj1ERN1ERN1ERNuVGTS1CQglu1MuOpJ0/qxNSp8qpaVX4REWY86cABnZ49Wz7166tgw4Zm/EJUlOKXLJFfeLi87r3XjJ//5RedW7dOhTp0kEdYmBmPX7JEF6KiVLRHD7kWLWrGT8+eraQDBxQ0YIBdM/PE1KlKS0hQ8NChdjXFjR8vq6+vAp591owZycmKGz9eHqVLq3CnTndUTS5BQXbH9U4493Li9RQSEqLvv/9e77zzjjw9PXX27Fn16tVLixcv1tixY9WtWzedOnVKFy9elKurqwIDA/Xnn3/a1VS2bFkNGDBAffv2Vc2aNc0LAtq0aaO0tLR8/x5BTdRETdRETdRETdSUn2pKTExUdjg8PUJwcLB++eUXlStXzpHVrp/IVdMj/Pbbb6pfv75iY2NVrFgxc9zjjz8ui8Wib7/9VmPHjtWMGTO0Z88eu20FBgZq1KhR6tOnj1q0aKHQ0FBNnTrVXL5r1y5VqlRJu3btUoUKFTLkktmVtiVKlNCpU6fMy5b56wI1URM1URM1UVP2avqqZk2d2LHjv+CdcFVqVrnfxjUF1qihJzduNGN3wrmXE6+nxMRE+fr6avny5XrwwQfNeKNGjWS1WrV69Wr16NFDixYtkru7uwoVKqQmTZpo1KhRKlKkiCRpy5Ytqlu3rj777DN99NFHOnbsmKpVq6bx48ercuXK+f49gpqoiZqoiZqoiZqoKT/VlJCQoCJFiuT89AgDBgzQhx9+qEmTJjm6qkOCg4MlSceOHbNr2h47dkz3/v8VKcHBwTp+/LjdeqmpqTp9+rS5fnBwsI4dO2Y3Jv1x+pireXh4yMPDI0Pc1dX18tc8r5B+sK6WflCyG796uzcSt1gsmcazytHRODVRU1ZxaqImiZqyytHR+J1YkwzjcrPwajZb5vG0tMvNy6ulpiqzvzQbKSmZ5pJlPLN9ZhV3NPfbuSbDuOPOvZx4Pfn4+KhevXoaO3asKleurKCgIM2aNUsbNmxQ2bJl5erqqtatW6tDhw4KDQ3V/v379eqrr6pNmzbasGGDrFaroqOjJUlvvPGG3nvvPZUuXVoTJkxQkyZNtHfvXhUuXPiW1nSt+O16nK4VpyZqyipOTdQkUVNWOToapyZqkqgpqxyvjmc1JsM62Rp1hT/++ENr1qzR4sWLValSpQw3Ivv+++8d3WSmQkNDFRwcrNWrV5tN2oSEBG3cuFF9+vSRJNWrV09nz57Vli1bVLNmTUnSmjVrZLPZVKdOHXPMsGHDlJKSYua6cuVK3XPPPZlOjQAAAABc6euvv1aPHj101113yWq1qkaNGurUqZO2bNkiSerYsaM5tkqVKqpatarKlCmjn376SU2bNjWv2hg2bJjat28vSZo2bZqKFy+uuXPn6tkrpqsAAAAAJCljC/k6/P391a5dOzVu3FhFixaVn5+f3Y8jzp8/r6ioKEVFRUm6fPOxqKgoxcTEyGKxaODAgXrzzTe1aNEi/fXXX3rqqacUEhJiTqFQoUIFtWzZUr169dIff/yh9evXq1+/furYsaNCQkIkSU8++aTc3d3NG0h8++23mjhxogYPHuxo6QAAAMiHypQpo59//lnnz5/Xv//+qz/++EMpKSkKu2Le4SuFhYWpaNGi2rdvnySZ3xqrWLGiOcbDw0NhYWGKiYnJ/QIAAABw23H4Sttp06bl2M43b96sJk2amI/TG6lPP/20pk+frhdffFGJiYnq3bu3zp49qwYNGmjZsmUqUKCAuc7MmTPVr18/NW3aVC4uLmrfvr3d1A1+fn5asWKFIiMjVbNmTRUtWlTDhw9X7969c6wOAAAA3Pm8vb3l7e2tM2fOaPny5Ro3blym4w4fPqxTp06ZzdqaNWvKw8NDe/bsUYMGDSRJKSkpOnjwoEqVKnXL8gcAAMDtw+EbkeVHCQkJ8vPzu+4EwQAAIKOvatTQ8W3b8joNXEdg9ep6auvWvE7DKS1fvlyGYeiee+7Rvn37NHToUBUoUEC//PKLkpKSNGrUKLVv317BwcHav3+/XnzxRZ07d05//fWXeZ+EgQMHat68efryyy9VqlQpjR8/Xj/++KP+/vtvpuwCAADIR7LbZ3T4StvQ0FBZrrhr8dUOHDjg6CYBAAAApxUfH69XXnlFhw8fVuHChdW+fXuNGTNGbm5uSk1N1fbt2zVjxgydPXtWISEhatGihd544w27G9uOHz9erq6u6tq1qy5evKg6depozZo1NGwBAACQKYevtJ04caLd45SUFG3btk3Lli3T0KFD9fLLL+dogs6AK20BALhxXGl7e+BKWwAAACD35dqVtgMGDMg0PnnyZG3evNnRzQEAAAAAAAAAruCSUxtq1aqV5s+fn1ObAwAAAAAAAIB8KceatvPmzVPhwoVzanMAAAC4g6XZuBfu7YTjBQAAcGs5PD1C9erV7W5EZhiG4uLidOLECX388cc5mhwAAADuTFYXi8ZMO6mYuJS8TgXXUTLYTcO6F83rNAAAAPIVh5u2bdu2tXvs4uKigIAAPfDAAypfvnxO5QUAAIA7XExciv75l6YtAAAAcDWHm7YjRozIjTwAAAAAAAAAAMrBOW0BAAAAAAAAADcv21fauri42M1lmxmLxaLU1NSbTgoAAAAAAAAA8qtsN20XLFiQ5bINGzZo0qRJstlsOZIUAAAAAAAAAORX2W7aPvLIIxlie/bs0csvv6wff/xRnTt31ujRo3M0OQAAAAAAAADIb25oTtvY2Fj16tVLVapUUWpqqqKiojRjxgyVKlUqp/MDAAAAAAAAgHzFoaZtfHy8XnrpJZUtW1Y7d+7U6tWr9eOPP6py5cq5lR8AAAAAAAAA5CvZnh5h3LhxeueddxQcHKzZs2dnOl0CAAAAAAAAAODmZLtp+/LLL8vT01Nly5bVjBkzNGPGjEzHff/99zmWHAAAAAAAAADkN9lu2j711FOyWCy5mQsAAAAAAAAA5HvZbtpOnz49F9MAAAAAAAAAAEgO3ogMAAAAAAAAAJC7aNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAAAAAAAAgBOhaQsAAAAAAAAAToSmLQAAAAAAAAA4EZq2AAAAAAAAAOBEaNoCAPKN0qVLy2KxZPiJjIyUJF26dEmRkZEqUqSIChYsqPbt2+vYsWMZtjN9+nRVrVpVBQoUUGBgoLk+AAAAAAA5wTWvEwAA4FbZtGmT0tLSzMc7duxQ8+bN9dhjj0mSBg0apCVLlmju3Lny8/NTv3791K5dO61fv95c57333tOECRM0fvx41alTR4mJiTp48OCtLgUAAAAAcAejaQsAyDcCAgLsHr/99tsqU6aMGjdurPj4eH3xxReaNWuWHnzwQUnStGnTVKFCBf3++++qW7euzpw5o9dee00//vijmjZtam6natWqt7QOAAAAAMCdjekRAAD5UnJysr755hv16NFDFotFW7ZsUUpKipo1a2aOKV++vEqWLKkNGzZIklauXCmbzaYjR46oQoUKKl68uB5//HH9+++/eVUGAAAAAOAORNMWAJAvLVy4UGfPnlW3bt0kSXFxcXJ3d5e/v7/duKCgIMXFxUmSDhw4IJvNprFjx+qDDz7QvHnzdPr0aTVv3lzJycm3uAIAAAAAwJ2Kpi0AIF/64osv1KpVK4WEhGR7HZvNppSUFE2aNEnh4eGqW7euZs+erX/++Udr167NxWwBAAAAAPkJc9oCAPKdQ4cOadWqVfr+++/NWHBwsJKTk3X27Fm7q22PHTum4OBgSVKxYsUkSRUrVjSXBwQEqGjRooqJibk1yQMAAAAA7nhcaQsAyHemTZumwMBARUREmLGaNWvKzc1Nq1evNmN79uxRTEyM6tWrJ0mqX7++GU93+vRpnTx5UqVKlbpF2QMAAAAA7nRcaQsAyFdsNpumTZump59+Wq6u/30M+vn5qWfPnho8eLAKFy4sX19fPf/886pXr57q1q0rSbr77rv1yCOPaMCAAfr000/l6+urV155ReXLl1eTJk3yqiQAAAAAwB2Gpi0AIF9ZtWqVYmJi1KNHjwzL3n//fbm4uKh9+/ZKSkpSeHi4Pv74Y7sxX331lQYNGqSIiAi5uLiocePGWrZsmdzc3G5VCQAAAACAOxxNWwBAvtKiRQsZhpHpsgIFCmjy5MmaPHlyluv7+vrqiy++0BdffJFbKQIAAAAA8jnmtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAMBNS0uz5XUKcADHCwAAAACcG3PaAgBumtXqos6dl2j37lN5nQquo0KFIpo5MyKv0wAAAAAAXANNWwBAjti9+5S2bTue12kAAAAAAHDbY3oEAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwInQtAUAAAAAAAAAJ0LTFgAAAAAAAACcCE1bAAAAAAAAAHAiNG0BAAAAAAAAwIk4ddN25MiRslgsdj/ly5c3l1+6dEmRkZEqUqSIChYsqPbt2+vYsWN224iJiVFERIS8vLwUGBiooUOHKjU19VaXAgAAAAAAAADZ4prXCVxPpUqVtGrVKvOxq+t/KQ8aNEhLlizR3Llz5efnp379+qldu3Zav369JCktLU0REREKDg7Wb7/9pqNHj+qpp56Sm5ubxo4de8trAQAAAAAAAIDrcfqmraurq4KDgzPE4+Pj9cUXX2jWrFl68MEHJUnTpk1ThQoV9Pvvv6tu3bpasWKFdu3apVWrVikoKEj33nuv3njjDb300ksaOXKk3N3db3U5AAAAAAAAAHBNTj09giT9888/CgkJUVhYmDp37qyYmBhJ0pYtW5SSkqJmzZqZY8uXL6+SJUtqw4YNkqQNGzaoSpUqCgoKMseEh4crISFBO3fuvLWFAAAAAAAAAEA2OPWVtnXq1NH06dN1zz336OjRoxo1apQaNmyoHTt2KC4uTu7u7vL397dbJygoSHFxcZKkuLg4u4Zt+vL0ZVlJSkpSUlKS+TghIUGSlJqaas6H6+LiIhcXF9lsNtlsNnNsejwtLU2GYVw3brVaZbFYMsyza7VaJV2e4iE7cVdXVxmGYRe3WCyyWq0ZcswqTk3URE3UdDM1Wa2Su7vFjKemGrLZJDc3iyz/hc34lWMlKSXFkGFkjCcnG7JYLm/n6riLi+Tq+l/cMC5vJ6u41SpZrf/FbTZDqamSq6vk4vJfPC3NUFpa1rnfzjVZrbI7n27FuSeLRZYrv91iGDJSUiQXF1mumPbIjFutsvz/9iTJsNmUXpTF5b+/NxtpaVJamixubrrygBipqZLNlnX8qm/aGCkpkmFkjCcnX87dzS1jPKvcb+earjret+J9T5KsLjZd+UpIs1lkyCJXF5uulGq7PMrVxchm3EUWGbJeETckpdlcZLEYsloyxl0shlyuiNsMyWa4yMVi0xUvJ9kMi2yGJWPuhkVGZvHbvCZJt/Xn0534mUtN1ERN1ERN1ERNt29N2b3XllM3bVu1amX+u2rVqqpTp45KlSql7777Tp6enrm237feekujRo3KEN+2bZu8vb0lSQEBASpTpoyio6N14sQJc0zx4sVVvHhx7d27V/Hx8WY8LCxMgYGB2rFjhy5evGjGy5cvL39/f23bts3uAFatWlXu7u7avHmzXQ61atVScnKytm/fbsasVqtq166t+Ph4/f3332bc09NT1apV08mTJ3XgwAEz7ufnpwoVKig2NlaHDx8249RETdRETTdTU8OGHgoP/286myVL4hUVdUE9ehRV0aL/fdzMnn1aBw4kacCAILtm5tSpJ5SQkKahQ+2nxBk/Pk6+vlY9+2yAGUtONjR+fJxKl/ZQp06FzfjJk6maOvWEqlb1UkSEnxk/cCBJs2efVv36PmrYsKAZj4q6oCVL4hUe7qd77/Uy47/8cl7r1p1Thw6FFBbmcUfV1LChh915cyvOPZegIAVf8ZmeevKkTkydKq+qVeUXEWHGkw4c0OnZs+VTv74KNmxoxi9ERSl+yRL5hYfL6957zfj5X37RuXXrVKhDB3mEhZnx+CVLdCEqSkV79JBr0aJm/PTs2Uo6cEBBAwbYNTNPTJ2qtIQEBQ8daldT3Pjxsvr6KuDZZ82YkZysuPHj5VG6tAp36nRH1eQSFGR3XG/F+54kNbrniAoWSDbjv+8rphPnvNS8yiG7JudPu0voYrKrWlWLtqtp6Z+h8nRP1QMV/jVjqTYXLf0zVEV9Lqpu2aP/Pb+X3LV2dwmVKHxO1Ur+l+OJc176fV8xlQs+o7uDz5jxmFM++jMmUFVKnFTJIufM+N64QtpztLBqhx1TgM8FM/5nTIBiTvnecTVJRW7rz6c78TOXmqiJmqiJmqiJmm7fmhITE5UdFuPKtvBtoHbt2mrWrJmaN2+upk2b6syZM3ZX25YqVUoDBw7UoEGDNHz4cC1atEhRUVHm8ujoaIWFhWnr1q2qXr16pvvI7ErbEiVK6NSpU/L19ZXEXxeoiZqoiZqujteu/ZW2b//vQ+5OuCr1TrzStlatQG3Y8KQZvxXn3lc1a+rEjh3/Be+Eq1LvwCttA2vU0JMbN5qxW/G+1+edYzpwJOmOuir1TrzStmxxd338YuBt+/l0J37mUhM1URM1URM1UdPtW1NCQoKKFCmi+Ph4s8+YGae+0vZq58+f1/79+9W1a1fVrFlTbm5uWr16tdq3by9J2rNnj2JiYlSvXj1JUr169TRmzBgdP35cgYGBkqSVK1fK19dXFStWzHI/Hh4e8vDwyBB3dXW9/DXPK6QfrKulH5Tsxq/e7o3ELRZLpvGscnQ0Tk3UlFWcmqhJktLSLjcdr5aSkvnfBjMbm1XcMDKP22yOxS/3wzLGL3+uZj/327mmtLTMz4/cPPdkGJebhVez2TKPp6Vdbl5eLTU1k4r+v0HpSDyzfWYVdzT327kmw8iT9700W+a3WEjNMm7JdtyQJfO4YVGqkTGe3rjMGHeRLZMDlVXud2JNt/Pn0534mUtN1JRVnJqoSaKmrHJ0NE5N1CTlTk1ZjcmwTrZG5ZEXXnhBbdq0UalSpRQbG6sRI0bIarWqU6dO8vPzU8+ePTV48GAVLlxYvr6+ev7551WvXj3VrVtXktSiRQtVrFhRXbt21bhx4xQXF6fXXntNkZGRmTZlAQAAAAAAACCvOXXT9vDhw+rUqZNOnTqlgIAANWjQQL///rsCAi7PAfj+++/LxcVF7du3V1JSksLDw/Xxxx+b61utVi1evFh9+vRRvXr15O3traefflqjR4/Oq5IAAAAAAAAA4Jqcumk7Z86cay4vUKCAJk+erMmTJ2c5plSpUvrf//6X06kBAADgJpUMdrv+IOQ5jhMAAMCt59RNWwAAANyZ0myGhnUvmtdpIJvSbIasLpnPvQsAAICcR9MWAAAAt5zVxSJ9P106GZfXqeB6igbL2q5bXmcBAACQr9C0BQAAQN7YsVmK2ZfXWeB6SpaVaNoCAADcUi55nQAAAAAAAAAA4D80bQEAAAAAAADAidC0BQAAAAAAAAAnQtMWAAAAAAAAAJwITVsAAAAAAAAAcCI0bQEAAADAQVOmTFHVqlXl6+srX19f1atXT0uXLjWXx8XFqWvXrgoODpa3t7dq1Kih+fPn222jdOnSslgsdj9vv/32rS4FAAA4of9r777DorjaNoDfS5MiiggI2AApggpix46xYMEeaxQLRiOKig0TC2qw19hNVGzYe41oFHtBwRawd7EiRens+f7wY8IKqMkr7LLcv+vySvbMmdlndh7O7j57ZkZL2QEQEREREREVNGXKlMGMGTNgZ2cHIQTWrl2Ldu3aITw8HJUqVULv3r0RGxuLvXv3wsTEBMHBwejSpQvCwsLg6uoqbWfKlCkYMGCA9NjQ0FAZu0NEREQqhjNtiYiIiIiI/iVPT0+0atUKdnZ2sLe3R2BgIIoWLYrz588DAM6ePYuhQ4eiVq1asLGxwfjx42FkZITLly8rbMfQ0BDm5ubSPwMDA2XsDhEREakYFm2JiIiIiIj+BxkZGdi8eTM+fPgANzc3AEDdunWxZcsWxMTEQC6XY/PmzUhOTkbjxo0V1p0xYwZKliwJV1dXzJ49G+np6UrYAyIiIlI1vDwCERERERHRf3D9+nW4ubkhOTkZRYsWxa5du+Dk5AQA2Lp1K7p27YqSJUtCS0sL+vr62LVrF2xtbaX1fX19Ua1aNRgbG+Ps2bMYN24coqOjMW/ePGXtEhEREakIFm2JiIiIiIj+AwcHB0RERCAuLg7bt2+Hl5cXQkND4eTkhAkTJiA2NhZHjx6FiYkJdu/ejS5duuDUqVOoUqUKAMDPz0/alrOzM3R0dDBw4EBMnz4dRYoUUdZuERERkQpg0ZaIiIiIiOg/0NHRkWbOVq9eHZcuXcLChQsxZswYLF68GDdu3EClSpUAAC4uLjh16hSWLFmC5cuX57i92rVrIz09HQ8fPoSDg0O+7QcRERGpHl7TloiIiIiI6BuQy+VISUlBYmIiAEBDQ/HrlqamJuRyea7rR0REQENDA2ZmZnkaJxEREak+zrQlIiIiIiL6l8aNG4eWLVuiXLlySEhIQHBwME6cOIE///wTFStWhK2tLQYOHIg5c+agZMmS2L17N0JCQrB//34AwLlz53DhwgW4u7vD0NAQ586dw4gRI/DDDz+gRIkSSt47IiIiUjYWbYmIiIiIiP6lV69eoXfv3oiOjkbx4sXh7OyMP//8E82aNQMAHDx4EP7+/vD09MT79+9ha2uLtWvXolWrVgCAIkWKYPPmzQgICEBKSgqsra0xYsQIhevcEhERUeHFoi0REREREdG/tGrVqs8ut7Ozw44dO3JdXq1aNZw/f/5bh0VERERqgte0JSIiIiIiIiIiIlIhLNoSERERERERERERqRAWbYmIiIiISGVkyIWyQ6B/gceLiIgob/CatkREREREpDI0NWQIXPMGj1+kKTsU+oJy5tr4pa+JssMgIiJSSyzaEhERERGRSnn8Ig13nrBoS0RERIUXL49AREREREREREREpEJYtCUiIiIiIiIiIiJSISzaEhEREREREREREakQFm2JiIiIiIiIiIiIVAiLtkREREREREREREQqhEVbIiIiIiIiIiIiIhXCoi0RERERERERERGRCmHRloiIiIiIiIiIiEiFsGhLREREREREREREpEJYtCUiIiIiIiIiIiJSISzaEhEREREREREREakQFm2JiIiIiIiIiIiIVAiLtkREREREREREREQqhEVbIiIiIiIiIiIiIhWipewAiIhIPTg6llR2CPQVeJyIiIiIiIhUH4u2RET0P8vIkGPjxtbKDoO+UkaGHJqaPNmGiIiIiIhIVbFoS0RE/zNNTQ2c+uUXxD14oOxQ6AuKW1ujQWCgssMgIiIiIiKiz2DRloiIvokHhw7hVXi4ssOgLzBzdWXRloiIiIiISMXx3EgiIiIiIiIiIiIiFcKiLREREREREREREZEKYdGWiIiIiIiIiIiISIWwaEtERERERERERESkQli0JSIiIiIiIiIiIlIhLNoSERERERERERERqRAWbYmIiIiIiIiIiIhUCIu2RERERERERERERCqERVsiIiIiIiIiIiIiFcKiLREREREREREREZEKYdGWiIiIiIiIiIiISIWwaEtERERERERERESkQli0JSIiIiIiIiIiIlIhLNoSkVo6efIkPD09YWlpCZlMht27dyssf/nyJfr06QNLS0vo6+vDw8MDd+7ckZbHxMRg6NChcHBwgJ6eHsqVKwdfX1/ExcXl854QERERERERUWHDoi0RqaUPHz7AxcUFS5YsybZMCIH27dvj/v372LNnD8LDw1G+fHk0bdoUHz58AAA8f/4cz58/x5w5c3Djxg0EBQXh8OHD6N+/f37vChEREREREREVMlrKDoCIKC+0bNkSLVu2zHHZnTt3cP78edy4cQOVKlUCACxbtgzm5ubYtGkTvL29UblyZezYsUNap0KFCggMDMQPP/yA9PR0aGlx+CQiIiIiIiKivMGZtkRU6KSkpAAAdHV1pTYNDQ0UKVIEp0+fznW9uLg4FCtWjAVbIiIiIiIiIspTLNoSUaFTsWJFlCtXDuPGjcO7d++QmpqKmTNn4unTp4iOjs5xnTdv3mDq1Kn48ccf8zlaIiIiIiIiIipsWLQlokJHW1sbO3fuxO3bt2FsbAx9fX0cP34cLVu2hIZG9mExPj4erVu3hpOTEwICAvI/YCIiIiIiIiIqVFi0JaJCqXr16oiIiEBsbCyio6Nx+PBhvH37FjY2Ngr9EhIS4OHhAUNDQ+zatQva2tpKipiIiIiICoKTJ0/C09MTlpaWkMlk2L17d7Y+kZGRaNu2LYoXLw4DAwPUrFkTjx8/Vuhz7tw5NGnSBAYGBihWrBgaNmyIpKSkfNoLIiJSNhZtiahQK168OExNTXHnzh2EhYWhXbt20rL4+Hg0b94cOjo62Lt3r8I1cImIiIiIcvLhwwe4uLhgyZIlOS6/d+8e6tevj4oVK+LEiRO4du0aJkyYoPBZ89y5c/Dw8EDz5s1x8eJFXLp0CUOGDMnxrDAiIlJPvJsOEaml9+/f4+7du9LjBw8eICIiAsbGxihXrhy2bdsGU1NTlCtXDtevX8ewYcPQvn17NG/eHMA/BdvExERs2LAB8fHxiI+PBwCYmppCU1NTKftFRERERKqtZcuWaNmyZa7Lf/nlF7Rq1QqzZs2S2ipUqKDQZ8SIEfD19YW/v7/U5uDg8O2DJSIilcWf6YhILYWFhcHV1RWurq4AAD8/P7i6umLixIkAgOjoaPTq1QsVK1aEr68vevXqhU2bNknrX7lyBRcuXMD169dha2sLCwsL6d+TJ0+Usk9EREREVLDJ5XIcOHAA9vb2aNGiBczMzFC7dm2FSyi8evUKFy5cgJmZGerWrYtSpUqhUaNGOH36tPICJyKifMeiLRGppcaNG0MIke1fUFAQAMDX1xdPnjxBamoqHj16hKlTp0JHR+eL6wshYGVlpZydIiIiIqIC7dWrV3j//j1mzJgBDw8PHDlyBB06dEDHjh0RGhoKALh//z4AICAgAAMGDMDhw4dRrVo1fPfdd7hz544ywycionzEyyMQEREREZFKKWfOG38WBDxO/55cLgcAtGvXDiNGjAAAVK1aFWfPnsXy5cvRqFEjqc/AgQPRt29fAICrqyuOHTuG1atXY/r06coJnoiI8hWLtkREREREpDIy5AK/9DVRdhj0lTLkApoaMmWHUWCYmJhAS0sLTk5OCu2Ojo7S5Q8sLCwAIMc+jx8/zp9AiYhI6Vi0JaJ/JSNDDk1NXlmloODxIiKigkZTQwbsDALevFB2KPQlJubQ7NhH2VEUKDo6OqhZsyZu3bql0H779m2UL18eAGBlZQVLS8sc+3zuBmdERKReWLQlon9FU1MDPXseQGTkW2WHQl/g6FgSGze2VnYYRERE/96NMODxXWVHQV9SzhZg0Tab9+/f4+7df/L3wYMHiIiIgLGxMcqVK4fRo0eja9euaNiwIdzd3XH48GHs27cPJ06cAADIZDKMHj0akyZNgouLC6pWrYq1a9ciKioK27dvV9JeERFRfmPRloj+tcjItwgPf6XsMIiIiIiIVE5YWBjc3d2lx35+fgAALy8vBAUFoUOHDli+fDmmT58OX19fODg4YMeOHahfv760zvDhw5GcnIwRI0YgJiYGLi4uCAkJQYUKFfJ9f4iISDlYtCUiIiIiIiL6Rho3bgwhxGf79OvXD/369ftsH39/f/j7+3/L0IiIqADhhQ6JiIiIiIiIiIiIVAiLtkREREREREREREQqhEVbIiIiIiIiUnkZGXJlh0D/Ao8XEdH/hte0JSIiIiIiIpWnqamBnj0PIDLyrbJDoS9wdCyJjRtbKzsMIqICjUVbIiIiIiIiKhAiI98iPPyVssMgIiLKc7w8AhEREREREREREZEKYdGWiIiIiIiIiIiISIWwaEtERERERERERESkQli0JSIiIiIiIiIiIlIhLNoSEREREREREeWzjIwMTJgwAdbW1tDT00OFChUwdepUCCGkPgEBAahYsSIMDAxQokQJNG3aFBcuXFBi1ESUX7SUHQARERERERERUWEzc+ZMLFu2DGvXrkWlSpUQFhaGvn37onjx4vD19QUA2NvbY/HixbCxsUFSUhLmz5+P5s2b4+7duzA1NVXyHhBRXmLRloiIiIiIiIgon509exbt2rVD69atAQBWVlbYtGkTLl68KPXp0aOHwjrz5s3DqlWrcO3aNXz33Xf5Gi8R5S9eHoGIiIiIiIiIKJ/VrVsXx44dw+3btwEAV69exenTp9GyZcsc+6empmLlypUoXrw4XFxc8jNUIlICzrQlIiIiIiIiIspn/v7+iI+PR8WKFaGpqYmMjAwEBgaiZ8+eCv3279+Pbt26ITExERYWFggJCYGJiYmSoiai/MKZtkRERERERERE+Wzr1q3YuHEjgoODceXKFaxduxZz5szB2rVrFfq5u7sjIiICZ8+ehYeHB7p06YJXr14pKWoiyi8s2pJaCQgIgEwmU/hXsWJFafmLFy/Qq1cvmJubw8DAANWqVcOOHTuUGDEREREREREVRqNHj4a/vz+6deuGKlWqoFevXhgxYgSmT5+u0M/AwAC2traoU6cOVq1aBS0tLaxatUpJURNRfuHlEUjtVKpUCUePHpUea2n9k+a9e/dGbGws9u7dCxMTEwQHB6NLly4ICwuDq6urMsIlIiIiIiKiQigxMREaGopz6TQ1NSGXyz+7nlwuR0pKSl6GRkQqgEVbUjtaWlowNzfPcdnZs2exbNky1KpVCwAwfvx4zJ8/H5cvX2bRloiIiIiIiPKNp6cnAgMDUa5cOVSqVAnh4eGYN28e+vXrBwD48OEDAgMD0bZtW1hYWODNmzdYsmQJnj17hu+//17J0RNRXuPlEUjt3LlzB5aWlrCxsUHPnj3x+PFjaVndunWxZcsWxMTEQC6XY/PmzUhOTkbjxo2VFzAREREREREVOosWLULnzp0xePBgODo6YtSoURg4cCCmTp0K4OOs26ioKHTq1An29vbw9PTE27dvcerUKVSqVEnJ0RNRXuNMW1IrtWvXRlBQEBwcHBAdHY3JkyejQYMGuHHjBgwNDbF161Z07doVJUuWhJaWFvT19bFr1y7Y2toqO3QiIiIiIiIqRAwNDbFgwQIsWLAgx+W6urrYuXNn/gZFRCqDRVtSKy1btpT+39nZGbVr10b58uWxdetW9O/fHxMmTEBsbCyOHj0KExMT7N69G126dMGpU6dQpUoVJUZesDg6llR2CPQVeJyIiIiIiIiICiYWbUmtGRkZwd7eHnfv3sW9e/ewePFi3LhxQzqVxMXFBadOncKSJUuwfPlyJUdbMGRkyLFxY2tlh0FfKSNDDk1NXgmHiIiIiIiIqCBh0ZbU2vv373Hv3j306tULiYmJAPCf7s5J/9DU1MCpX35B3IMHyg6FvqC4tTUaBAYqOwwiIiIiojzFiQoFC48X0ddh0ZbUyqhRo+Dp6Yny5cvj+fPnmDRpEjQ1NdG9e3cYGRnB1tYWAwcOxJw5c1CyZEns3r0bISEh2L9/v7JDL1AeHDqEV+Hhyg6DvsDM1ZVFWyIiIiJSe5qaGujZ8wAiI98qOxT6AkfHkjxz8ytMnz4dO3fuRFRUFPT09FC3bl3MnDkTDg4O2foKIdCqVSscPnwYu3btQvv27fM/YMoTLNqSWnn69Cm6d++Ot2/fwtTUFPXr18f58+dhamoKADh48CD8/f3h6emJ9+/fw9bWFmvXrkWrVq2UHDkREREREX0Jr9lfMCjjOEVGvkV4+Kt8f16ivBAaGgofHx/UrFkT6enp+Pnnn9G8eXP8/fffMDAwUOi7YMECyGQyJUVKeYlFW1Irmzdv/uxyOzs77NixI5+iISIiIiKib4X3VihYeAo80X93+PBhhcdBQUEwMzPD5cuX0bBhQ6k9IiICc+fORVhYGCwsLPI7TMpjLNoSERERERGRyuO9FQoO3luB6NuKi4sDABgbG0ttiYmJ6NGjB5YsWQJzc3NlhUZ5iEVbIiIiIiIiKhB4b4WCgfdWIPp25HI5hg8fjnr16qFy5cpS+4gRI1C3bl20a9dOidFRXmLRlnKUIRfQ1OA1UQoKHi8iIiIiIiIi9ePj44MbN27g9OnTUtvevXvx119/IZw/Yqk1Fm0pR5oaMgSueYPHL9KUHQp9QTlzbfzS10TZYRARERERERHRNzRkyBDs378fJ0+eRJkyZaT2v/76C/fu3YORkZFC/06dOqFBgwY4ceJE/gZKeYJFW8rV4xdpuPOERVsiIiIiIiIiovwihMDQoUOxa9cunDhxAtbW1grL/f394e3trdBWpUoVzJ8/H56envkZKuUhFm2JiIiIiIiIqEBzdCyp7BDoK/A4fR0fHx8EBwdjz549MDQ0xIsXLwAAxYsXh56eHszNzXO8+Vi5cuWyFXip4GLRloiIiIiIiIgKrIwMOTZubK3sMOgrZWTIoampoewwVNqyZcsAAI0bN1ZoX7NmDfr06ZP/AZFSsGhLRERERERERAWWpqYGTv3yC+IePFB2KPQFxa2t0SAwUNlhqDwhRL6sQ6qNRVvKVTlzbWWHQF+Bx4mIiIiIiAq7B4cO4VV4uLLDoC8wc3Vl0ZboK7FoSznKkAv80tdE2WHQV8qQC2hqyJQdBhERERERERERfQMs2lKONDVkwM4g4M0LZYdCX2JiDs2OfZQdBREREREREZFK4fVzCxYeL0WFqmi7ZMkSzJ49Gy9evICLiwsWLVqEWrVqKTss1XUjDHh8V9lR0JeUswVYtCUiIiIiIiJSoKmpgZ49DyAy8q2yQ6EvcHQsyRsKfqLQFG23bNkCPz8/LF++HLVr18aCBQvQokUL3Lp1C2ZmZsoOj4iIiIiIiIiIvrHIyLcID3+l7DCI/rVCM+d43rx5GDBgAPr27QsnJycsX74c+vr6WL16tbJDIyIiIiIiIiIiIpIUipm2qampuHz5MsaNGye1aWhooGnTpjh37pwSIyMiIiIiIiIiorzi6FhS2SHQV+Bxyq5QFG3fvHmDjIwMlCpVSqG9VKlSiIqKytY/JSUFKSkp0uO4uDgAQExMDNLT0wF8LPpqaGhALpdDLpdLfTPbMzIyIIT4YrumpiZkMpm03aztAJCRkfFV7VpaWhBCKLTLZDJoampmizG39mz7ZGQGpKRDQwhoQCBDpgGR5Tlza9cUcsgApMsUJ3Jrio/PlfGV7VpCDvFJu+z/+8shg1wm+2K7BgQ0hIBcJsPHqD4fe4HcJyMzICYmX3NP194ehpkxpacDMhnw/8sBAEIAGRm5t2tofPyXSS7/+C+3dk3Nj9vKlJHxcVu5tWt9MrRl7uO/aVeDfdK1s0NMTMz/P8yDMeKTdl07u3/yIo/2KVu7Ghyn/N6nrHkB5M/7U7bc4HFSyX36NDe+9RiR4/uTkSkyUtILzntuZrs6fY74mn0yMkXGu3f5+xnWyBTy5DQeJ1XfJyNTyGNj826MyKFd184OhhkZHMtVfJ90bW0RHx+fr99zpdzgcVLpfcrMjbwaIz59f5LL5Vi0yE01aizfaJ++FHtB3qeYmHfQ1NRQq33KKfb4+HgAUFg/JzLxpR5q4Pnz5yhdujTOnj0LNzc3qX3MmDEIDQ3FhQsXFPoHBARg8uTJ+R0mERERERERERERFQJPnjxBmTJlcl1eKGbampiYQFNTEy9fvlRof/nyJczNzbP1HzduHPz8/KTHcrkcMTExKFmyJGRZf5WiAiU+Ph5ly5bFkydPUKxYMWWHQyqEuUE5YV5QbpgblBvmBuWGuUG5YW5QbpgblBvmRsEnhEBCQgIsLS0/269QFG11dHRQvXp1HDt2DO3btwfwsRB77NgxDBkyJFv/IkWKoEiRIgptRkZG+RAp5YdixYpxYKMcMTcoJ8wLyg1zg3LD3KDcMDcoN8wNyg1zg3LD3CjYihcv/sU+haJoCwB+fn7w8vJCjRo1UKtWLSxYsAAfPnxA3759lR0aERERERERERERkaTQFG27du2K169fY+LEiXjx4gWqVq2Kw4cPZ7s5GREREREREREREZEyFZqiLQAMGTIkx8shUOFQpEgRTJo0KdulL4iYG5QT5gXlhrlBuWFuUG6YG5Qb5gblhrlBuWFuFB4yIYRQdhBERERERERERERE9JGGsgMgIiIiIiIiIiIion+waEtERERERERERESkQli0JSIiIiIiIiIiIlIhLNoSERERERERERERqRAWbYmIiIjykVwuV3YIRERERESk4li0JfoK/IJNuWFuUG6YG5RVcnIyoqKiEB8fDw0Nfvyij4QQADhekCIhBNLT05UdBqkojhv0OcwLygnHjYKL3xqIcpCYmIjff/8d27dvBwDpCzYHOfrw4QO2bt2KixcvAvgnNzLfCKnw4rhBnxMQEIBBgwahatWq+P333xEeHi4t4/hR+CQnJ2PUqFGYMmUK7t+/zwIdSVJSUjB27Fj07dsXly5dwsuXL5UdEqkIjhuUm7S0NDx48AAAP3+SIo4bBR+LtkQ5iIqKwvHjxzFlyhTUq1cPCxcuRHR0NDQ0NJCRkaHs8EiJwsLCsGDBAgwdOhTfffcdDhw4gJiYGMhkMn44KuQ+N24wN2jGjBnYt28fhg8fjjVr1mDIkCFYuHAhAEAmkyk5OspvGhoaMDAwwMOHD1G3bl2MGjUKBw4cUHZYpAI0NTXh7OwMY2Nj9OnTB4MGDcL69euVHRapAI4blBO5XI4RI0agZ8+e6N69O0JCQpCQkMDvrQSA44Y6kAlO7yBSIISQvkCnp6dj7NixuHHjBl68eIGtW7fCwcEBcrmcp7cWYklJSfjw4QMGDRqE169fo0SJEli4cCHKly/P3CikOG7Q52TNDwC4du0a9u7di2nTpsHX1xczZszIsR+pp0/Hgi1btuDw4cMICQnB6NGjMWzYMADMh8Lo09w4fvw4jhw5gvnz58PPzw+BgYHMiUKK4wZ9TuYsWz8/P8THxyM9PR1r166FlZWVcgMjpeK4oR5YtCXKRUZGBjQ1NQEAZ8+exYwZM3DixAmcPHkSVatWVVhOhUvWY79p0yYEBQXhyZMn2L9/P2xsbFicKyRy+oDzpXGDuVE4ZM2NlJQUyOVy6OnpKfRJSEjA9u3bMWjQIPz888+YNGmSMkKlfJLTeJF1PHj8+DGCg4Px888/IzAwEOPGjVNGmKQEX/qynJiYiN27d8Pb2xve3t747bff8jE6UiaOG/S1MnNFLpfj+PHjmDdvHs6dO4cdO3bA3d2dRblCJKdjnZ6eDi0tLQAcNwoiFm2p0Ms6sH1aUMm67OnTp/Dz80NoaCguXryI8uXL8w1QzWU9vi9evEBSUhKsra2zHfezZ89i6tSpiImJwe7du2FhYaGskCmfZM2Be/fuISEhAba2ttDV1ZU+FAEcNwq7GTNm4Pz584iMjESXLl3g7u6OJk2aSMtTU1Px+++/Y9asWViwYAE6dOigxGgpr2T9mz937hxev36N8uXLw9zcHKVKlZL6JSUlYdWqVRg1ahRWrlyJ3r17KytkyidZcyMkJARPnjyBpaUlbGxsYG9vr9B3//796NChA2bOnAk/Pz9lhEv5iOMG5ebTz5FZC7aZ32NjY2MxfPhw7Ny5EydOnEC1atU44agQyJobN2/exLt371C2bFlYWFhAR0dH6sdxo2Bh0Zbo/wUFBcHExAQtWrSAtrZ2jn1u376N4cOHw8TEBEuWLIGhoWE+R0nKMGHCBOzZswdPnz6Fg4MDOnfujAEDBqBYsWJSn6NHj2LGjBmoX78+fv75Z4U3RlJfP//8M3bu3Ilnz56hQoUKqF+/PiZPnoySJUtKH5w4bhROAQEBWLx4MX7++Wc8evQIV69exYsXLzBmzBj069dP6vfkyRNMnDgRurq6WLJkCQBwNraaGjt2LDZs2ABtbW28f/8eNWrUgK+vL1q1aiX1iY2NRWBgIK5cuYLFixfD0dFRiRFTfhkzZgzWr1+PkiVLIiEhAQYGBhg/fjx69OgB4J8v4vPnz8eyZcuwevVq1K9fX8lRU37guEFZZS3KXb9+HTY2NjAwMMixb3p6Onr06IGwsDCEhYXB2Ng4P0MlJZo4cSK2bt2KuLg4JCcnY9KkSfjpp5+gra2tUNjnuFEw8FsBET7OhurXrx98fHwQGhqa610V7e3t0blzZzx8+BCvXr0CwLt+q7sFCxZg6dKlGD9+PPbs2QM7Ozts27YN/fv3R0xMjNSvadOmqFu3Lg4ePIi0tDQAzA11t3z5cqxYsQLz5s3D6dOn0b59e4SHh8PDwwMvX76UPlRz3Ch83r17h+PHj+O3336Dn58fFi5ciN9++w1t2rTByJEjsWrVKqlv2bJl0bFjR2zatAl///03C7ZqaseOHVi9ejWCg4Nx48YNrFmzBqampujfvz+2bNki9TMyMkKHDh2QmJiIW7duAeB4oe4OHz6MNWvWYNu2bYiIiMD27dvh4eGBXr16ST/kZL6ftGnTBpUrV0Z4eDgA3h1e3XHcoE9ljgUTJ06Eh4cHtm3bhsTERADZj7mWlhamTp0KGxsbzJkzhzclKySmTp2KP/74A0uWLEFYWBhGjhyJKVOm4OnTpwqfMTluFCCCqJA7d+6cqFGjhggKChIeHh7C3NxcHDlyRKSlpSn0k8vl0v/XqVNH9OvXL79DpXyWkpIiunXrJiZPniy1paWliZUrV4o6deqIjh07itjYWIV1KlWqJCZMmJDfoZIS+Pj4CF9fX+lxRkaGOHLkiKhXr55wdXUVr1+/VujPcaPwePXqlTA2NhaLFy9WaH/06JEYNWqUqFChgjh8+LDCsr59+4qpU6fmZ5iUj2bPni2aNWum0BYVFSV8fHyEqamp2Lt3r8Ky8ePHiypVqogPHz7kZ5ikBGvXrhU1a9ZUaHv37p349ddfhUwmE+vWrVNY9ttvvwkrKysRFxeXn2GSEnDcoJysWbNGWFtbC1dXV+Hs7CzWrl0rHfOs31eF+PjZdPr06cLd3V1kZGQoI1zKR+fPnxd16tQRu3btUmivUqWK+O2333Jch+OG6uN0Dir0dHR00KZNG7Ro0QKHDh2Ci4sLvLy8cPz4cYUZt1mvHTR16lSkpqbi/fv3ygiZ8omOjg7i4+Nx48YNqU1LSwv9+/eHt7c3oqOjsXjxYsjlcml27ZAhQxAbG6ukiCk/xcXFISwsTHqsoaGBZs2aISAgAAYGBhg7dqx0EyqA40ZhIYSAsbExWrZsiYsXL+LFixfSsnLlyqFPnz6ws7PDwYMHAUCa+eLm5pbrKY5U8BUtWhRRUVF4+vSp1Obg4IBhw4ahdevWmDt3Lh4/fizNcunbty+cnJz4flIIFCtWDH///TeioqKkNiMjIwwZMgSjRo3CpEmTcO3aNWlZ//794ebmhvv37ysjXMpHHDfoUx8+fMD9+/fRqVMnnDhxAk5OTpg5cya2b9+OxMREyGQyKR+EENDQ0MDo0aPx9OlTrFu3TsnRU15LSkqCmZkZqlevDuCfmbPGxsZ48+ZNjuv06dOH44aKY9GWCj0XFxcMHjwY5ubmAD6epubs7AwvLy/89ddf0hfq169fS6ef2NjYwMrKSuGGQ6Re5HI5hBCoWbMmHj58iJs3b0rLNDQ00Lt3b7i4uGDnzp0AIF0H2c3NDTKZDKmpqUqJm/JeZhG2adOmSEpKwsGDBxVOUXV3d0fbtm0RFhaG+Ph46VQkjhvqR+RwGplMJoOmpibq16+Po0ePYteuXQqF+kqVKqFevXrYvHkz4uLipJuCDBgwAD179sy32Clv5JQTwMfjXrx4cWzbtk0hH+zs7NCjRw/cvXsXT548kX4gLl++POrUqQM9Pb18iZvy3udyo1q1ali2bBmeP38utRcvXhy9evWCnp6eQkFXT08PrVq1gpWVVV6HTPmE4wZ9LX19fXTr1g19+vRBsWLFsGnTJlSuXFkq3H748EHKh8z/ampq4scff+QPw2omp3GjcePGmDZtGsqWLQvgn4kB5cuXV7inRnJyMp49ewYAsLKygpubG8cNVaacCb5E+S/r6SIJCQkiOTlZpKenKyxPTU2VHrdo0UJYWFiIY8eOiatXr4p69eopnKKWlJSUP4FTnvtcbrx+/VqUKVNGtGrVSrx69UphvcjISKGrqyvCwsIUtsPTS9RH1tx49eqVSEhIEPHx8UKIj6ev1qlTR7i5uYnLly8r9H38+LEoUqSICAkJUdgexw31kfV4r1y5Uvz4449i8ODBYunSpVL7yJEjRZEiRcSyZcvEy5cvpfatW7eKxo0bS6c3f3o6IxVMWY/jrVu3RFRUlHj48KHUNmLECGFsbCw2btwo3r9/r7CunZ2dWL58uRBCSKewMi/UR9ZjGRYWJi5duiR9dhBCiHnz5okKFSqIadOmiefPnyusW6NGDenSKZnbYW6oD44blJvcjmXmd5Ssl/Lr2rWrcHJyEuvWrRPJycni4cOHYvz48dJ329u3b4sXL17kfdCUL3IaN+7fv6+wPPOfEEJ06dJFjB07VgghxJs3b4Sbm5v4/fffc9weqR5O96FCI/PXxmnTpuHs2bO4f/8+WrRogU6dOkl34NXW1kZ6ejq0tLRw+PBhtG7dGt27d0dqaipq1qyJXr16SdvT1dVVyn7Qt5dbbrRt2xbu7u44dOgQ3N3d0bdvX8ybNw/29vYAPt5syNraGsWLF1fYjr6+vnJ2hL65zGM6efJkHD16FE+fPkXlypXRv39/tG/fHvv27UONGjXg4+ODKVOmoFmzZgA+XjrB2to62516OW6oj8zcGDduHP744w907NgRUVFR2L17N3bs2IHdu3djzpw5kMvlCAgIwNWrV9GoUSOULl0akyZNQu3atVGsWDGFbVHBljUn9u/fj0ePHsHW1hZubm5YsmQJ5s2bh5iYGPj4+CAmJgbff/89SpUqhfv370Mul0tn/GTOzmdeqI/MYzlmzBjs3LkTsbGx0NPTQ506dbBixQqMGDEC7969w++//46YmBgMHDgQtra2ePz4MeLj46VZU5/OoKOCj+MG5UQIIR3LQ4cO4cmTJzAxMYGLiwsqVKgAIQS0tLSk762bN29Gt27dMGvWLDx79gxLly5FzZo1pTMB7ezslLk79I3lNm40aNAACxcuzDYOJCcnQ0NDA3FxcWjUqBFMTEzg7e2dbXukopRdNSbKTwEBAcLY2FgsXbpU+Pr6itatW4tixYqJLVu2CCH++ZUp8xfMBw8eCJlMJnr16iVtgxdxV0+55UZwcLAQQoiIiAhhYWEhateuLXx8fMTKlSuFo6Oj6Ny5s5Ijp7w2bdo0YWxsLDZv3ixmzJgh+vbtK2QymZgxY4YQ4uNs7Bo1aojq1auLtm3bimnTpgkHBwfRvn17JUdOee3WrVvC2tpaHDx4UAghRHJysjh9+rSoUKGCqFGjhnSjwoULF4r27dsLXV1dUbNmTdG1a1dpG5zdoF4WLVokjI2NxV9//SUOHz4sFi1aJEqWLCmaNm0qzZLz9fUVFStWFFWqVBHff/+9sLOzE56enkqOnPLaqlWrhImJiTh//ry4dOmS2L9/v7CyshJVq1YVN2/eFEJ8vPGUm5ubMDU1FU2aNBE2NjaiTZs2So6c8hrHDcrNqFGjhKWlpXBychL29vaiVKlSYseOHQp9ss64bdWqlZDJZKJDhw5SGz9nqKfcxg0PDw/pZsiZM60HDhwo/Pz8hKurq8LNDVnXKBhkQuRyER0iNZOQkIA2bdqgd+/e6N+/PwDg/v37WLp0KebNm4fg4GB069ZN+mXz0aNHqFWrFqpWrYo///wTwMdrWWb+kk3q40u5sWHDBvTo0QOvX79GYGAgLl++jCJFiqBixYpYvHgxAMVfxEl9pKeno23btmjcuDHGjBkD4ONNIP744w+MHDkSU6dOxbhx4xAbG4u1a9fi2LFjKFKkCKysrDB79mwAHDfU2bVr19C8eXOcOXMGFSpUkNrv3buHli1bonTp0jh+/DgAIDExEa9evYKWlhbKlCkDgLmhjoYMGQK5XI6lS5cC+PjeEB4ejg4dOsDW1hbHjh0D8HHm1LVr1/DixQuUL18ew4cPB8CcUGcTJkzA33//jR07dkhtMTExaNCgAbS0tHDkyBGUKlUK4eHhuH79Op4+fYpSpUpJn0uYG+qL4wbl5NChQ+jduzf2798PV1dX3L17F3/88QcWLFiARYsWwcfHR+orhMCjR4/QpEkT1KlTB8HBwQCYG+rsc+OGo6MjDh8+LPX94YcfEBwcjPbt20v3Y2FuFCDKqxcT5a9Xr14JExMTsXLlSoX2d+/eidGjRwt9fX1x/Phxqf3Bgwdi+vTp0mP+EqW+Ppcbo0aNEvr6+uLIkSNCiI95kJ6eLhISEqR+zA31lZCQICpUqKAwFmT67bffhEwmE9u2bVNozzrjgbmh3hISEoSZmZn49ddfpbbMGS0XLlwQlpaW0ozsT3Hmi3pq2bKlaNmypfQ4cwwIDw8XJiYmon///rmuy/FCPWX+rffr10/UqVNHak9JSRFCfPysYWNj89lZk8wN9cZxg3KyadMmUb16dYXPlXK5XEyfPl1oaGiIrVu3Sm1yuVwMHz5cuLm5SX2ZG+rtS+PGwIEDpWXTpk0T3bt3z9aXCgaW1qnQMDU1RatWrbB7926Fu/MaGRlhyJAh8PDwwLp165Camgrg450U/f39AfCXKHX3udwYOnQoPDw8sGnTJiQnJ0t3hi9atCiAj79qMjfUV9GiRdGuXTusW7cOt2/fBvDP3VoHDBiAQYMGYdGiRYiJiZHatbS0pH7MDfUll8uhr68Pb29vHDx4ELt37wbwz3XBqlWrhoYNG+LatWs5rs+Z+erJ29sb169fx7Zt2wB8vM6kEAJVq1bFrFmzcO7cOfz99985rsvxQj1l/q17e3sjMjJSOkNHR0cHqampMDIywurVq3Hp0iWcOHEix20wN9Qbxw3KiZaWFiIiIhAdHQ3g4+cOmUwGf39/jBw5Ej/++CMiIyMhk8kgk8kwffp0nD17VurL3FBvXxo3Tp06hZs3bwL4eO1bzr4uuHi0qFBp0qQJnj17ho0bNyImJkZqL1euHFxdXRESEoLk5ORs63FgU39fkxupqanZCi0svKi/1q1bw8TEBAsXLsSTJ08gk8kghICuri5q1qyJ27dvIy0tjblRyGhoaEBDQwM9evSAoaEhVqxYgT179kjLtbS0YGNjgw8fPkAulysxUspPrq6uqF27tnS5FOCfsaBSpUp49OgR4uPjlRkiKYmjoyP69u2LtWvXSl+edXR0AACWlpaQy+U5fgYl9cdxg3LSqFEjNGjQAL/88gtevHghFeUA4KeffoK1tbVCkTbzZrecNFA4fM24kZCQoLAOc6Ng4hGjQsXLywtNmjTBihUrsHr1aoVZlS4uLihfvjzS0tKUGCEpC3ODctOkSRO0b98e586dw8yZM3Hnzh3pQ5GdnR0sLCyQlJSk5ChJWSpVqoTJkycjIyMD8+bNw9y5cxEfH4/r169j165dcHJy4gfkQsTa2hpDhw5FXFwcFixYIF07DgCMjY1Rvnx5/qBTSBkZGaFv376ws7PDggULsHz5cmlZ0aJFYWRkpLzgSKk4blBOTE1N0blzZ0RFRWH+/Pl4+fKllAfW1tbQ0tLCs2fPAChOMGKuFA7/ZdxgbhRMvBEZFRpZTwUYPnw4jh8/Dnt7e/To0QNFixbFsGHDUKtWLQQFBSk3UMp3zA3KTdbcmDNnDvbs2YOkpCQMHjwYurq6CAwMhIuLizRritSH+Jc3F7x27RrWrVuHoKAgaGhowNDQEM7Ozti1a9d/2h4VbCdOnMCCBQtw/fp1uLm5wcHBARs3bkTFihWlS2lQ4XT16lX88ccfCA4ORq1atWBtbY2//voLdnZ22Ldvn7LDIyXiuEGZsn5mmDhxIg4ePIiqVatiypQpsLS0xPPnz/Hdd99h1KhR0s0KqXDiuKH+WLQltfC5L8NZiy4ZGRnQ1NQEAKxcuRIhISHYt28fnJ2dYWtrKxVe+OVafTA3KDdZj+WnxzVrPmTNk0OHDmHPnj3Ytm0bnJycYGdnh9WrV+e4DSq4sh7LY8eO4dmzZyhTpgysrKxgY2OTa+4kJycjISEBV69eRbFixVCrVi0AvH6YOsh6nBMTE6GtrQ0tLS3pcik55cOdO3dw5swZLFu2DFZWVihdujTmzZuXrR8VbFmP5du3b6Gvrw8hhPTfnI7zmzdvEBERgUWLFsHMzAzm5uaYOnUqAI4X6oTjBuUmt2OZtT3rWLBw4ULs3LkTYWFhqF27Nh48eIBKlSph//79+Ro35T2OG/QpFm2pwMs6EK1btw737t1DSkoKmjZtCnd3d2hqaioUYNLT06UbBQHAw4cPoa+vDzMzMwD8sKxOmBuUm6y5sWLFCly9ehUpKSmoV68eevfuDS0tLYXcyPr/APD69Wvo6+vDwMAAAHNDXY0ZMwYbNmyAoaEhkpOTYWhoiKlTp6JDhw4A/rkpnUwmyzUHmBvqZcaMGTh79iwePXqE5s2b4/vvv0etWrVy/aL9NY9JPUyZMgXHjh3D8+fPUblyZfj4+KBp06YKfT59L/kUc0M9cdygrD4ttiUmJsLS0hKmpqYAFL+PZB0zHj58iL/++guxsbEwMjJCv379ADA31BXHDcrEI0gFXuagNXbsWIwYMQK3b9/G1q1bMXLkSPzwww9IS0uDpqYm0tPTIYSAlpYW3r17J61vZWUlFeV4cW71wtyg3GTmxrhx4/Dzzz9DU1NTumZYgwYNkJCQIBX1AUBTUxOvX7+W1i9ZsqRUsGVuqKf9+/djzZo12LZtG65fv45NmzahUaNG6Ny5M9asWSP1k8lkuHfvHn788UfExsZm2w5zQ30EBARg9uzZaNasGerWrYvr16+jRYsW2Lt3rzQDJnM8ePToEdLT0wH8U9zP/H/mhPqZNm0aFi5ciB9//BFeXl4wMDBAixYtsHTpUoV+mpqauHv3LlJTUwFAyhGAuaGuOG7QpzI/g/r7+6N9+/Zwc3ODp6cnBgwYAADSxAFA8TOElZUV+vXrBz8/PxZs1RzHDVIgiNRARESEsLa2FsePHxdCCJGWliZWrlwpqlatKho2bChSU1Olvk+ePBGdO3cWixcvVlK0lJ+YG5Sbu3fvCjs7O7F//34hhBByuVyEhIQIV1dXYW9vL+Li4qS+L168EE2aNBG//PKLssKlfLZq1Srh5uam0PbmzRsxfvx4IZPJxLZt24QQH/Nm//79wszMTEybNk0ZoVI+iI2NFfXq1RNr1qyR2m7fvi2GDh0qZDKZ2LVrlxDiYz7ExMSI9u3bi5o1a4r09HTlBEz5JiUlRTRv3lzMnTtXaouPjxczZswQmpqaYtGiRUKIj7nx/v174enpKYyNjUVaWpqyQqZ8wnGDcrNkyRJRokQJceTIEXH69Gkxa9YsYW9vL2rWrCmSkpKEEEIaI6KiosTmzZuVGS7lI44b9CmtL5d1iVTfu3fvEBsbCxsbGwAff6H08vKChYUFxo8fj27dumHLli3Q0tJCQkIC3r59i+joaCVHTfmBuUG5ef/+PV6/fi3lhkwmQ5MmTbBu3Tp4eXmhSZMmOHfuHLS1tZGWlgYrKyvEx8crOWrKLwYGBrh+/Tru378v5UjJkiXh5+eHhIQE+Pv7w8nJCU5OTmjRogV2794NNzc3JUdNeUEIgeTkZERGRipcF87Ozg4BAQEAgF69euHIkSNwc3ODvr4+GjdujOjo6M+eCk8FX0ZGBpKTk3H79m14eHhI7YaGhhg7diw0NDTg6+sLW1tbeHh4QFdXF4MGDULFihUVLsdE6ofjBn3OrVu30KNHDzRr1gwAULNmTTRo0AD9+vVDgwYNcOnSJWhpaSEpKQk7duzA+PHjYWJigu+++07JkVNe4rhBOVJy0Zjom3j06JFwcHAQq1evVmhPTU0VQUFBwsXFRWzfvl2hPxUOzA3KTWJionBychITJkxQaJfL5SI0NFRUqVJFYebU69evFfqQertz546oW7euGDlypHjx4oXCsitXrghHR0exc+fObOtlZGTkV4iUhz58+CB+//13hbZu3bqJtm3bZsuH+/fvi7Zt24oBAwaI5ORkIYRQmEXJ8UK9fPjwQcyZM0ehzcfHR1SpUkXcv39fCPHPMU9MTBT9+/cXTZo0ETExMQrLhOB4oW44blBuMo9n5t98586dRb169bL1u3DhgrC3txc9e/aU2m7cuCGCgoLyJ1DKdxw36Et4kQtSC8bGxqhYsSI2bdqE69evS+3a2tro1asXtLS0cOTIEam9XLlyABSv+0LqiblBudHS0kLz5s0RGhqqcPddmUyGhg0bwsbGBqdPn5baTUxMAPAurIWFra0tPD09sW/fPqxfvx6vXr2Slrm6ukJHRwe3bt3Kth6vH6YewsPDERQUhKSkJMjlcgDAd999h8ePHyM4OBhxcXFSX2tra7i4uODo0aNIS0sDAIVZlBwv1MuTJ0+wevVqPH78WPqs0LZtWxQvXhwLFixAdHS0dM1BPT091KpVC7du3ZKuOZg1HzheqBeOG5STtLQ0dOzYEU+ePJH+5rt164a4uDhs27ZNoW/VqlUxfPhwREVF4cGDBwCASpUqwcvLCwCkvCL1wXGDvoSfFKjAE0KgaNGimDt3Lq5fv46xY8fi5s2b0nINDQ3UrVs3xzc5DmzqjblBn6OtrY2RI0ciLS0N8+bNw8GDBxWW16hRAwCkD0WZmBvq59MfaTKLK/7+/ujQoQOWLl2KBQsW4NGjRwCAx48fIykpCWXLls33WCl/lCxZEs+fP8fNmzelL9ne3t6oV68eli1bhqCgILx8+VLq7+rqijJlykg3mCL1ZWRkhKJFi+LGjRvS+0Hz5s3RunVrnDp1CjNnzsTDhw+lZQ4ODihVqhSSkpKUGTblA44blJOUlBQkJycr3Oy4Tp06sLS0RFBQEEJDQ6V2HR0dNGzYENeuXcPDhw+zbYs/9Kgfjhv0JfyrpwIj80v1pwU2IQTkcjkqVKiAkydPIjw8HCNHjsTmzZsRGxuLe/fu4fDhw/xyrcaYG5SbzJz4tCgnl8shhECZMmWwdetWpKSkYNasWZgxYwZevnyJ69evY8OGDbCzs4O2trYyQqc8lpiYiLlz5wJQLMTL5XJp1sKVK1cwY8YMDBgwAH/99Rdq164NDw8PuLu7w97eHj179lRK7JT3KlasiJYtW8Lf3x9v3ryR2hcvXoymTZti9erVGDFiBA4ePIi//voLv/zyC2xtbWFsbKzEqCk/lCpVCh4eHhgxYgSeP38utfv7+6Nz5864dOkSunbtiuDgYGzduhWDBw+Go6OjdCYPqa+KFSuiVatWHDdIQdGiRaGjo4MpU6ZIbaVLl8bcuXPx6NEjzJo1C7t27ZKWaWtrw97eHkWLFlVGuJTPOG7Ql8gEzwGmAiAtLQ1dunTBb7/9plBgk8vl0i9Su3btQt26dfHhwwf89NNPePLkCV6+fAlTU1PY29tj7969ygqf8hBzg3KTlpaGFi1aYMmSJXB0dJTas+bGunXrULVqVZiYmGDq1Kk4ceIEnj59itKlS8PR0VH6EM1LIqifW7duoWPHjjh06JDCZVEyj/P06dOxYcMGhISEwNLSEhEREbh06RJevHiBUqVK4ccffwSgmE9UMOX29338+HFMnDgRXl5e6N27N3R0dKRlS5YsQUhICA4dOoQqVarAzs4OmzZt+uz2qODL/Hu/desWfH19UaNGDYwdOxbFihWT+uzbtw87d+7E7t274ejoCHt7ewQFBQFgbqiTrMfy9evXMDU1BQAcOXIE06ZNww8//MBxo5DK6VhGRESgf//+8Pf3x/fffy+137hxA76+voiNjUWZMmVQp04drF27Fo6Ojti9e3c+R075LfM9JSQkBIGBgRw3KEcs2lKB8P79e3z//feYOXMmnJ2dkZGRoXCHxOnTp2P+/Pn4888/4erqiri4ODx79gw3btyAqakp3N3dAfDLtTr68OEDOnfuzNygHHXt2hU9evRAu3btsuXGzJkzMXv2bBw4cAC1a9dGcnIyEhMTER4ejhIlSqBatWoAmBvq6uXLl2jbti0mTZqEVq1aKRznCRMmYNmyZQgODkbz5s1z3QZzo+DL+oVn586dePXqFTIyMtCmTRuUL18evr6++PPPP7F06VI0btw4292Z7927BwMDA5ibmwNgTqiTrLlx//596OjoQFNTExYWFgCAgIAA7Nu3Dz/99BO6d+8OAwMDhfVfvHgBAwMDGBoaAmBuqKspU6YgLCwM48ePR61atQAAffr0waVLl/Dbb79x3Chkso4by5cvR5cuXWBsbIy3b9/Cx8cHwMexo2LFitI6jx8/xtGjR7Fx40aYmZmhdOnSmDNnTrbtUcH26bH89O++X79+uHDhAscNyi7v73VG9G20bdtWdOrUSXqceXfEOXPmCG1tbfHnn38qtH+Kd+hVX23atGFuUI4GDRok3N3dpceZOTB37lyhoaEhjhw5otD+KeaGeps4caKwt7cXz549E0L8c7z79u0r9u7dq8zQKJ+NGjVKGBsbC3d3d2FgYCCqVq0qZs2aJYQQwtPTU1hbW4s9e/aI+Ph4IYQQ6enp2bbBuzarj6zHMiAgQNSsWVOYmpqKdu3aiTNnzkjLevXqJZydncWCBQvE69evhRD/3Mk76/sHc0M9RUdHi7JlywpnZ2fRv39/ceHCBWlZvXr1hJ2dHceNQiTrsRw+fLgoWrSouH//vtR2/vx5YW5uLry9vcXjx4+/uA1+BlUfWY/r6tWrxfDhw4WHh4c4dOiQSE5OlpY1atRI2Nvbc9wgBSzNU4ExefJk3L9/X7rLZuYvVZUrV8ahQ4ek2VC5/RrJX6LUg8hyckDmTYGmTp2KBw8eMDdIkpknU6dORXR0NObPnw/gnxxo1qwZQkJC0KxZM4X2TzE31EPWcSPrta9/+OEHWFlZYcmSJYiPj5eO9+rVq+Hp6ZnvcZJynDx5Eps3b8b+/fvx119/ITo6Gk2bNsX69esxevRo7N27F7Vq1UJAQAACAgLw6NEjhRkwmfnF2VDqI/NYTpgwAUuXLsWkSZMwffp0PHv2DBcvXpT6rVu3Dm5ubti+fTu8vb0RFRUlXRM76/sHc0M9mZqawsnJCTVq1MDVq1exaNEinD59GgBw+vRp1KhRg+NGIZJ5LEeMGIHVq1cjNDQU1tbWAD4e79q1a2P9+vUIDg7G+PHjcerUKWndzBugZm5DCMHPoGok87j6+/tj8uTJiI2NhVwuh6enJ06cOCH1O3HiBOzs7DB16lSOGyTRUnYARJ8SWU4dSE5ORkZGBgwMDGBjYwN7e3vs2LEDVapUkU4radGihTLDpXyUNTfmzJmDc+fOYcOGDbC0tISdnR1zoxATn5xyJJPJIJfLYWhoiHbt2uHIkSNwdnbGd999BwCoUqWKskKlfJY1N/744w+UKVMGDRs2hL6+Puzs7FC3bl3s3bsX1tbW0inOPOWscHn58iU0NDSka18bGhpi/PjxsLCwwJo1a1CyZEls3rwZCxcuRGhoKKpVq4YxY8agSpUqaNWqFb88qambN29i37592LZtGxo2bAjg43UpMzIycO/ePcjlctjZ2WH58uXYunUr9u7dCzc3N/To0QO1atWCl5eXkveA8pJcLoempiZKlCiB3r17IykpCb/88gvWr1+P6OhoHDhwAMHBwZgzZw7Onj3LcaOQmDZtGhYuXIhHjx6hbNmyuHDhAsLDw3H16lW0bt0abdq0QWhoKAYPHoypU6eiTp06Cjcoy/zMwvxQP7///js2bdqEHTt2oEaNGgAAb29vTJw4EU2bNkVGRgZ0dHSwf/9+zJ07F2fOnOG4QQAAfiMhlZL1y/X8+fPRq1cvuLq6Yt68eShWrBhGjBiB0NBQzJs3D0+ePJHWyzpzitRT1tzw8/PDmDFjsHfvXjx48ABmZmYYNmwYc6OQypobZ86cke7mraGhgSJFiqBXr16IjY3FihUrcP78eWk95kbhkJkbY8aMgb+/PxISEhSO/aRJk+Dk5IRFixbhjz/+wJs3b6ChoYGMjAxlhUz5zMLCArq6urh+/TqAj2NK8eLF4e3tjbZt22Lz5s2IiorCsGHDsGXLFsydOxcxMTEIDQ1FbGyscoOnPCOTyfD8+XN8+PABwMf3jAMHDmD9+vWoW7cu2rdvj8WLFwMAunTpgg0bNiA4OBgODg64efMm3r17p8zwKY9l/rBXpUoVhISEwMPDA7/++ivOnTuHvn37IjIyEgAwatQobN68meNGIfD+/XuEhYWhXLlyiI+Px+nTp9GjRw+sW7cOZ8+eRa9evdC/f3/Y2Nhg69at8PT0xLZt21CvXj2MGjUK0dHRLMqpqaSkJBw9ehSDBg1C9erVpc+YjRs3RnJyMjQ1NaGjoyO1jxw5kp836B/5fkEGoq8wZswYYWFhIWbPni2GDBkitLW1pWtP/vnnn0JPT0/07t1bnDx5UlqH1/1RX59eI8rIyEhcuHBBtGzZUnTr1k0kJiYKIYQ4cuSI0NPTE3369GFuFEITJkwQMplMjB07Vrq2YKZz584JJycn0aFDB7Fp0yaFZbwulPr7448/hLm5ubh06ZIQQojU1FSRlJQkXS9MCCF+/PFHUb9+fdGuXTsRGRmprFBJCV68eCEcHR1Ft27dRGxsrMKy9+/fi1KlSokpU6ZkW49jh3p78+aNqF+/vmjZsqWYPXu2sLOzEw0bNhRRUVHi7NmzIiAgQFSsWFFEREQoO1RSgsy//2XLlolGjRoJIYR49+6dKFasmDAxMRE//PCD9J6T03qknp49eyb69esnLCwsRPHixcWKFSvEq1evhBBCrF+/XpQrV07Mnj1bYZ3t27eL4OBg6fr6pJ7CwsKk+6xkOnXqlChfvrz48OGDdO1aXsOWPsWZtqRyFi9ejODgYBw4cACjRo3CokWL0LhxYyQmJuLdu3do3rw5Tp06hcjISEyZMgUTJ04E8M+sOZHl2oWkHjJ/dR4+fDjWrl2L0NBQ1KpVC66urrh8+TISEhIAfLxO6cGDB3Hz5k38+uuvzI1CZOfOndi+fTsGDBiAuXPnYubMmXjz5o20vE6dOli7di20tLQwb948eHt74+3bt3j//j1nNRQCUVFR8PLyQo0aNXDw4EF4eXmhevXqGDhwINavXw8AWLFiBYYOHYqiRYvCzc0NPj4+WLt2rZIjp/xQqlQprF69Gjt37sT48eMRHx8vLTMwMICbmxtSU1OzrcexQ72VLFkSK1asQJkyZfDy5Utoa2tj3bp1cHBwgJubGxo0aIDXr18jOTlZ2aGSEmT+/bu7u8Pa2hqPHj2CnZ0dunXrhgULFuDWrVuYPHkyHj58qPD5k+OGerO0tMTUqVPh4eEBHx8f9OzZEyYmJgA+Xke/SZMmWL16NVJSUqTr2Hbq1Andu3eHpaWlMkOnPFa9enXpPiuZNDQ0kJycjKSkJGhqaiI2NhZr167NdqYGx43CjUVbUimJiYl48uQJpk2bBhcXFwBAamoq7ty5g/nz56NSpUrw8vJCkSJFsGfPHrRr146nlRQSjx49QnBwME6cOAFnZ2cAwLhx4/Du3TvMnTtX6te4cWNs2LABbdq0YW4UEunp6YiPj0ezZs2wYsUKBAcHY+7cuZg1a5ZC4bZGjRpYsGABJk6ciPDwcHTo0AG9evXCnTt3lBg95SUhBDIyMnDmzBkUL14cjx49Qp8+feDg4ICOHTtCT08Po0ePxu+//w6ApzgXZnXq1MG2bduwcuVK+Pj4ICwsDKmpqXj27BmuXr0KU1NTZYdISuDk5ISVK1eiX79+SEpKUijem5iYoEyZMrz+dSGnq6uLbdu2wdraGq1atcKiRYvQs2dP+Pj4oFq1arCysuLnz0LG0tISM2fORO/evWFgYACZTCad9l6sWDFUr14dRYoUkW5aSIWXTCaDgYEBSpYsidjYWFStWhUHDx5EiRIllB0aqRCZ4NQzUjFv3rxBeno6zM3NkZGRAQcHB5QqVQr+/v54+fIlNmzYgDJlymDDhg3SOjt27EBqaioaNWrEXynVWGJiIvT19SGEkG4AMW7cOJw8eRKbNm1C2bJls91tlblROMTFxeHt27ewsbEBAGzevBk9evTAqFGjMGbMGGmWQ3p6uvQh+eLFi4iOjkbNmjWZG2ru119/RXh4uFRgmTt3LjQ0NPDkyRP89ttvuHLlCoKDg2FmZsYv14Xc2bNn8cMPP6Bo0aJISkqClpYWKlSogP379ys7NFKiN2/ewM3NDePHj0f16tWhq6uLjh07okqVKti4caOywyMlmzFjBhISEvDLL79AT08v2/uI+ORmqVQ4vXz5Eq1bt0bHjh3x888/KzscUgGnT5/GTz/9hMOHD6NZs2YoX748Dh06BIDjBv2DRVtSaU+fPsXy5csxevRoFC9eHAAwe/ZsTJ06Fbdu3YKFhYWSIyRlO336NJo2bYqgoCB069ZNeoPLyMiApqamssOjfCaEkAr3WQu3P//8M16/fo2ZM2di+PDhqFy5srJDpXwUGRmJtm3bIjExEX369EFgYKC0bMeOHfD29saVK1dgbW2txChJVTx79gzh4eF48OABSpUqhS5dugD4eKkdzqosvI4cOYIffvgBWlpaMDY2hpOTE7Zu3QqAX64Lu5SUFGhpaUmfO5kPlFV0dDSioqIwfPhwWFlZYc+ePQCYJwSEhYWhadOm0NXVReXKlXH06FEA/LxBijgnn1RamTJl8OuvvwL4Z4acmZkZGjRogGLFiik5OlIF9evXR+/evTFnzhw0adIEZmZmAMCCbSGV+eFXCIFu3bpBJpOhZ8+eePv2LQ4cOIDatWuzYFsIOTo6YvXq1WjUqBFCQkLQo0cPVKpUCQBgbW0NJycnfjgmSenSpVG6dGmFNn6BoubNm+Ps2bO4efMm9PT0pGsTMjeoSJEiCo9ZiKOs3r9/j1GjRqFatWpYs2YNAI4b9FGpUqUQHx8PT09P6R4LzA36FGfaUoGSeVqJu7s7Zs+erexwSEVs3boVfn5+2L59O+rUqaPscEgFZJ29MG/ePIwaNQrff/89tmzZkm05FR6hoaFo06YNmjRpgnbt2qFs2bIYMWIEXF1dpQ/LRERfi+8lRPQ1Xrx4AXNzcwAsypGimzdvShMJmBuUExZtqUCIjo7G7du3MWzYMJQtWxb79u0DwA/L9A8rKyt4eXlh8uTJyg6FVEhkZCSaN2+O2rVrY/v27QD4gaiwu3LlCqZNm4aDBw/C1dUVNjY2UsGW7ylERESUV/g5g3LD7yeUGxZtqUC4e/cu+vXrh4oVK2LlypUAOLDRR5l5EBkZCUdHR2WHQypECIHNmzdj27Zt2LlzJwCOG/RRRkYGoqOjUaRIEZiamgJgbhARERERkWph0ZYKjFevXknXK+WXa8oNc4OyyrwWNsDcoNxx5gsREREREakaFm2pwOGXayL6tzhuEBERERERUUHCoi0RERERERERERGRCuF5okREREREREREREQqhEVbIiIiIiIiIiIiIhXCoi0RERERERERERGRCmHRloiIiIiIiIiIiEiFsGhLREREREREREREpEJYtCUiIqICTSaTYffu3coO419ZtWoVmjdvnifb7tOnD9q3b58n2/6SEydOQCaTITY2Ntc+yjheVlZWWLBgwTfZVlBQEIyMjL7JtvLKt9zf3KxcuRJly5aFhoZGnj/X11Bm3v8vHj58CJlMhoiIiFz7/Jec+5rXo06dOtixY8e/2i4RERHlHxZtiYiISGW9ePECQ4cOhY2NDYoUKYKyZcvC09MTx44dy5Pn+5qi4/8qOTkZEyZMwKRJk/LsOSjvdO3aFbdv31Z2GJ916dIl/Pjjj3m2/fj4eAwZMgRjx47Fs2fP8vS5VFVAQACqVq2aL8+VVzk3fvx4+Pv7Qy6Xf/NtExER0f+ORVsiIiJSSQ8fPkT16tXx119/Yfbs2bh+/ToOHz4Md3d3+Pj4KDu8zxJCID09Pcdl27dvR7FixVCvXr3/6TnS0tL+p/Vz87nYCdDT04OZmZmyw8hRamoqAMDU1BT6+vp59jyPHz9GWloaWrduDQsLixyfKzMW+t/lVc61bNkSCQkJOHTo0DffNhEREf3vWLQlIiIilTR48GDIZDJcvHgRnTp1gr29PSpVqgQ/Pz+cP38+x3VymikbEREBmUyGhw8fAgAePXoET09PlChRAgYGBqhUqRIOHjyIhw8fwt3dHQBQokQJyGQy9OnTBwAgl8sxffp0WFtbQ09PDy4uLti+fXu25z106BCqV6+OIkWK4PTp0znGuHnzZnh6eiq0yeVyTJkyBWXKlEGRIkVQtWpVHD58WFqeeQr1li1b0KhRI+jq6mLjxo3IyMiAn58fjIyMULJkSYwZMwZCiGzb/i+xf2k9ADh48CDs7e2hp6cHd3d36TX+kujoaLRs2RJ6enqwsbFR2G6TJk0wZMgQhf6vX7+Gjo7OZ2dY79u3DzVr1oSuri5MTEzQoUOHXPs+fvwY7dq1Q9GiRVGsWDF06dIFL1++lJZfvXoV7u7uMDQ0RLFixVC9enWEhYUByH6qeuaMy/Xr18PKygrFixdHt27dkJCQIPVJSEhAz549YWBgAAsLC8yfPx+NGzfG8OHDc40xc7srVqxA2bJloa+vjy5duiAuLk7qk3kKfGBgICwtLeHg4AAg++URYmNjMXDgQJQqVQq6urqoXLky9u/fLy0/ffo0GjRoAD09PZQtWxa+vr748OFDjnEFBQWhSpUqAAAbGxvpbysz3j/++APW1tbQ1dX9qtc6c73Vq1ejXLlyKFq0KAYPHoyMjAzMmjUL5ubmMDMzQ2BgYK6vVU5SUlLg6+sLMzMz6Orqon79+rh06ZK0vEaNGpgzZ470uH379tDW1sb79+8BAE+fPoVMJsPdu3dzfA0mT56Mq1evQiaTQSaTISgo6Kv2Nzf379+Hu7s79PX14eLignPnzik836eXR/j1119hZmYGQ0NDeHt7w9/fP8eZv3PmzIGFhQVKliwJHx8fhR97NDU10apVK2zevPmL8REREVH+Y9GWiIiIVE5MTAwOHz4MHx8fGBgYZFv+v1xT1MfHBykpKTh58iSuX7+OmTNnomjRoihbtqx0fcdbt24hOjoaCxcuBABMnz4d69atw/Lly3Hz5k2MGDECP/zwA0JDQxW27e/vjxkzZiAyMhLOzs45Pv/p06dRo0YNhbaFCxdi7ty5mDNnDq5du4YWLVqgbdu2uHPnTrbtDxs2DJGRkWjRogXmzp2LoKAgrF69GqdPn0ZMTAx27dqlsM5/jf1L6z158gQdO3aEp6cnIiIipMLR15gwYQI6deqEq1evomfPnujWrRsiIyMBAN7e3ggODkZKSorUf8OGDShdujSaNGmS4/YOHDiADh06oFWrVggPD8exY8dQq1atHPvK5XK0a9cOMTExCA0NRUhICO7fv4+uXbtKfXr27IkyZcrg0qVLuHz5Mvz9/aGtrZ3r/ty7dw+7d+/G/v37sX//foSGhmLGjBnScj8/P5w5cwZ79+5FSEgITp06hStXrnzxdbp79y62bt2Kffv24fDhwwgPD8fgwYMV+hw7dgy3bt1CSEiIQiE26/62bNkSZ86cwYYNG/D3339jxowZ0NTUlGL38PBAp06dcO3aNWzZsgWnT5/OVjjP1LVrVxw9ehQAcPHiRURHR6Ns2bJSvDt27MDOnTsRERHxVa91ZgyHDh3C4cOHsWnTJqxatQqtW7fG06dPERoaipkzZ2L8+PG4cOHCF1+zTGPGjMGOHTuwdu1aXLlyBba2tmjRogViYmIAAI0aNcKJEycAfJxdfurUKRgZGUk/toSGhqJ06dKwtbXN8TUYOXIkKlWqhOjoaERHR6Nr165fvb85+eWXXzBq1ChERETA3t4e3bt3z3XG+8aNGxEYGIiZM2fi8uXLKFeuHJYtW5at3/Hjx3Hv3j0cP34ca9euRVBQkFRczlSrVi2cOnXqi/ERERGREggiIiIiFXPhwgUBQOzcufOLfQGIXbt2CSGEOH78uAAg3r17Jy0PDw8XAMSDBw+EEEJUqVJFBAQE5LitnNZPTk4W+vr64uzZswp9+/fvL7p3766w3u7duz8b67t37wQAcfLkSYV2S0tLERgYqNBWs2ZNMXjwYCGEEA8ePBAAxIIFCxT6WFhYiFmzZkmP09LSRJkyZUS7du3+p9i/Zr1x48YJJycnheVjx47N9vp9CoAYNGiQQlvt2rXFTz/9JIQQIikpSZQoUUJs2bJFWu7s7JzrMRNCCDc3N9GzZ89cl5cvX17Mnz9fCCHEkSNHhKampnj8+LG0/ObNmwKAuHjxohBCCENDQxEUFJTjttasWSOKFy8uPZ40aZLQ19cX8fHxUtvo0aNF7dq1hRBCxMfHC21tbbFt2zZpeWxsrNDX1xfDhg3LNeZJkyYJTU1N8fTpU6nt0KFDQkNDQ0RHRwshhPDy8hKlSpUSKSkpue7vn3/+KTQ0NMStW7dyfJ7+/fuLH3/8UaHt1KlTQkNDQyQlJeW4zqd/U5nxamtri1evXkltX/Na5/T6tWjRQlhZWYmMjAypzcHBQUyfPj3HeDJfi8y8f//+vdDW1hYbN26UlqempgpLS0vp72Xv3r2iePHiIj09XURERAhzc3MxbNgwMXbsWCGEEN7e3qJHjx65Pt+kSZOEi4uLQtvX7O+nMv+2//jjj2zrREZGCiGy51zt2rWFj4+Pwnbq1aunEI+Xl5coX768SE9Pl9q+//570bVrV4X19uzZIzQ0NBReayIiIlINnGlLREREKkd8cor/t+Tr64tff/0V9erVw6RJk3Dt2rXP9r979y4SExPRrFkzFC1aVPq3bt063Lt3T6HvpzNoP5WUlAQA0qnjwMebOj1//jzbNW7r1asnzT7NaftxcXGIjo5G7dq1pTYtLS2FPv819q9ZLzIyUuG5AcDNze2z+59bPzc3N2lfdXV10atXL6xevRoAcOXKFdy4cUO6VEVOIiIi8N13333Vc0dGRqJs2bLS7FAAcHJygpGRkRSDn58fvL290bRpU8yYMSPba/UpKysrGBoaSo8tLCzw6tUrAB9Pe09LS1OY+Vu8eHHpUgafU65cOZQuXVp67ObmBrlcjlu3bkltVapUgY6OTq7biIiIQJkyZWBvb5/j8qtXryIoKEjhOLdo0QJyuRwPHjz4YoxZlS9fHqamptLjr3mtgeyvX6lSpeDk5AQNDQ2FtszX9Evu3buHtLQ0hb8pbW1t1KpVS3reBg0aICEhAeHh4QgNDUWjRo3QuHFjafZtaGgoGjdu/K/2/2v3NydZZ+ZbWFgAQK77e+vWrWwzyXOaWV6pUiVpRnXmdj/dpp6eHuRyucLMdiIiIlINWsoOgIiIiOhTdnZ2kMlkiIqK+lfrZRZ5shZ9P71hl7e3N1q0aIEDBw7gyJEjmD59OubOnYuhQ4fmuM3Ma1weOHBAoYAGAEWKFFF4nNOlHLIqWbIkZDIZ3r1793U79Ikvbf9T/zX2f7NeXvD29kbVqlXx9OlTrFmzBk2aNEH58uVz7a+np/dNnz8gIAA9evTAgQMHcOjQIUyaNAmbN2/O9Tq5n146QSaTQS6Xf9OYcvOlnPjSa/P+/XsMHDgQvr6+2ZaVK1fum8aSm5xev7x+TY2MjODi4oITJ07g3LlzaNasGRo2bIiuXbvi9u3buHPnDho1avTNnu9Lsu6vTCYDgP95f7/mNYyJiYGBgcE3/xsiIiKi/x1n2hIREZHKMTY2RosWLbBkyZIcb4iU9UZjWWXO8ouOjpbaIiIisvUrW7YsBg0ahJ07d2LkyJH4/fffAUCasZiRkSH1dXJyQpEiRfD48WPY2toq/Ms6o+5r6OjowMnJCX///bfUVqxYMVhaWuLMmTMKfc+cOQMnJ6dct1W8eHFYWFgoXOczPT0dly9f/p9j/5r1HB0dcfHiRYX1crtB3Kc+7Xf+/Hk4OjpKj6tUqYIaNWrg999/R3BwMPr16/fZ7Tk7O3/2JmVZOTo64smTJ3jy5InU9vfffyM2Nlbh9ba3t8eIESNw5MgRdOzYEWvWrPmq7X/KxsYG2traCjfBiouLw+3bt7+47uPHj/H8+XPp8fnz56GhofFVs3QzOTs74+nTp7k+X7Vq1fD3339nO862trafncH7Nb72tf7WKlSoAB0dHYW/qbS0NFy6dEnheRs1aoTjx4/j5MmTaNy4MYyNjeHo6IjAwEBYWFjkOjsZ+Pi3nHWcAPJvfx0cHBTyCUC2x1/rxo0bcHV1/RZhERER0TfGmbZERESkkpYsWYJ69eqhVq1amDJlCpydnZGeno6QkBAsW7Ysx9ONM4uKAQEBCAwMxO3btzF37lyFPsOHD0fLli1hb2+Pd+/e4fjx41LBsHz58pDJZNi/fz9atWoFPT09GBoaYtSoURgxYgTkcjnq16+PuLg4nDlzBsWKFYOXl9e/2q8WLVrg9OnTGD58uNQ2evRoTJo0CRUqVEDVqlWxZs0aREREYOPGjZ/d1rBhwzBjxgzY2dmhYsWKmDdvnkJB+7/G/jXrDRo0CHPnzsXo0aPh7e2Ny5cvZ7vJUW62bduGGjVqoH79+ti4cSMuXryIVatWKfTx9vbGkCFDYGBgkOsM10yTJk3Cd999hwoVKqBbt25IT0/HwYMHMXbs2Gx9mzZtiipVqqBnz55YsGAB0tPTMXjwYDRq1Ag1atRAUlISRo8ejc6dO8Pa2hpPnz7FpUuX0KlTp6/at08ZGhrCy8sLo0ePhrGxMczMzDBp0iRoaGhIMypzo6urCy8vL8yZMwfx8fHw9fVFly5dYG5u/tXP36hRIzRs2BCdOnXCvHnzYGtri6ioKMhkMnh4eGDs2LGoU6cOhgwZAm9vbxgYGODvv/9GSEgIFi9e/J/2OdOXXuu8YmBggJ9++kl6zcuVK4dZs2YhMTER/fv3l/o1btwYixYtgqmpKSpWrCi1LV68GN9///1nn8PKygoPHjyQLj9haGiYb/s7dOhQDBgwADVq1EDdunWxZcsWXLt2DTY2Nv96W6dOnULz5s2/WWxERET07XCmLREREakkGxsbXLlyBe7u7hg5ciQqV66MZs2a4dixYzneKR34eDrwpk2bEBUVBWdnZ8ycORO//vqrQp+MjAz4+PjA0dERHh4esLe3x9KlSwEApUuXxuTJk+Hv749SpUphyJAhAICpU6diwoQJmD59urTegQMHYG1t/a/3q3///jh48CDi4uKkNl9fX/j5+WHkyJGoUqUKDh8+jL1798LOzu6z2xo5ciR69eoFLy8vuLm5wdDQMFuB87/G/qX1ypUrhx07dmD37t1wcXHB8uXLMW3atK96DSZPnozNmzfD2dkZ69atw6ZNm7LNROzevTu0tLTQvXt3hWsA56Rx48bYtm0b9u7di6pVq6JJkybZZgFnkslk2LNnD0qUKIGGDRuiadOmsLGxwZYtWwAAmpqaePv2LXr37g17e3t06dIFLVu2xOTJk79q33Iyb948uLm5oU2bNmjatCnq1asHR0fHL+6Xra0tOnbsiFatWqF58+ZwdnaWcvXf2LFjB2rWrInu3bvDyckJY8aMkWaJOjs7IzQ0FLdv30aDBg3g6uqKiRMnwtLS8j/ta1Zfeq3z0owZM9CpUyf06tUL1apVw927d/Hnn3+iRIkSUp8GDRpALpcrXAahcePGyMjI+OL1bDt16gQPDw+4u7vD1NQUmzZtyrf97dmzJ8aNG4dRo0ahWrVqePDgAfr06fPFfPrUs2fPcPbsWfTt2/ebxkdERETfhkzk5Z0+iIiIiCib77//HtWqVcO4ceOUHYrKevjwISpUqIBLly6hWrVqyg7nm/rw4QNKly6NuXPnKsz8zCogIAC7d+/O8fIeRJ9q1qwZzM3NsX79+q9eZ+zYsXj37h1WrlyZh5ERERHRf8XLIxARERHls9mzZ2Pfvn3KDkMlpaWl4e3btxg/fjzq1KmjFgXb8PBwREVFoVatWoiLi8OUKVMAAO3atVNyZFQQJSYmYvny5WjRogU0NTWxadMmHD16FCEhIf9qO2ZmZvDz88ujKImIiOh/xaItERERUT6zsrLC0KFDlR2GSjpz5gzc3d1hb2+P7du3Kzucb2bOnDm4desWdHR0UL16dZw6dQomJibKDosKIJlMhoMHDyIwMBDJyclwcHDAjh070LRp03+1nZEjR+ZRhERERPQt8PIIRERERERERERERCqENyIjIiIiIiIiIiIiUiEs2hIRERERERERERGpEBZtiYiIiIiIiIiIiFQIi7ZEREREREREREREKoRFWyIiIiIiIiIiIiIVwqItERERERERERERkQph0ZaIiIiIiIiIiIhIhbBoS0RERERERERERKRCWLQlIiIiIiIiIiIiUiH/B/xlq1KlN+1SAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_days_spx = extract_normalized_daily_ohlc(test_features1)\n",
        "test_clusters01 = generate_clusters(test_days_spx, pca_models, cluster_models, feature_steps)\n",
        "test_clusters_spx = test_clusters01[:, ::-1].copy()"
      ],
      "metadata": {
        "id": "qsyl_unWYT9B"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Evaluation function for cluster analysis\n",
        "def evaluate_cluster_range(cluster_indices, true_labels, pred_labels):\n",
        "    \"\"\"\n",
        "    Evaluate performance on specific clusters\n",
        "\n",
        "    Args:\n",
        "        cluster_indices: List of cluster indices to evaluate\n",
        "        true_labels: Ground truth labels\n",
        "        pred_labels: Predicted cluster assignments\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (mean accuracy, sample count) or (None, 0) if no samples\n",
        "    \"\"\"\n",
        "    mask = np.isin(pred_labels, cluster_indices)\n",
        "    y_subset = true_labels[mask]\n",
        "    return (np.mean(y_subset), len(y_subset)) if len(y_subset) > 0 else (None, 0)"
      ],
      "metadata": {
        "id": "guj_KW85YUYE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm  # For progress bars\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Initialization\n",
        "batch_size = 30000  # Process data in batches to manage memory usage\n",
        "all_predicted_tokens = []\n",
        "\n",
        "# Batch prediction with progress bar\n",
        "for i in tqdm(range(0, len(test_clusters_spx), batch_size)):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # Prepare batch (excluding last token since we're predicting it)\n",
        "    batch = test_clusters_spx[i:i+batch_size, :-1]\n",
        "    start_ids = torch.tensor(batch, dtype=torch.long, device=device)\n",
        "\n",
        "    # Generate predictions - we only need 1 new token prediction\n",
        "    y = model.generate(start_ids, max_new_tokens=1)\n",
        "    predicted_tokens = y[:, -1]  # Get the predicted tokens\n",
        "\n",
        "    all_predicted_tokens.extend(predicted_tokens.cpu().tolist())\n",
        "\n",
        "predicted_tokens_array = np.array(all_predicted_tokens)\n",
        "\n",
        "# =============================\n",
        "# Save predicted tokens as .npy file\n",
        "# =============================\n",
        "np.save(\"predicted_tokens2015-2024csi9+10.npy\", predicted_tokens_array)\n",
        "print(f\"Predicted tokens saved to: predicted_tokens2024.npy with shape {predicted_tokens_array.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUesdwGpYXiD",
        "outputId": "c2d55cdc-5284-44ab-d99d-013d19af6aa3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [03:45<00:00, 10.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted tokens saved to: predicted_tokens2024.npy with shape (633768,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store predictions for evaluation\n",
        "test_pred1 = predicted_tokens_array\n",
        "\n",
        "# Evaluate top performing clusters\n",
        "print(\"Top Cluster Evaluation:\")\n",
        "for n in range(1, 8):  # Evaluate top 1-7 clusters\n",
        "    # Get cluster IDs of top n clusters\n",
        "    clusters = sorted_indices[:n]\n",
        "    #clusters = [item['cluster'] for item in clusters]\n",
        "\n",
        "    # Evaluate performance on these clusters\n",
        "    acc, count = evaluate_cluster_range(clusters, test_labels1, test_pred1)\n",
        "\n",
        "    if acc is not None:\n",
        "        # Print accuracy and sample count for these clusters\n",
        "        print(f\"Top {n} clusters: Acc={(1-acc):.4f}, Samples={count}\")\n",
        "    else:\n",
        "        print(f\"Top {n} clusters: No samples\")\n",
        "\n",
        "# Evaluate bottom performing clusters\n",
        "print(\"\\nBottom Cluster Evaluation:\")\n",
        "for n in range(1, 8):  # Evaluate bottom 1-7 clusters\n",
        "    # Get cluster IDs of bottom n clusters\n",
        "    clusters = sorted_indices[-n:]\n",
        "    #clusters = [item['cluster'] for item in clusters]\n",
        "\n",
        "    # Evaluate performance on these clusters\n",
        "    acc, count = evaluate_cluster_range(clusters, test_labels1, test_pred1)\n",
        "\n",
        "    if acc is not None:\n",
        "        # Print inverse accuracy (1-acc) since these are worst performers\n",
        "        print(f\"Bottom {n} clusters: Acc={(acc):.4f}, Samples={count}\")\n",
        "    else:\n",
        "        print(f\"Bottom {n} clusters: No samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dPAvLQpYx0-",
        "outputId": "808371aa-3545-4178-b286-f6636c60cf58"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Cluster Evaluation:\n",
            "Top 1 clusters: Acc=0.5237, Samples=38987\n",
            "Top 2 clusters: Acc=0.5268, Samples=85616\n",
            "Top 3 clusters: Acc=0.5285, Samples=166061\n",
            "Top 4 clusters: Acc=0.5363, Samples=416745\n",
            "Top 5 clusters: Acc=0.5338, Samples=489232\n",
            "Top 6 clusters: Acc=0.5301, Samples=580417\n",
            "Top 7 clusters: Acc=0.5285, Samples=602268\n",
            "\n",
            "Bottom Cluster Evaluation:\n",
            "Bottom 1 clusters: Acc=0.5521, Samples=12793\n",
            "Bottom 2 clusters: Acc=0.5402, Samples=31471\n",
            "Bottom 3 clusters: Acc=0.5290, Samples=53322\n",
            "Bottom 4 clusters: Acc=0.5044, Samples=144507\n",
            "Bottom 5 clusters: Acc=0.4963, Samples=216994\n",
            "Bottom 6 clusters: Acc=0.4761, Samples=467678\n",
            "Bottom 7 clusters: Acc=0.4751, Samples=548123\n"
          ]
        }
      ]
    }
  ]
}